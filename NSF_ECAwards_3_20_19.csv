Award Number#long,Project Type,#img,Title,#name,Collaboration,NSF Organization,Program(s)#multi,Start Date#date,Last Amendment Date#date,Principal Investigator,State,Organization,Latitude#number#hidden,Longitude#number#hidden,Award Instrument,Program Manager,End Date#date,Awarded Amount To Date#number,Co-PI Name(s)#multi,PI Email Address#hidden,Organization Street#hidden,Organization City,Organization State,Organization Zip#hidden,Organization Phone#hidden,NSF Directorate,Program Element Code(s)#multi,Program Reference Code(s)#multi,Abstract#long,NSF URL#link,#href
1821039,IA,IA,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,Collaborative,ICER,EarthCube,7/1/2017,1/18/2018,Jocelyn Sessa,PA,Academy of Natural Sciences Philadelphia,39.95709,-75.171205,Standard Grant,Eva Zanzerkia,8/31/2019,"$99,599.00 ",,js4558@drexel.edu,1900 Benjamin Franklin Parkway,Philadelphia,PA,191031195,2152991065,GEO,8074,7433,"Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.  The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist.  The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1821039,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1821039
1643294,OTHER,OTHER,AAAS Science & Technology Policy Fellowships,AAAS Science & Technology Policy Fellowships,One organization,OIA,ADVANCE|NSF INCLUDES|AAAS FELLOW (O/D)||AAAS - American Association fo|AAAS FELLOWS|OFFICE OF MULTIDISCIPLINARY AC|SCI & TECH  CTRS (INTEG PTRS)|SPECIAL STUDIES AND ANALYSES|AGEP|S-STEM:SCHLR SCI TECH ENG&MATH|NNCO ACTIVITIES|IUSE|ARCTIC RESEARCH PROJECTS|INDUSTRY/UNIV COOP RES CENTERS|GRADUATE RESEARCH FELLOWSHIPS|ITEST|PROGRAM EVALUATION|PRES AWARDS FOR EXCEL IN SCIEN|IIS SPECIAL PROJECTS|Eval & Assessment Capabilites|EFRI RESEARCH PROJECTS|DISCOVERY RESEARCH K-12|ICER|RIC - Research Investment Comm|Core R&D Programs|I-Corps - Nodes|EarthCube|ALLIANCES-MINORITY PARTICIPAT.|Unallocated Program Costs,9/1/2016,8/30/2018,Jennifer Pearl,DC,American Association For Advancement Science,38.900233,-77.028458,Continuing grant,Leah Nichols,8/31/2019,"$14,814,087.00 ",,jpearl@aaas.org,"1200 NEW YORK AVENUE, N.W.",WASHINGTON,DC,200053928,2023266400,O/D,016Y|032Y|039P|0626|065Y|110P|1253|1297|1385|1515|1536|1685|1998|5201|5761|7172|7227|7261|7345|7484|7550|7633|7645|7699|7957|7980|8045|8074|9133|9199,019P|039P|064P|110P|8209,"The American Association for the Advancement of Science (AAAS) and the National Science Foundation (NSF) will continue its collaboration in providing to early- and mid-career scientists and engineers experiential professional development and public service fellowships via the AAAS Science and Technology Fellowship Program. Consistent with the immersion model adopted by AAAS, Fellows at NSF will be selected annually through a competitive process and placed in organizations throughout the Foundation.  Fellows will work with NSF staff on a broad range of activities in order to gain insight into how national science and technology policy goals are translated into and reflected by NSF's mission and strategic goals and how and by whom national science and technology policy is driven, shaped and prioritized.  NSF fellowship assignments are designed to:  educate and expose Fellows to NSF programmatic planning, development and oversight activities in all fields of fundamental research via hands-on engagement; utilize the Fellows' expertise on projects that apprise NSF officials in areas of mutual interest to the Fellow and the host organization; and provide developmental opportunities to inform future career decisions.  The program includes an orientation on executive branch and congressional operations, as well as a year-long suite of knowledge- and skill-building seminars involving science, technology and public policy within the federal as well as NSF contexts.  In the long-term, the AAAS Fellowship program seeks to build leadership capacity for a strong national science and engineering enterprise.  Upon completion of the Fellowship, Fellows will have gained: a broader understanding and increased insights about the development and execution of federal-level science, technology, engineering and mathematics policies and initiatives as well as how policy and science intersect; enhanced skills in communicating science to support policy development; and a greater capacity to serve more effectively in future leadership roles in diverse environments, including public and policy arenas, academia and the private sector.  The ultimate outcome of the Fellowship program experience -- policy savvy science and engineer leaders who understand government and policymaking and are well-trained to develop and execute solutions to address the nation's challenges.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1643294,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1643294
1540902,IA,IA,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Jocelyn Sessa,NY,American Museum Natural History,40.781324,-73.973988,Standard Grant,Eva E. Zanzerkia,2/28/2018,"$172,303.00 ",Neil Landman,js4558@drexel.edu,Central Park West at 79th St,New York,NY,100245192,2127695975,GEO,8074,7433,"Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.  The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist.  The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540902,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540902
1256235,"CC, GOVERNANCE",CC,Community Engagement to Inform EarthCube Governance,Community Engagement to Inform EarthCube Governance,One organization,OAC,DATANET|EarthCube,9/1/2012,3/21/2013,Genevieve Pearthree,AZ,Arizona Geological Survey,33.489048,-112.074213,Standard Grant,Amy Walton,10/31/2013,"$252,506.00 ",Gary Crane|James Bowring,genevieve.pearthree@azgs.az.gov,"416 W. Congress St, #100",Tucson,AZ,857011381,5207703500,CSE,7726|8074,0000|7433|7726|OTHR,"EarthCube is a joint venture between the Directorate of Geosciences and the Office of Cyberinfrastructure at the National Science Foundation. It is a community-driven effort to design and implement an effective data and knowledge management system for the geosciences that will integrates disparate data sets and web services and serves all members of the geoscience community. This planning and assesment project collects and synthesizes the prodigious amount of geoscience and cyberinfrastrucutre community input on possible governance structures for EarthCube that were generated in the run up to the June 2012 EarthCube meeting and actities that have happened during the post meeting timeframe. The project focuses on broadening grass roots geoscience engagement in the process, deepening the input and collecting science-drivers from geoscience communities, and organizing and summarinzing all information so it can be used effectively by the initial EarthCube governance body that will be selected in early 2013. The PI and his outreach team will hold face-to-face and virtual meetings as well as attend and run Town Hall meeings at professional society meetings to engage stakeholders. An important aspect of the project will be to identify community needs and incorporate their suggestions into the final summaries. Project goals also include building stakeholder alignment around shared goals in terms of producing ways to establish standardization of data practices and aspects of its management as well as create a community consensus structure for the evaluation of new tools and utilities. Broader impacts of the work are focused primarily on building infrastructure for science in terms of informing the development of an effective and well received community governance structure.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1256235,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1256235
1238951,WORKSHOP,WORKSHOP,Workshops for a Community Roadmap for Governance of Geoscience Cyberinfrastructure (EarthCube),Workshops for a Community Roadmap for Governance of Geoscience Cyberinfrastructure (EarthCube),One organization,EAR,EarthCube,4/1/2012,3/27/2012,M. Lee Allison,AZ,Arizona Geological Survey,33.489048,-112.074213,Standard Grant,Barbara L. Ransom,3/31/2013,"$99,999.00 ",Geoffrey Fox|Gary Crane|David Arctur|Hannes Leetaru,lee.allison@azgs.az.gov,"416 W. Congress St, #100",Tucson,AZ,857011381,5207703500,GEO,8074,7433,"EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (governance) in the development of EarthCube, a major new NSF initiative. Community/stakeholder buy-in and adoption of standards; common tools and aproaches, if possible; best practices; cyberinfrastructure protocols; and workflows are essential to any holistic approach to creating an interoperable and service-oriented architecture that serves the needs of the geoscience research community wishing to do data-enabled science. The funded series of online/virtual workshops that will engage a brod spectrum of the geoscience community were considered innovative and exciting, especially the proposed application of social networking outreach utilities to engage early career scientists and students. A prime deliverable of the project will be a road map of how to move forward in terms of setting up broadly agreed upon structures to oversee the development of EarthCube activities in the associated working groups and concept grants. Broader impacts of the work include converging on mutually agreed upon processes to allow decision making with regard to whether or not standards or specific protocols should be established, and if so what they should be. They also include the fostering of close interaction between communities that do not commonly interact with one another (the geosciences and those in cyberinfrastructure and computer science) and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238951,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238951
1417948,WORKSHOP,WORKSHOP,EarthCube Domain Workshop: Data Facilities,EarthCube Domain Workshop: Data Facilities,One organization,ICER,EarthCube,1/15/2014,1/16/2014,M. Lee Allison,AZ,Arizona Geological Survey,33.489048,-112.074213,Standard Grant,Eva E. Zanzerkia,12/31/2015,"$93,147.00 ",Jennifer Arrigo|Cynthia Chandler|Kerstin Lehnert,lee.allison@azgs.az.gov,"416 W. Congress St, #100",Tucson,AZ,857011381,5207703500,GEO,8074,7433,"Data facilities provide a key resource in the pursuit of innovative scientific research by aggregating, preserving, and disseminating large quantities of data sets, including highly complex petabyte scale data to more simple metadata catalogs. The proposed workshop provides a forum for leaders from these facilities, regardless of scale, type or format of data, to gather and discuss commonalities and collaborative solutions to the increasing challenges associated with providing data access for researchers. In addition, this workshop will act as a key end-user Assembly Group during the EarthCube Test Enterprise Governance process to identify decision making processes and governance models that are most applicable to the geoscience data facilities.  A steering committee of experts from across the Geosciences, including Atmosphere, Oceans, and Earth Sciences will act to identify key participants and create a quality agenda. Social scientists will be utilized to ensure developmental evaluation and learning loops are incorporated into the agenda; this includes the construction of key scenarios and exercises for discussion and breakout groups.  Results of the meeting will include a set of common and unique requirements and challenges associated with the communication, collaboration, interoperability, and governance structures required to ensure that the capabilities and opportunities of existing and emerging NSF/GEO facilities are incorporated into the EarthCube concept.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1417948,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1417948
1346690,WORKSHOP,WORKSHOP,"EarthCube Domain End-User Workshop: Community-Based Cyberinfrastructure for Polar Science Instrumentation, Technology, and Environmental Monitors","EarthCube Domain End-User Workshop: Community-Based Cyberinfrastructure for Polar Science Instrumentation, Technology, and Environmental Monitors",One organization,PLR,POLAR CYBERINFRASTRUCTURE|EarthCube,10/1/2013,3/27/2015,Alberto Behar,AZ,Arizona State University,33.42424,-111.928053,Standard Grant,Renee D. Crain,3/31/2015,"$35,233.00 ",,alberto.behar@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,GEO,5407|8074,1079|7433,"The project consists in the organization of a workshop aiming at bringing together scientists from the polar science domain and cyberinfrastructure specialists. The goal is to gather requirements and develop a vision for an advanced information and knowledge management system that will transform the way instrumentation, technology, sensors and environmental monitors are used in polar regions in the conduct of science. The workshop will provide community feedback to the EarthCube initiative and the Polar Cyberinfrastructure program to design and develop the architecture of an Earth Science cyberinfrastructure that is aligned with the end-users' needs for new systems aimed data acquisition, field storage, transmission, security, redundancy and the deployment infrastructure techniques and material for these systems. The format will be the same as previous Earthcube sponsored workshop.  The workshop will target requirements on science-drivers on the latest needs in instrumentation/sensing systems, field computing, power: generation, handling, distribution & storage, data: storage, reliability and transmission, environmental enclosures, field deployment techniques and other needs to design strategies for funding opportunities that will support scientists and engineers to perform outstanding and ground-breaking research in the polar regions. The workshop will target a broad spectrum of polar scientists, with the goal that a significant contingent of early career scientists will participate.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1346690,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1346690
1225810,OTHER,OTHER,Collaborative Research: OpenTopography: A Cyberinfrastructure-Enabled Facility for High-Resolution Topographic Data and Tools,Collaborative Research: OpenTopography: A Cyberinfrastructure-Enabled Facility for High-Resolution Topographic Data and Tools,Collaborative,EAR,GEOINFORMATICS|EarthCube,4/1/2013,7/13/2015,J Ramon Arrowsmith,AZ,Arizona State University,33.42424,-111.928053,Continuing grant,Russell C. Kelz,3/31/2017,"$198,158.00 ",,ramon.arrowsmith@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,GEO,7255|8074,7433,"This Geoinformatics award to Arizona State University (PI: Arrowsmith) supports a three year development project that is collaborative with the University of California, San Diego (PI: Baru).  The project plan will improve upon and refine the capabilities of the OpenTopography Light Detection and Ranging (LiDAR) data services web portal that was previously jointly supported by NSF/EAR, NSF/OCI and NSF/CISE (EAR-0930731/EAR-0930643).     OpenTopography (OT) was designed to allow users web-based access Lidar generated high resolution topographic data sets and analysis tools in support of surface Earth process research, research training and education.  This award will develop OT2, an extensible interface and platform that will allow scientists to develop and plug in functional modules, and a scalable system that will allow archive growth and computer services provided by cloud computing modalities.   OT2 will expand capabilities to handle full waveform LiDAR, TLS data and bathymetric data.  OT2 will continue to ingest extant airborne LiDAR and terrestrial laser scanning (TLS) data sets from numerous sources beyond airborne LiDAR and TLS data sets produced by continued and expanding use of the National Center for Airborne Laser Swath Mapping Facility (NCALM) and the UNVACO hosted TLS instrument pool.   Hosted data now at OT includes also airborne LiDAR data sets flown for EarthScope science projects, Critical Zone Observatories, NOAA, US Bureau of Reclamation, USGS, Bureau of Land Management, the US Forest Service and numerous state airborne LiDAR data sets.     Currently, OT hosts some 200 billion LiDAR returns and thousands of pre-computed digital elevation models (DEMs) and Google Earth readable kmz files.  OT management has documented high volume use of the web portal.  There are over 1,500 registered users, the site gets between 5,000 and 25,000 page view per month and more than 12,000 automated job runs have accessed over 250 billion LiDAR returns.  OT PIs also report that more than 35,000 pre-computed DEM tiles have been downloaded and over 70 Gb of Google Earth imagery is streamed per month.  The user base is approximately 22% students, 27% academic researchers, 24% government scientists and 15% commercial sector.    ***",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1225810,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1225810
1550229,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,Collaborative,OAC,Software Institutes|EarthCube,9/1/2016,8/19/2016,Everett Shock,AZ,Arizona State University,33.42424,-111.928053,Standard Grant,Micah Beck,8/31/2019,"$213,345.00 ",,eshock@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,CSE,8004|8074,7433|8004|8009,"Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science.  They model the chemistry of melting of the interiors of planets as a result of heat flow within the body.  They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits.  They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles.  They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids.  Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies.   It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization.    This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics.  ENKI will provide software tools in computational thermodynamics and fluid dynamics.  It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks.  ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research.  ENKI development will be community driven.  Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples.  All software associated with this project will be released as open source.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550229,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550229
1101100,OTHER,OTHER,"Bridging Data, New Technologies, and Communities to Enable and Communicate EarthScope Exploration and  Discovery","Bridging Data, New Technologies, and Communities to Enable and Communicate EarthScope Exploration and  Discovery",One organization,EAR,EARTHSCOPE-SCIENCE UTILIZATION|ICER|EarthCube,5/1/2011,7/8/2014,J Ramon Arrowsmith,AZ,Arizona State University,33.42424,-111.928053,Cooperative Agreement,Gregory J.  Anderson,4/30/2016,"$2,615,614.00 ",Edward Garnero|Steven Semken|Wendy Taylor|Matthew Fouch,ramon.arrowsmith@asu.edu,ORSPA,TEMPE,AZ,852816011,4809655479,GEO,017F|7699|8074,017F|1733|7433|8076,"EarthScope enables the exploration of the structure and evolution of the North American continent by scientists accessing a range of seismological, geodetic, in situ fault zone sampling, and geochronology and high resolution topography resources. EarthScope science is notable for its interdisciplinarity. Science results from EarthScope go beyond narrow analyses of individual datasets, and combine diverse observational datasets with innovative experimental and theoretical exploration. These results produce transformative knowledge for studying earth's structures and processes and in understanding hazards and guiding exploration of resources. In addition, these data and technologies offer superb opportunities to enhance formal and informal science education in the solid Earth sciences. The EarthScope National Office (ESNO) at Arizona State University serves the broad and diverse community of EarthScope stakeholders, including EarthScope researchers, formal and informal educators in Earth science, and the general public.   The ESNO will serve the scientific community through leadership and support of the EarthScope Steering committee, via close communication with the EarthScope program at NSF and the EarthScope Facilities (USArray, PBO, SAFOD), and by frequent solicitation of feedback and new ideas. The ESNO will maintain these activities as well as further promote EarthScope by assuming a meta-leadership role in coordinating current and new earth science initiatives (such as a major focus on Cascadia, the eastward movement of the Transportable Array, developing a plan for Alaskan EarthScope investigation, impending Frontiers in Earth System Dynamics projects, and earthquakes directly affecting the US). The need to integrate EarthScope and related data and other geoscience tools remains a critical need which can be addressed using the tools of cyberinfrastructure. Interesting new and unexpected applications of the EarthScope observational systems will be encouraged (e.g., atmosphere, hydrosphere, and cryosphere).  The ESNO foregrounds education and outreach (E&O): giving it attention, expertise, and resources at the same level as EarthScope science.  This is accomplished by maintaining and expanding on effective services such as the EarthScope E&O website, Newsletters, Speaker Series, Interpretive Workshops for informal educators, and the biannual EarthScope National Meeting.  Further, ESNO adds value to the programmatic E&O portfolio through new initiatives to:  - Rapidly channel EarthScope science through new social media such as Facebook, Twitter, and the 'Geoblogosphere';  - Pilot and disseminate exemplary new solid-Earth science content and inquiry-driven pedagogy for K-12 STEM teacher development (in partnership with organizations such as AGI and PRI); - Catalyze the use of regional and local results from EarthScope research in promoting place-based Earth science teaching at all levels to better engage and retain diverse students; and - Deliver a new continuing professional education service for EarthScope researchers and educators at the university and graduate levels: the University of EarthScope.  E&O at ESNO, infused with a place-based and educator-centered ethos, coordinates the compilation and presentation of the spectacular findings and scientific legacy of the EarthScope program, and is a reliable and effective partner to stakeholders.  Intellectual merit: Exploration of the 4-D structure of the North American continent is spectacularly underway with EarthScope by a vigorous community of scientists. The results are fundamental to increasing our understanding of the Earth, for characterizing how we live with potentially hazardous Earth processes, and for guiding exploration of resources. They are transformative in Earth science and technology education.  The ESNO at ASU will be well-situated, planned, and configured to foster continued Earth exploration and discovery.    Broader impacts: The ESNO at ASU will enhance and continue to expand a high-profile public identity for EarthScope, establish a sense of ownership among scientific, professional, and educational communities, promote science literacy and understanding of EarthScope and Earth science in general, advance formal Earth science education, and foster use of EarthScope data, discoveries, and new technology in resolving challenging problems and improving our quality of life. Scientists, educators, students, decision makers, and our fellow citizens, in the Southwest as well as across the US and abroad, will all benefit from these activities.   Non-technical explanation of broader significance and importance: Exploration of the four dimensional structure of the North American continent and Earth processes operating on and within it is spectacularly underway with EarthScope by a vigorous community of scientists. The results are fundamental to increasing our understanding of Earth, for characterizing how we live with potentially hazardous Earth processes, and for guiding exploration of natural resources. They are transformative in Earth science and technology education.  The EarthScope National Office at Arizona State University will be well-situated, planned, and configured to foster continued Earth exploration and discovery.  It will enhance and continue to expand a high-profile public identity for EarthScope, establish a sense of ownership among scientific, professional, and educational communities, promote science literacy and understanding of EarthScope and Earth science in general, advance formal Earth science education, and foster use of EarthScope data, discoveries, and new technology in resolving challenging problems and improving our quality of life. Scientists, educators, students, decision makers, and our fellow citizens, in the Southwest as well as across the U.S. and abroad, will all benefit from these activities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1101100,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1101100
1835704,"SI2, CSSI",SI2,Collaborative Research: Framework: Software: NSCI : Computational and data innovation implementing a national community hydrologic modeling framework for scientific discovery,Collaborative Research: Framework: Software: NSCI : Computational and data innovation implementing a national community hydrologic modeling framework for scientific discovery,Collaborative,OAC,Software Institutes|EarthCube,10/1/2018,9/12/2018,Catherine Olschanowsky,ID,Boise State University,43.603313,-116.201649,Standard Grant,Stefan Robila,9/30/2022,"$700,000.00 ",Alejandro Flores,cathie@cs.boisestate.edu,1910 University Drive,Boise,ID,837250001,2084261574,CSE,8004|8074,026Z|062Z|077Z|7925|8004,"This award supports the design and implementation of a software framework to simulate the movement of water at various scales. Understanding the movement and availability of water locally and across the country is of paramount importance to economic productivity and human health of our nation. Hydrologic scientists, are actively tackling these challenges using increasingly complex computational methods. However, modeling advances have not been easily translated to the broader community of scientists and professionals due to technical barriers to entry. This software platform draws from computer models and employs supercomputers capable of analyzing big data to provide unprecedented simulations of water movement over the continental US. Combining hydrologists and computer scientists the team behind the project envision a broad community of users who will have multiple ways to interact with the software framework. For the hydrologic scientist who is interested in generating their own scenarios the framework will facilitate direct interaction with the hydrologic models and the ability to generate simulations on the fly. Conversely, the framework will also provide a set of static output and a range of tools for a broader set of users who would like to evaluate hydrologic projections locally or extract model data for use in other analyses.  Continental scale simulation of water flow through rivers, streams and groundwater is an identified grand challenge in hydrology. Decades of model development, combined with advances in solver technology and software engineering have enabled large-scale, high-resolution simulations of the hydrologic cycle over the US, yet substantial technical and communication challenges remain. With support from this award, an interdisciplinary team of computer scientists and hydrologists is developing a framework to leverage advances in computer science transforming simulation and data-driven discovery in the Hydrologic Sciences and beyond. This project is advancing the science behind these national scale hydrologic models, accelerating their capabilities and building novel interfaces for user interaction. The framework brings computational and domain science (hydrology) communities together to move more quickly from tools (models, big data, high-performance computing) to discoveries. It facilitates decadal, national scale simulations, which are an unprecedented resource for both the hydrologic community and the much broader community of people working in water dependent systems (e.g., biological system, energy and food production). These simulations will enable the community to address scientific questions about water availability and dynamics from the watershed to the national scale. Additionally, this framework is designed to facilitate multiple modes of interaction and engage a broad spectrum of users outside the hydrologic community. We will provide easy-to-access pre-processed datasets that can be visualized and plotted using built-in tools that will require no computer science or hydrology background. Recognizing that most hydrology training does not generally include High Performance Computing and data analytics or software engineering, this framework will provide a gateway for computationally enhanced hydrologic discovery. Additionally, for educators we will develop packaged videos and educational modules on different hydrologic systems geared towards K-12 classrooms.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Activities Program of the Division of Earth Sciences within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835704,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835704
1642610,RCN,RCN,Collaborative Proposal: EarthCube RCN: Connecting the Earth Science and Cyberinfrastructure communities to advance the analysis of high resolution topography data,Collaborative Proposal: EarthCube RCN: Connecting the Earth Science and Cyberinfrastructure communities to advance the analysis of high resolution topography data,Collaborative,EAR,EarthCube,8/15/2017,8/10/2017,Nancy Glenn,ID,Boise State University,43.603313,-116.201649,Standard Grant,Dena Smith,7/31/2019,"$50,081.00 ",,nancyglenn@boisestate.edu,1910 University Drive,Boise,ID,837250001,2084261574,GEO,8074,9150,"This EarthCube Research Coordination Network (RCN) will bring together communities that create and use high resolution map data, including those that conduct research on earth surface processes and those that create the technology to make these types of complex data usable. Members of this network will work to share currently available resources and best practices, and to develop new tools to make data more available to researchers. Training will focus on teaching graduate student and early career researchers to access and use high resolution map data to answer earth science research questions.   Vast quantities of High Resolution Terrain (HRT) data have been collected, with applications ranging from scientific research to commercial sector engineering. Full scientific utilization of these HRT data is still limited due to challenges associated with the storage, manipulation, processing, and analysis of these data. The cyberinfrastructure community, including computer vision, computer science, informatics, and related engineering fields are developing advanced tools for visualizing, cataloging, and classifying imagery data including point clouds. Yet, many of these tools are most applicable to engineered structures and small datasets, and not to heterogeneous landscapes. Together the earth science and cyberinfrastructure communities have the opportunity to test and validate emerging tools in challenging landscapes (e.g., heterogeneous and multiscale landforms, vegetation structures, urban footprints). In particular, this RCN will be focused on four themes: (1) coordination of the analysis of HRT data across the earth surface processes and hydrology communities to identify work-flows and best practices for data analysis; (2) identification of cyberinfrastructure tool development needs as new technologies for HRT data acquisition emerge; (3) use of HRT data for numerical models validation and integration of HRT data information in models; (4) training in HRT best practices, and data processing and analysis work-flows.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1642610,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1642610
1440638,"SI2, CSSI",SI2,SI2-SSE: GEM3D: Open-Source Cartesian Adaptive Complex Terrain Atmospheric Flow Solver for GPU Clusters,SI2-SSE: GEM3D: Open-Source Cartesian Adaptive Complex Terrain Atmospheric Flow Solver for GPU Clusters,One organization,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,10/1/2014,8/31/2017,Inanc Senocak,ID,Boise State University,43.603313,-116.201649,Standard Grant,Alan Sussman,9/30/2018,"$500,000.00 ",Grady Wright|Donna Calhoun|Elena Sherman,senocak@pitt.edu,1910 University Drive,Boise,ID,837250001,2084261574,CSE,1525|8004|8074,7433|8005|9150,"The U.S. Government invests in leadership supercomputing facilities through several agencies to advance scientific discovery in many fronts. This project is motivated by this national commitment to supercomputing research and the increasing availability of many-core computing hardware from workstations to supercomputers. Today scientists and engineers have access to extreme-scale computing resources. However, many legacy codes do not take advantage of recent innovations in computing hardware, and there is a lack of open-source simulation science software that can effectively leverage the many-core computing paradigm. Computational fluid dynamics (CFD) solvers have advanced many fields such as aerospace engineering and atmospheric sciences. Many current open-source CFD models and numerical weather prediction models do not take full advantage of the superior compute performance of graphics processing units (GPUs). By creating an open-source community model that can execute on multi-GPU workstations and large GPU clusters, the project team expects to broaden the use of high-performance computing in fluid dynamics applications. The immediate target application is wind modeling over complex terrain, to support research and development in wind resource assessment, power forecasting, atmospheric research, and air pollution. Through this project, the PIs will continue to transfer and expand the knowledge bases in GPU computing, computational mathematics, and software engineering to new students. Skill sets that transcend traditional disciplines are highly prized by national laboratories as there is a critical shortage of workforce who can conduct scientific research using supercomputers. Students and postdoctoral researchers who are involved in this project will contribute toward this critical workforce.   This project brings together engineers, applied mathematicians, and computer scientists. The entire suite of software elements will be designed for GPU clusters with an MPI-CUDA implementation that overlaps computation with communications using a three-dimensional decomposition for enhanced scalability. The implementation will balance performance and further development and ownership by a broader community of academic researchers. The team will follow modern software engineering practices for concurrent applications. An adaptive mesh refinement strategy that can scale on GPU clusters will be developed. A novel projection method based on radial basis functions will impose the divergence-free constraint on a hierarchy of adaptively refined grids. Software elements will be tested using unit testing and verification techniques for concurrent programs, and against data available from benchmark numerical problems.  The flow solver will include modules for the immersed boundary approach for arbitrarily complex terrain and the dynamic large-eddy simulation technique. The software implementation and syntax will be intuitive to allow contributions from a larger community. The project team expects the proposed software to help reduce modeling errors with very high resolution simulations and contribute toward a fundamental understanding of turbulent winds over complex terrain. The PIs of this project will continue their teaching efforts in Parallel Scientific Computing, Computational Mathematics, and Software Engineering. The results will be disseminated through conference presentations and via a wiki site for the open-source project. Software elements will be released under an open-source GNU General Public License.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440638,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440638
1212508,"DIBBS, BIGDATA, III",DIBBS,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,Collaborative,IIS,INFO INTEGRATION & INFORMATICS,10/1/2012,9/18/2012,Roberto Tamassia,RI,Brown University,41.826772,-71.402548,Standard Grant,Maria Zemankova,9/30/2018,"$250,000.00 ",,rt@cs.brown.edu,BOX 1929,Providence,RI,29129002,4018632777,CSE,7364,7925|9150,"Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.  This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1212508,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1212508
1343661,"CC, GOVERNANCE",CC,EarthCube Conceptual Design:  A Scalable Community Driven Architecture,EarthCube Conceptual Design:  A Scalable Community Driven Architecture,One organization,ICER,EarthCube,6/15/2014,6/9/2014,Stanislav Djorgovski,CA,California Institute of Technology,34.137658,-118.125269,Standard Grant,Eva E. Zanzerkia,5/31/2018,"$299,994.00 ",Daniel Pilone,george@astro.caltech.edu,1200 E California Blvd,PASADENA,CA,911250600,6263956219,GEO,8074,7433,"The PIs develop a conceptual architecture for the EarthCube program. The conceptual architecture will serve as the blueprint for the definition, construction, and deployment of both existing and new components to ensure that they can be unified and integrated into a evolutionary national infrastructure for EarthCube. They intend to create a concept that incorporates findings and requirements from ongoing EarthCube activities as well as other cross-agency Earth Science informatics efforts. The architecture models will be a roadmap for building an extensible and sustainable EarthCube system that facilitates new science and inspires substantive participation of a broad spectrum of geoscientists. The project team is led by a group of computer scientists from National Aeronautics and Space Administration (NASA) and private industry that has extensive experience and a proven track record leading the architecture, design and development of complex and data intensive science data systems. They will specifically focus on the development of a guiding architecture report and specification.   The results of this EarthCube architecture study can intellectually contribute to other scientific and agency efforts as they are studying new architectural models to address scientific data management and discovery in the big data era.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343661,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343661
1835860,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: HDR: Data-Driven Earth System Modeling,Collaborative Research: HDR: Data-Driven Earth System Modeling,Collaborative,AGS,Software Institutes|EarthCube,11/1/2018,9/7/2018,Tapio Schneider,CA,California Institute of Technology,34.137658,-118.125269,Continuing grant,Eric T. DeWeaver,10/31/2023,"$1,499,913.00 ",Andrew Stuart,tapio@caltech.edu,1200 E California Blvd,PASADENA,CA,911250600,6263956219,GEO,8004|8074,026Z|062Z|4444|7925|8004,"Global weather and climate models represent the atmosphere on computational grids with horizontal spacing of perhaps 100km, stacked in layers which can be over a kilometer thick.  Such grids suffice to capture the dynamics of cyclones, fronts, and other large-scale atmospheric phenomena, but these phenomena depend critically on processes with spatial scales much smaller than the grid spacing.  The small-scale processes must be represented indirectly, through parameterization schemes which estimate their net impact on the resolved atmospheric state.  For example clouds are typically too small for the grid spacing yet they are critical for moving moisture from the ocean surface to the mid-troposphere, thus cloud parameterizations play a key role in determining atmospheric humidity even on the largest spatial scales.  Parameterization schemes are inherently approximate, and the development of schemes which produce realistic simulations is a central challenge of model development.  Shortcomings in parameterization limit the usefulness of weather and climate models both for scientific research and for societal applications.  Most parameterization schemes depend critically on various parameters whose values cannot be determined a priori but must instead be found through trial and error.  This task, referred to as ""tuning"", is laborious as it is performed separately for each parameterization scheme and involves multiple integrations of the model in multiple configurations. It is also inefficient in its use of observations, which is unfortunate given the large amount of observational data available from satellites and other sources. The resulting parameter sets may not be optimal and may produce unexpected results when all the schemes interact with each other in global simulations.  Finally, manual tuning is not conducive to uncertainty quantification, which would be valuable for estimating the uncertainty in future climate change projections.   The goal of this project is to replace ad hoc manual tuning with a combination of data assimilation, machine learning, and fine-scale process modeling using large eddy simulation (LES) models.  LES models have grid spacings of a few tens of meters and can explicitly simulate the clouds and turbulence represented by parameterization schemes.  These ingredients are combined to create a global Machine Learning Atmospheric Model (MLAM), in which LES models embedded in selected grid columns of a global model explicitly simulate subgrid-scale processes which are represented by parameterization schemes in the other columns. Machine learning is used to tune the schemes to emulate the behavior of the LES simulations, so that explicit simulations become an online benchmark for parameterization.  In this way all the schemes can be tuned together and interactively within a running global simulation.  Observational data from a variety of sources is assimilated during the model integration to provide a further constraint on parameter values, and estimates of parameter uncertainty are generated as part of the automated tuning.  A similar tuning process is implemented in an ocean general circulation model, and the two are combined to produce a machine learning climate model.  Model tuning is generally viewed as a necessary but mundane activity which is not in itself a research topic.  But a model capable of learning its parameters from observations and process models offers a new path forward, toward both better models and better ways of using models.  The work has broader impacts due to the societal value of better forecasts and projections from weather and climate models.  The work directly addresses uncertainty in forecasts and projections used by decision makers to plan for weather and climate impacts.  In addition, the modeling strategy developed here is applicable to a broad class of research areas which face the problem of relating large-scale behaviors to small-scale unresolved processes (the problem of relating genotypes to phenotypes in evolutionary biology, for example).  In addition, the PIs will establish a cross-disciplinary graduate program on data-driven Earth system modeling. The program bridges the gap between environmental and computational sciences which currently hinders progress in environmental modeling.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835860,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835860
1541049,IA,IA,EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment,EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment,Collaborative,ICER,EarthCube,9/1/2015,9/9/2015,Stanislav Djorgovski,CA,California Institute of Technology,34.137658,-118.125269,Standard Grant,Eva Zanzerkia,8/31/2018,"$144,529.00 ",,george@astro.caltech.edu,1200 E California Blvd,PASADENA,CA,911250600,6263956219,GEO,8074,7433,"EarthCube is supporting the creation of interoperable tools and services for Earth science research, but no environment currently exists for integration and testing of these components.  The EarthCube Integration and Test Environment (ECITE), an outgrowth of activities of the EarthCube Testbed Working Group. The ECITE approach focuses on integrating existing effective technologies and resources as well as capabilities being built by the EarthCube community to provide a federated and interoperable test environment. ECITE?s nationwide cyberinfrastructure for the geosciences will also advance the understanding of regional cyberinfrastructure and collaborative geosciences across geographic locations and disciplines by contributing relevant scheduling tools and a working integration and testing environment. A hallmark of the ECITE effort will be engagement of scientists and technologists from multiple disciplines and geographic regions across the geosciences community to develop requirements, prototype, design, build, and test an integration test-bed that will support cross-disciplinary research.  The multi-disciplinary ECITE team is led by Sara Graves of the University of Huntsville in Alabama (UAH) and includes participants from all areas of the United States. ECITE activities will enable EarthCube to further support other members and contribute leadership to the broader scientific community. The ECITE federated Integration and Test (I&T) environment has the potential to scale and extend to an NSF wide integration and test capability that can serve as a model and example for other agencies. The proposed ECITE functionality is vital to ensure that the broader goals of the EarthCube are achieved.  The ECITE team will actively engage EarthCube and the wider geosciences community in definition of requirements, design, and testing of the system. ECITE will consist of a seamless federated system of scalable and location independent distributed computational resources (nodes) across the US.  The hybrid federated system will provide a robust set of distributed resources to include both public and private cloud capabilities.  The nodes will provide compute and storage resources requiring minimal system administration.ECITE is an important step in ensuring that EarthCube components will be able to work together to provide a successful framework that can continue to evolve to meet the needs of the geosciences community.  This research addresses timely issues of integration, test and evaluation methodologies and best practices with a strong interoperability theme to advance disciplinary research through the integration of diverse and heterogeneous data, algorithms, systems and sciences. The results and findings will provide guidance for EarthCube evolution and future integration efforts. The ECITE team aims to make the Integration and Test (I&T) environment easy to use and readily available to the EarthCube community. Access to the resulting platform will enable and encourage the EarthCube community to develop prototypes, try out new technologies, and to share ideas, concepts and experiments",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541049,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541049
1338705,WORKSHOP,WORKSHOP,Collaborative Research: EarthCube End-User Workshop: Deep Seafloor Processes and Dynamics,Collaborative Research: EarthCube End-User Workshop: Deep Seafloor Processes and Dynamics,Collaborative,OCE,EarthCube,4/15/2013,4/5/2013,Karyn Rogers,DC,Carnegie Institution of Washington,38.909372,-77.035855,Standard Grant,Eva Zanzerkia,3/31/2014,"$12,874.00 ",,rogerk5@rpi.edu,1530 P ST NW,WASHINGTON,DC,200051910,2023876400,GEO,8074,0000|7433|OTHR,"The seafloor serves and the primary conduit for mass and heat transfer between the sub-seafloor and the overlying ocean water column, with both operating on vastly different time and mass scales.  Dynamics at this interface drive global biogeochemical and geochemical elemental cycles, control global ocean chemistry, and shape the atmosphere and climate systems. Deep sea ecosystems also host some of the most diverse and extreme ecosystems including those inhabiting hydrothermal vents, cold seeps, mid-ocean ridges, ridge flanks, and plate margins.  Without data from a wide variety of disciplines, such as geology, petrology, geophysics, hydrogeology, and micro/macro/evolutionary biology, it is not possible to realistically model these important systems and understand the complex interactions between their various physical, chemical, and biological components. Instrumental to understanding processes and dynamics of the deep sea requires integration of the disparate datasets and models that represent and predict the behavior of the components of this complex, important system.  The goal of this workshop is to surface requirements in the field of deep sea processes for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~55 oceanographers from across the relevant disciplines. It will also include cyber/computer science experts.  Together workshop participants will collectively define future science goals in this important scientific area and focus on identifying the most critical, widespread cyberinfrastructure and data management issues and problems presently holding back scientific advances in deep sea science in order to guide the development of NSF EarthCube cyberinfrastructure. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers to enable more interdisciplinary research to take place.  Workshop participants will address topics such as science drivers in deep sea process research in the next 15 years, data and data management needs and problems, and software and visualization needs to help model and understand data. Broader impacts of the work include support of an organization in an EPSCoR state, support of two PIs whose gender is under-represented in the sciences and engineering, and engagement of early career scientists. A virtual component of the workshop will be held to help broaden participation beyond those present on-site.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338705,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338705
1443037,"DIBBS, BIGDATA, III",DIBBS,CIF21 DIBBs: Collaborative Research: Cyberinfrastructure for Interpreting and Archiving U-series Geochronologic Data,CIF21 DIBBs: Collaborative Research: Cyberinfrastructure for Interpreting and Archiving U-series Geochronologic Data,Collaborative,OAC,PALEOCLIMATE PROGRAM|PETROLOGY AND GEOCHEMISTRY|MARINE GEOLOGY AND GEOPHYSICS|DATANET|EarthCube|EPSCoR Co-Funding,9/1/2014,8/25/2014,James Bowring,SC,College of Charleston,32.783612,-79.937176,Standard Grant,Amy Walton,8/31/2019,"$579,762.00 ",,bowringj@cofc.edu,66 GEORGE ST,CHARLESTON,SC,294240001,8439534973,CSE,1530|1573|1620|7726|8074|9150,4444|7433|8048|9150,"Uranium-series geochronology plays a critical role in understanding the time-scales and rates of climate change, sea-level change, and volcanic activity.  There are no standardized data-handling protocols or community-based open data archives for raw isotopic data and reduced results. The U-series geochronology community wants to change this and is encouraged by NSF's vision for 21st century cyberinfrastructure.  In this pilot demonstration project, software engineers and geochronologists collaborate to build open-source cyberinfrastructure that standardizes and facilitates U-series data analysis, reporting, and archiving and analysis and re-processing of the vast amounts of legacy data.  The project uses the NSF-funded EarthChem-Geochron data repository that archives results from many dating schemes, stimulating inter-domain sharing and discovery. This cyberinfrastructure supports teaching and training at all levels and provides non-experts access to new knowledge.    This collaborative effort applies modern software engineering practices to solving the cyberinfrastructure problems of the U-series geochronology community, making the calculation, archiving, access, and interpretation activities of U-series geochronology as rigorous, seamless, and simple as possible.  Currently, isotopic dates from U-series data are calculated and analyzed using legacy, platform-dependent software, and dates are difficult to synthesize because they have been published with disparate decay constants and reporting norms. This pilot project includes new software to calculate, visualize, and interpret U-series dates from new and legacy data, and new schema for data archiving at Geochron.org. Importantly, this project advances the sustainability of NSF's software ecosystem by building upon the cyberinfrastructure architecture already developed for the U-Pb geochronology community under the EARTHTIME umbrella.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443037,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443037
1704896,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,Collaborative,ICER,EarthCube,10/1/2016,11/9/2016,Thomas Narock,MD,College of Notre Dame of Maryland,39.352239,-76.621145,Standard Grant,Eva Zanzerkia,8/31/2017,"$50,718.00 ",,tnarock@ndm.edu,4701 North Charles Street,Baltimore,MD,212102404,4105325314,GEO,8074,7433,"The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.  A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1704896,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1704896
1450089,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,Russ Schumacher,CO,Colorado State University,40.573436,-105.086547,Standard Grant,Bogdan Mihaila,7/31/2019,"$177,173.00 ",,russ.schumacher@colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,CSE,1525|8004|8074,4444|7433|8009,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450089,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450089
1239693,"EAGER, RAPID, INSPIRE",EAGER,EAGER:  Collaborative Research:  Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER:  Collaborative Research:  Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities,Collaborative,EAR,EarthCube,4/1/2012,7/30/2014,Clifford Matsumoto,CO,Colorado State University,40.573436,-105.086547,Standard Grant,Barbara L. Ransom,3/31/2015,"$17,972.00 ",,cliff.matsumoto@colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,GEO,8074,7433|7916,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239693,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239693
1639570,BB,BB,EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2016,9/1/2016,V. Chandrasekar,CO,Colorado State University,40.573436,-105.086547,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$228,600.00 ",,chandra@colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,GEO,8074,7433,"While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.  CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639570,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639570
1440109,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2014,8/6/2014,V. Chandrasekar,CO,Colorado State University,40.573436,-105.086547,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$40,000.00 ",,chandra@colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,GEO,8074,7433,"The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating  data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)  The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440109,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440109
1465216,OTHER,OTHER,"Feedbacks between Vegetation, Aerosol and Cloud Processes Using Observations and a Unified Regional Climate Model","Feedbacks between Vegetation, Aerosol and Cloud Processes Using Observations and a Unified Regional Climate Model",One organization,AGS,PHYSICAL & DYNAMIC METEOROLOGY|EarthCube,9/15/2015,8/15/2017,Lixin Lu,CO,Colorado State University,40.573436,-105.086547,Continuing grant,Nicholas Anderson,4/30/2020,"$648,866.00 ",Stephen Saleeby,lixin.lu@colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,GEO,1525|8074,4444|7433,"The impacts of clouds and aerosols on terrestrial carbon and water cycles and the resultant feedbacks to atmospheric processes are core in understanding land-atmosphere coupling.  This project will advance our understanding of vegetation-CO2-aerosol-cloud interactions, and improve the representation of CO2- and aerosol- induced feedbacks within a regional-scale modeling system.  This study will use outreach to broaden K-12 education and the inform the public on these important interactions to help us better understand the earth's climate system.    This study will merge the existing CSU-RAMS coupled biosphere-atmosphere modeling system (SiB-RAMS) with the cloud-resolving Aerosol-RAMS (that includes direct and indirect effects) to form an integrated, process-based Vegetation-Aerosol-Cloud modeling system (VAC-RAMS).  This will allow us to better understand spatial and temporal variability in land surface fluxes of energy, water, and CO2, induced by clouds, aerosols and cloud-aerosol interactions.  The study will also identify ecosystem feedbacks that are critical to cloud-aerosol interactions and quantify these feedbacks using VAC-RAMS and observations from a 2007 field campaign.  This will allow the investigators to assess the importance of aerosol forcing on clouds through biophysical and biogeochemical pathways.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1465216,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1465216
1661663,"SI2, CSSI",SI2,SI2-SSI: Lidar Radar Open Software Environment (LROSE),SI2-SSI: Lidar Radar Open Software Environment (LROSE),One organization,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/15/2016,11/28/2016,Michael Bell,CO,Colorado State University,40.573436,-105.086547,Standard Grant,Stefan Robila,7/31/2020,"$2,499,996.00 ",,mmbell@hawaii.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,CSE,1525|8004|8074,4444|7433|8004|8009|9150,"Modern radars and lidars are a diverse class of instruments, capable of detecting molecules, aerosols, birds, bats and insects, winds, moisture, clouds, and precipitation. Scientists and engineers use them to perform research into air quality and pollution, dangerous biological plumes, cloud physics, cloud extent, climate models, numerical weather prediction, road weather, aviation safety, severe convective storms, tornadoes, hurricanes, floods, and movement patterns of birds, bats and insects. Radars and lidars are critical for protecting society from high impact weather and understanding the atmosphere and biosphere, but they are complex instruments that produce copious quantities of data that pose many challenges for researchers, students, and instrument developers. This project will develop a new set of tools called the Lidar Radar Open Software Environment (LROSE) to meet these challenges and help address the 'big data' problem faced by users in the research and education communities. This project will open new avenues of scientific investigation, including data assimilation to improve weather forecasts, and help to maximize returns on NSF investments in weather and climate research by providing better software tools to researchers, students, and educators. Improving the effectiveness of NSF research will provide significant scientific and societal benefits through an improved understanding of many diverse scientific topics that are relevant to public safety, national defense, and the global economy.  The LROSE project will develop a 'Virtual Toolbox' with a set of software tools needed for a diverse set of scientific applications. LROSE will be packaged so that it can be run on a virtual machine (VM), either locally or in the cloud, and stocked with core algorithm modules for those typical processing steps that are well understood and documented in the peer-reviewed literature. LROSE will enable the user community to use the core toolset to develop new research modules that address the specific needs of the latest scientific research. Through the VM Toolbox and a core software framework, other developers of open-source radar software can then provide their own compatible software tools to the set. By combining the open source approach with recent developments in virtual machines and cloud computing, we will develop a system that is both highly capable and easy to run on virtually any hardware, without the complexity of a compilation environment. The LROSE project will build on existing prototypes and available software elements, while facilitating community development of new techniques and algorithms to distribute a suite of documented software modules for performing radar and lidar analysis. These modules will each implement accredited scientific methods referencing published papers. The infrastructure and modules will allow researchers to run standard procedures, thereby improving the efficiency and reproducibility of the analyses, and encourage researchers to jointly develop new scientific approaches for data analysis. The use of collaborative open source methods will lead to a suite of available algorithmic modules that will allow scientists to explore radar and lidar data in new, innovative ways. Researchers will benefit from the improved toolset for advancing understanding of weather and climate, leading to a positive outcome in the advancement of scientific knowledge and societal benefits.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1661663,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1661663
1664198,"SI2, CSSI",SI2,SI2-SSI: Lightweight Infrastructure for Land Atmosphere Coupling (LILAC): A Tool for Easy Integration of the Community Land Model into Multiple Modeling Systems,SI2-SSI: Lightweight Infrastructure for Land Atmosphere Coupling (LILAC): A Tool for Easy Integration of the Community Land Model into Multiple Modeling Systems,One organization,OAC,Software Institutes|CR|Earth System Models|EarthCube,10/1/2017,9/15/2017,A Denning,CO,Colorado State University,40.573436,-105.086547,Standard Grant,Vipin Chaudhary,9/30/2020,"$1,600,000.00 ",L. Darrell Whitley,denning@atmos.colostate.edu,601 S Howes St,Fort Collins,CO,805232002,9704916355,CSE,8004|8012|8074,026Z|4444|7433|8004|8009,"Everyone on Earth lives on the ground, so interactions between the atmosphere and the land surface are a critically important part of the climate system and understanding these interactions is important for weather prediction, agriculture, and urban water management. Earth System Models (ESMs) are complex software systems representing complex natural systems. They are critical tools for diagnosing, understanding, and predicting interactions and change in the atmosphere, oceans, and land ecosystems. This project will develop a new software system for coupling the land and atmosphere components of Earth System models, specifically for the most widely-used climate model in the world: the Community Earth System Model (CESM). The new system will be capable of simulating climates near the ground including exchanges of heat, water ,and carbon between vegetated land and the air as well as streamflow and soil moisture. As an officially-supported component of CESM, it will be used by thousands of scientists and students around the world. Unlike its predecessor, the new system will be able to simulate small areas at high resolution for important applications and testing. The project will also support a computer science graduate student as well as academics and scientists who will help develop and test the software. The PIs will engage a global community of software developers and users through a series of workshops and webinars as well as through professional societies and publications. The PIs recognize the chronic under-representation of women and ethnic minorities in both Computer Science and Atmospheric Science. To address this, they will host a computer science summer camp for middle school students from underrepresented groups (URGs), and close collaboration with existing climate courses for K-12 teachers, science outreach in K-12 schools, and a highly successful REU-Site operated by the PI. This project will dramatically improve the usability of the most widely-used climate model in existence. Hundreds of developers and thousands of users around the world will benefit from the far greater flexibility and use cases for this model. The Community Land Model will be coupled to a much greater range of atmospheric codes for weather prediction, air quality applications, and climate projections that enhance the quality of life for people everywhere.         The Community Earth System Model CESM) is a uniquely open ESM with a distributed community of hundreds of developers and thousands of users around the world. Compared to other ESMs, CESM is the ""Linux of climate models."" The land component of CESM, the Community Land Model (CLM), has its own vibrant and diverse user and development community, which has supported the construction of a particularly comprehensive terrestrial system model. It includes a rich array of processes that enable examination of the physical, biological, and chemical processes by which natural terrestrial ecosystems and human-managed land affect and are affected by climate and weather. CESM can only be run globally, but there is widespread interest in coupling CLM to alternative high-resolution atmosphere models to study the challenging scientific problems that exist at the interface between small and large spatial scales. A barrier to this research, however, is that CLM cannot readily be coupled to alternative atmosphere models. The CLM coupling interface only supports communication with the CESM coupling infrastructure (CPL7), which imposes strict requirements on how an atmospheric component can communicate with CLM. One key requirement is for the atmosphere model to complete a full time step before coupling can occur. This requirement necessitates significant refactoring of many atmospheric models in order for them to couple to CLM via CPL7. In addition, the tools to build and configure CLM are currently difficult to use outside of the CESM context. For all of these reasons, CLM has never been coupled to alternative atmospheric models in a sustainable fashion. Colorado State University (CSU), in partnership with the National Center for Atmospheric Research (NCAR), proposes to develop a Lightweight Infrastructure for Land-Atmosphere Coupling (LILAC) that will significantly simplify the coupling of CLM to alternative atmospheric models. The LILAC coupler and the associated proposed streamlining and simplification of the CLM tool chain will be developed and tested with a prototype high-resolution atmosphere model, the CSU SAM Cloud Resolving Model, and will be extended for use with any arbitrary Target Atmosphere Model. The development of LILAC and associated tools will enable numerous groups to couple CLM to their atmospheric models, and to quickly update to new state-of-the-art CLM model versions as they become available. This will open up new avenues of land-atmosphere research that can exploit the combined biogeophysical and biogeochemical capabilities of CLM with the strengths of high-resolution atmosphere models. It will enable research into land-atmosphere interactions across a variety of scales, ranging from turbulence-resolving simulations of tower and aircraft data to cloud-resolving simulations to study how small-scale land features such as hillslopes, valleys, lakes, rivers, urban areas and farms conspire to alter surface climate and atmospheric boundary layer characteristics to continental-scale simulations of the impact of land cover and land use change on weather and climate.   This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer & Information Science and Engineering and the Office of Polar Programs and Division of Atmospheric and Geospace Science in the Directorate for Geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664198,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664198
1740648,IA,IA,Collaborative Proposal: EarthCube Integration: Pangeo: An Open Source Big Data Climate Science Platform,Collaborative Proposal: EarthCube Integration: Pangeo: An Open Source Big Data Climate Science Platform,Collaborative,OCE,OCE|EarthCube,9/1/2017,8/21/2017,Ryan Abernathey,NY,Columbia University,40.807536,-73.962573,Standard Grant,Baris M. Uz,8/31/2020,"$736,713.00 ",Naomi Henderson|Richard Seager|Michael Tippett|Chiara Lepore,ra2697@columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,6899|8074,026Z|7433,"Climate, weather, and ocean simulations (Earth System Models; ESMs) are crucial tools for the study of the Earth system, providing both scientific insight into fundamental dynamics as well as valuable practical predictions about Earth's future. Continuous increases in ESM spatial resolution have led to more realistic, more detailed physical representations of Earth system processes, while the proliferation of statistical ensembles of simulations has greatly enhanced understanding of uncertainty and internal variability. Hand in hand with this progress has come the generation of Petabytes of simulation data, resulting in huge downstream challenges for geoscience researchers. The task of mining ESM output for scientific insights  has now itself become a serious Big Data problem. Existing Big Data tools cannot easily be applied to the analysis of ESM data, leading to a building crisis across a wide range of geoscience fields. This is exactly the sort of problem EarthCube was conceived to address. The project will integrate a suite of open-source software tools (the ""Pangeo Platform"") which together can tackle petabyte-scale ESM datasets. Additionally, training and educational materials for these tools will be developed, distributed widely online, and integrated into existing educational curricula at Columbia. A workshop at NCAR in the final year will help inform the broader community about Pangeo. Collaborators at other US climate modeling centers will encourage adoption and participation in the Pangeo project by their scientists. Beyond climate and related fields, multidimensional numeric arrays are common in many fields of science (e.g. astronomy, materials science, microscopy). However, the dominant Big Data software stack (Hadoop) is oriented towards tabular text-based data structures and cannot easily ingest petabyte scale multidimensional numeric arrays. The proposed work thus has potential to transform Data Science itself, enabling analysis of such datasets via a novel, highly scalable, highly flexible tool with a syntax familiar to disciplinary researchers.  The core technologies are the python packages Dask, a flexible parallel computing library which provides dynamic task scheduling, and XArray, a wrapper layer over Dask data structures which provides user-friendly metadata tracking, indexing, and visualization. These tools interface with netCDF datasets and understand CF conventions. They will be brought to bear on four high impact Geoscience Use Cases in atmospheric science, land-surface hydrology, and physical oceanography. Disciplinary scientists will define workflows for each use case and interact with computational scientists to demonstrate, benchmark, and optimize the software. The resulting software improvements will be contributed back to the upstream open source projects, ensuring long-term sustainability of the platform. The end result will be a robust new software toolkit for climate science and beyond. This toolkit will enhance the Data Science aspect of EarthCube. Implementation of these tools on the cloud will also be tested, taking advantage of agreement between commercial cloud service providers and NSF for the BIGDATA solicitation. ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740648,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740648
1740663,IA,IA,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative,ICER,EarthCube,9/1/2017,9/13/2017,Kerstin Lehnert,NY,Columbia University,40.807536,-73.962573,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$74,287.00 ",Stephen Richard,lehnert@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,7433,"Data heterogeneity and accessibility are major barriers to scientific progress. Many community curated data repositories (CCDRs) have emerged in the paleogeosciences in response to the needs of their scientific communities, but these CCDRs are not well integrated. This project seeks to transform geoscientific research by breaking down the barriers among the CCDRs that serve geoscientists. All participating resources are closely engaged with their respective disciplinary communities and each is mobilizing data from its communities; the key need is to facilitate data interchange among CCDRs. The work will align several major CCDRs using a system that develops new shared services that rely on common standards, and demonstrates the kinds of new scientific insights that become possible with an integrated geoscientific infrastructure.  This collaborative project will accomplish the following: 1) A survey of existing data structures and standards, their suitability for paleogeoscience CCDRs and alignment with requirements identified by the paleogeosciences research coordination network, and their degree of adoption. This will lead to recommendations for adoption by participating resources (EarthChem, Flyover Country, IODP, LacCore/CSDCO, LinkedEarth, Neotoma) and documentation written for geoscientific audiences. 2) Alignment of participating CCDRs to recommended standards and development of a common API that will allow data exchange among CCDRs and to third-party users. 3) Development of an Annotation Engine, which will provide a credentialed, crowd-sourced system for scientists to flag changes to datasets, to connect datasets post hoc, to add context to legacy data, and to provide link-back notification among CCDRs when linked dataset attributes change. Annotation Engine will be embedded into existing scientific CCDR-based workflows, minimizing disruption to users. 4) Development of GeoNoteBase to enable scientists to generate citeable, reproducible workflows that draw information from across data resources, with workflows made available through keyword searches, with full attribution. This is a pilot effort to begin some of the work Through two pilot scientific projects, THROUGHPUT will test and evaluate these new capabilities and demonstrate kinds of new scientific insights that can be gained through integration.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740663,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740663
1835769,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: HDR Elements: Software for a new machine learning based parameterization of moist convection for improved climate and weather prediction using deep learning,Collaborative Research: HDR Elements: Software for a new machine learning based parameterization of moist convection for improved climate and weather prediction using deep learning,Collaborative,OAC,DATANET|EarthCube,10/1/2018,8/13/2018,Pierre Gentine,NY,Columbia University,40.807536,-73.962573,Standard Grant,Amy Walton,9/30/2021,"$307,426.00 ",,pg2328@columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,CSE,7726|8074,062Z|077Z|7923,"This project targets a difficult problem in weather and climate prediction -- the representation of convection.  Accurate representation of convection is important, since a majority of current model predictions depend on it.  Unraveling the physics involved in convective conditions, clouds and aerosols may take years of modeling to fully understand; however, a set of machine learning techniques, known as ""neural net techniques"", may provide enhanced predictability in the interim, and this project explores their potential.  The project develops a Python library enabling the use of machine learning (artificial neural networks) in a broad range of science domains. The focus is on integration of convection and cloud formation within larger-scale climate models, with the Community Earth System Model (CESM) as an initial target.  The project develops a new set of machine learning climate model parameterizations to reduce uncertainty in weather and climate predictions.  The neural networks will be trained on high-fidelity simulations that explicitly resolve convection.  Two types of high-resolution simulations will be used for training the neural networks: 1) an augmented super-parameterized simulation, and 2) a full Global Cloud Resolving Model (GCRM) simulation based on the ICOsahedral Non-hydrostatic (ICON) modelling frameworks provided by the Max Planck Institute, using initial 5km horizontal resolution.  The effort has the potential to increase understanding of convection dynamics and processes across scales, and could potentially be implemented to address other scale problems as well, where it is too computationally costly or impractical to represent processes occurring at much finer scales than the main grid resolution.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835769,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835769
1338760,WORKSHOP,WORKSHOP,Collaborative Research: EarthCube End-User Workshop: Deep Seafloor Processes and Dynamics,Collaborative Research: EarthCube End-User Workshop: Deep Seafloor Processes and Dynamics,Collaborative,OCE,EarthCube,4/15/2013,4/5/2013,Vicki Ferrini,NY,Columbia University,40.807536,-73.962573,Standard Grant,Eva E. Zanzerkia,3/31/2014,"$9,564.00 ",,ferrini@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,0000|7433|OTHR,"The seafloor serves and the primary conduit for mass and heat transfer between the sub-seafloor and the overlying ocean water column, with both operating on vastly different time and mass scales. Dynamics at this interface drive global biogeochemical and geochemical elemental cycles, control global ocean chemistry, and shape the atmosphere and climate systems. Deep sea ecosystems also host some of the most diverse and extreme ecosystems including those inhabiting hydrothermal vents, cold seeps, mid-ocean ridges, ridge flanks, and plate margins. Without data from a wide variety of disciplines, such as geology, petrology, geophysics, hydrogeology, and micro/macro/evolutionary biology, it is not possible to realistically model these important systems and understand the complex interactions between their various physical, chemical, and biological components. Instrumental to understanding processes and dynamics of the deep sea requires integration of the disparate datasets and models that represent and predict the behavior of the components of this complex, important system. The goal of this workshop is to surface requirements in the field of deep sea processes for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~55 oceanographers from across the relevant disciplines. It will also include cyber/computer science experts. Together workshop participants will collectively define future science goals in this important scientific area and focus on identifying the most critical, widespread cyberinfrastructure and data management issues and problems presently holding back scientific advances in deep sea science in order to guide the development of NSF EarthCube cyberinfrastructure. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers to enable more interdisciplinary research to take place. Workshop participants will address topics such as science drivers in deep sea process research in the next 15 years, data and data management needs and problems, and software and visualization needs to help model and understand data. Broader impacts of the work include support of an organization in an EPSCoR state, support of two PIs whose gender is under-represented in the sciences and engineering, and engagement of early career scientists. A virtual component of the workshop will be held to help broaden participation beyond those present on-site.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338760,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338760
1440351,RCN,RCN,Earthcube RCN:  iSAmplEs:  The Internet of Samples in the Earth Sciences,Earthcube RCN:  iSAmplEs:  The Internet of Samples in the Earth Sciences,One organization,ICER,EarthCube,9/1/2014,7/28/2018,Kerstin Lehnert,NY,Columbia University,40.807536,-73.962573,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$299,965.00 ",Yue Cai,lehnert@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,7433,"Across many Earth Science disciplines, research depends on the availability of representative samples collected above, at, and beneath Earth?s surface, on the moon and in space, or generated in experiments. These samples are fundamental references that are studied to generate new knowledge about the earth and the entire universe and a deeper understanding of the processes that created and shaped it, the availability of natural resources and the risk of natural hazards. Many samples have been collected at great cost and with substantial difficulty, are rare or unique and irreplaceable. The use of information technology and the internet to make these samples easily accessible, to ensure persistent access to relevant sample metadata, to allow unambiguous linking of the physical objects to the digital data in a distributed data infrastructure, will have a broad impact across the entire Earth Sciences. It will open new opportunities to reexamine existing samples in response to new societal issues, environmental concerns, scientific interpretations, and analytical techniques. The activities of this coordination network will allow domain scientists, curators, and computer and information scientists to learn from each other about the requirements of physical and digital sample and collection management and to articulate a vision of and a path forward toward an Internet of Samples in the Earth Sciences.  The EarthCube Research Coordination Network iSamplES (Internet of Samples in the Earth Sciences) is intended to advance the use of innovative cyberinfrastructure to connect physical samples and sample collections across the Earth Sciences with digital data infrastructures to revolutionize their utility for science. The ultimate goal of this RCN is to dramatically improve the discovery, access, sharing, analysis, and curation of physical samples and the data generated by their study for the benefit of science and society as part of the EarthCube program. In order to work toward this objective, the project will help build, grow, and foster domain scientists, curators of sample repositories and collections, computer and information scientists, software developers and technology innovators to engage in and collaborate on defining, articulating, and addressing the needs and challenges of physical samples as a critical component of digital data and information infrastructures (theme 1: socialization). The RCN will compile information about existing resources (technologies, architectures, tools, profiles, workflows) that facilitate the management of samples, sample collections, and sample-based data in the field, in the lab, in repositories, in data systems and scientific publications, and identify critical gaps and needs (theme 2: knowledge creation). The RCN will recognize and promote best practices and standards for sample identification, documentation, citation, curation, and sharing across the entire Earth Science community as a foundation to building a shared cyber-infrastructure (theme 3: best practices).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440351,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440351
1321723,WORKSHOP,WORKSHOP,EarthCube Domain End-User Workshop: Community-Based Cyberinfrastructure for Petrology and Geochemistry,EarthCube Domain End-User Workshop: Community-Based Cyberinfrastructure for Petrology and Geochemistry,One organization,EAR,EarthCube,2/15/2013,2/11/2013,Kerstin Lehnert,NY,Columbia University,40.807536,-73.962573,Standard Grant,Jennifer Wade,1/31/2016,"$99,975.00 ",,lehnert@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,,"This workshop will bring together scientists from the petrology and geochemistry domains, data managers, sample curators, and cyberinfrastructure specialists to gather requirements and develop a vision for an advanced information and knowledge management system that will transform the way petrological and geochemical data and samples are acquired, analyzed, published, and re-used across the geosciences in the conduct of science. The outcomes of this workshop will provide guidance to the EarthCube initiative from the petrology-geochemistry community to design and develop the architecture of an Earth Science cyberinfrastructure that is aligned with the end-users' needs for data and sample access, software tools for data and metadata acquisition, workflow support, data analysis, data visualization, and modeling, computing capabilities, interoperability with data from other domains, as well as policies and procedures that address the scientists' concerns regarding, for example, data sharing, data citation, intellectual property, sample curation, and career advancement. The workshop report will be made widely accessible on the web.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1321723,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1321723
1354990,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,Collaborative,ICER,EarthCube,9/15/2013,8/12/2013,Robert Arko,NY,Columbia University,40.807536,-73.962573,Standard Grant,Barbara Ransom,8/31/2015,"$74,936.00 ",Suzanne Carbotte,arko@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,0000|7433|7916|OTHR,"This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures.  It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed.  Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details.  Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354990,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354990
1341929,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: SAVI:   Leveraging the Ocean Data Interoperability Platform (ODIP) for International Marine Science,EAGER: Collaborative Research: SAVI:   Leveraging the Ocean Data Interoperability Platform (ODIP) for International Marine Science,Collaborative,OCE,INTERNATIONAL COORDINATION ACT,8/1/2013,7/28/2014,Suzanne Carbotte,NY,Columbia University,40.807536,-73.962573,Continuing grant,James Holik,11/30/2015,"$99,967.00 ",Vicki Ferrini|Robert Arko,carbotte@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,1679,,"Leveraging US-R2R and EU-ODIP Informatics for International Marine Science   Since the 2009 launch, the Rolling Deck to Repository (R2R; http://rvdata.us/) program has made dramatic progress in routinely capturing shipboard data from the entire US academic fleet of 25 active service vessels. The R2R team has developed innovative technology to overcome the wide diversity of data practices, naming conventions and data formats across the fleet, which is managed by 18 independent operating institutions, large and small. As of September 2012, R2R had cataloged 11,026,386 data files from 2,644 cruises.   These NSF-funded accomplishments clearly benefit the US research community, but inquiries in the marine sciences are becoming more global in scope. While other nations and regions, notably the Europeans and the Australians, have also made tremendous progress in gathering data sets and placing them online, inevitably barriers to discovery and access can exist for a host of reasons, from basic awareness of resources to conflicts in search and access protocols, naming conventions and data formats.   Rather than continuing to independently develop (expensive) wheels, ODIP proposes to establish formal collaboration mechanisms to synchronize US, European and Australian efforts with a series of technical workshops designed to make practical advances, rather than a series of meetings in which PI?s stand up and make presentations. The Ocean Data Interoperability Platform (ODIP) has been launched as a combined US-EU-Australian project specifically because ocean data interoperability must span national boundaries.   R2R is a collaborative NSF program, funded through 31 August 2014, combining the efforts of LDEO, SIO, WHOI and FSU. The R2R team requests funding to (1) enhance the flexible discovery and harvesting of R2R content through implementing a ?Linked Data? approach; (2) map key vocabularies used by R2R to their EU counterparts, allowing users to search across US and EU resources using the terms with which they are familiar; and (3) upgrade existing R2R ISO 19115 metadata records to be compliant with the EU INSPIRE schema, which specifically addresses documenting quality. These efforts will be carried out in coordination with a number of other current interoperability projects, such as the work of the EarthCube Interoperability Concept Group, Unidata, and the COOPEUS project.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1341929,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1341929
1440221,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,Collaborative,ICER,EarthCube,9/1/2014,8/19/2014,Robert Arko,NY,Columbia University,40.807536,-73.962573,Standard Grant,Eva Zanzerkia,8/31/2017,"$369,179.00 ",Suzanne Carbotte|Kerstin Lehnert,arko@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,7433,"The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.  A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440221,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440221
1440229,BB,BB,EarthCube Building Blocks: Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models,EarthCube Building Blocks: Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models,Collaborative,ICER,EarthCube,9/1/2014,6/28/2016,Leslie Hsu,NY,Columbia University,40.807536,-73.962573,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$87,673.00 ",,hsu.leslie@gmail.com,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,7433,"The project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. Many challenges hinder the seamless integration of models with data. These challenges compel scientists to perform the integration process manually. The primary challenges are a consequence of the knowledge latency between model and data resources and others are derived from inadequate adoption and exploitation of information technologies. Knowledge latency challenges increase exponentially when a user aims to integrate long-tail data (data collected by individual researchers or small research groups) and long-tail models (models developed by individuals or small modeling communities).The goal of this research is to develop a framework rooted in semantic techniques and approaches to support ?long-tail? models and data integration. The vision is to develop a decentralized knowledge-based platform that can be easily adopted across geoscience communities comprising of individual and small group researchers.    This project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. The project will develop a knowledge framework to close the loop from models? queries back to data sources by first investigating the required concepts architecture for integrating two leading examples of long-tail resources in geoscience: Community Surface Dynamic Modeling System (CSDMS) and Sustainable Environment Actionable Data (SEAD). The project will also develop a context-based data model that provides an explicit interpretation of a metadata attribute. The researchers will capture the metadata concepts and semantic from various geo-informatics systems and provide tools for ensuring conceptual integration between the resources. Next, the project will develop a knowledge discovery tool that allows automated coupling of a model and data coming from different contributors. Finally, the project will provide a prototype physical implementation of the knowledge framework in CSDMS modeling framework to demonstrate how it can advance the seamless discovery, selection, and integration between models and data, and how to achieve dynamic reusability of resources across multiple Earth Science long-tail resources.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440229,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440229
950477,OTHER,OTHER,Geoinformatics Facilities Support:  Integrated Data Collections for the Earth & Ocean Sciences:  The Marine Geoscience Data System and the Geoinformatics for Geochemistry Progr,Geoinformatics Facilities Support:  Integrated Data Collections for the Earth & Ocean Sciences:  The Marine Geoscience Data System and the Geoinformatics for Geochemistry Progr,One organization,OCE,PETROLOGY AND GEOCHEMISTRY|MARINE GEOLOGY AND GEOPHYSICS|ANTARCTIC INSTRUM & SUPPORT|ANTARCTIC EARTH SCIENCES|POLAR CYBERINFRASTRUCTURE|OCE SPECIAL PROGRAMS|OCEAN DRILLING PROGRAM|EAR|OCE|CYBERINFRASTRUCTURE|GEOINFORMATICS|COLLABORATIVE RESEARCH|NSF Public Access Initiative|ICER|EarthCube,12/1/2010,10/28/2016,Kerstin Lehnert,NY,Columbia University,40.807536,-73.962573,Cooperative Agreement,Barbara Ransom,9/30/2017,"$12,623,687.00 ",William Ryan|Suzanne Carbotte|Vicki Ferrini|Karin Block|Stephen Richard,lehnert@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,1573|1620|1647|5112|5407|5418|5720|6898|6899|7231|7255|7298|7414|7699|8074,0000|1620|1647|1733|5936|5979|7433|OTHR,"This Cooperative Agreement creates a community-driven facility that consolidates a number of essential cyberinfrastructure activities in the solid-earth geosciences at the Lamont Doherty Earth Observatory of Columbia University.  It includes data repositories; author attribution schema; data management, discovery, and visualization tools; web portals and services; and the development and implementation of a sample unique-identifier registration system and database interoperability and metadata standards.  The project also includes the creation of geoscience education and outreach modules and workshops.  Goals of the facility are to serve the data management and discovery needs of the geoscience community and to provide direct public accessibility to NSF-funded data sets and associated data products. To achieve these goals, the collected activities are overseen by an external advisory structure of users and domain scientists in the geoinformatics, geophysics, igneous petrology, geochemistry, sedimentology, hydrothermal vent fluid, and polar geoscience communities and who work in concert with NSF to best serve community needs and monitor project performance.  The broader impacts of the resulting facility and its activities are broad and far-reaching in terms of building infrastructure for science and education in the solid-earth geosciences.  The resulting infrastructure and unified data submission procedures and standards will significantly advance the field of geoinformatics and provide essential tools for discovering data and combining disparate datasets such that more complex scientific problems can be tackled by providing a means to efficiently collect and view and model multiple datasets.  It also provides an important educational tool for students by allowing them to explore large amounts of data in creative ways.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=950477,https://www.nsf.gov/awardsearch/showAward?AWD_ID=950477
1541022,IA,IA,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Collaborative,ICER,EarthCube,9/1/2015,8/19/2015,Kerstin Lehnert,NY,Columbia University,40.807536,-73.962573,Standard Grant,Eva Zanzerkia,8/31/2019,"$418,614.00 ",Suzanne Carbotte|Vicki Ferrini|Leslie Hsu,lehnert@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,7433,"A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services.   Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541022,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541022
1340301,RCN,RCN,EarthCube RCN: C4P: Collaboration and Cyberinfrastructure  for Paleogeosciences,EarthCube RCN: C4P: Collaboration and Cyberinfrastructure  for Paleogeosciences,Collaborative,ICER,EarthCube,9/15/2013,3/5/2018,Kerstin Lehnert,NY,Columbia University,40.807536,-73.962573,Standard Grant,Eva Zanzerkia,8/31/2018,"$299,381.00 ",John Williams|Christopher Jenkins|Mark Uhen,lehnert@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,GEO,8074,7433,"This project establishes and operates the EarthCube Research Coordination Network (RCN) Collaboration and Cyberinfrastructure for Paleogeosciences (C4P) to advance the role of cyberinfrastructure (CI) in unraveling the large-scale, long-term evolution of the Earth-Life System through the study of the geological record.Paleogeosciences research into our large-scale, long-term Earth-Life system is an ambitious program that informs public debate on human stewardship of the earth and has - since its inception - caught public imagination on issues such as species survival under environmental changes. In the last decade, fresh discoveries, plus the application of new technologies of measurement, data analysis, and modeling have revitalized the science. Bringing to bear recent advances in computing and mathematics will further quicken the pace of discoveries, synthesis and publication in the science. This RCN intends to stimulate and grow CI-focused collaborations and partnerships among paleogeoscientists, paleobiologists, bioinformaticists, stratigraphers, geochronologists, geographers, data scientists, and computer scientists that will help dissolve existing intellectual barriers to dramatically improve the application of modern data management approaches, data mining technologies, and computational methods to better analyze the heterogeneous and sparse data of the Earth record in sediments, rocks, and ice within the paleogeosciences and other domains and disciplines.  Activities envisioned include a series of coordinated workshops and webinars, web-enabled networking, outreach events such as symposia and town-hall meetings, and cross-EarthCube coordination, and creation of an interoperable C4P resource catalog that will be integrated with other EarthCube resource inventories. High-priority themes in C4P are the management and representation of age and age uncertainty in data models and computation to advance interoperability among and analysis of time-referenced data types, the integration of physical samples into digital data infrastructure, and the need to properly track and attribute provenance of data to ensure trust in the data and credit to authors.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1340301,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1340301
1550337,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,Collaborative,OAC,Software Institutes|EarthCube,9/1/2016,8/19/2016,Marc Spiegelman,NY,Columbia University,40.807536,-73.962573,Standard Grant,Micah Beck,8/31/2019,"$245,093.00 ",,mspieg@ldeo.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,CSE,8004|8074,7433|8004|8009,"Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science.  They model the chemistry of melting of the interiors of planets as a result of heat flow within the body.  They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits.  They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles.  They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids.  Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies.   It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization.    This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics.  ENKI will provide software tools in computational thermodynamics and fluid dynamics.  It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks.  ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research.  ENKI development will be community driven.  Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples.  All software associated with this project will be released as open source.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550337,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550337
1740669,IA,IA,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative,ICER,OCE|EarthCube,9/1/2017,9/13/2017,Stephen Kuehn,WV,Concord University,37.424758,-81.006049,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$89,186.00 ",,sckuehn@concord.edu,P O Box 1000,Athens,WV,247121000,3043846318,GEO,6899|8074,026Z|7433|9150,"Data heterogeneity and accessibility are major barriers to scientific progress. Many community curated data repositories (CCDRs) have emerged in the paleogeosciences in response to the needs of their scientific communities, but these CCDRs are not well integrated. This project seeks to transform geoscientific research by breaking down the barriers among the CCDRs that serve geoscientists. All participating resources are closely engaged with their respective disciplinary communities and each is mobilizing data from its communities; the key need is to facilitate data interchange among CCDRs. The work will align several major CCDRs using a system that develops new shared services that rely on common standards, and demonstrates the kinds of new scientific insights that become possible with an integrated geoscientific infrastructure.  This collaborative project will accomplish the following: 1) A survey of existing data structures and standards, their suitability for paleogeoscience CCDRs and alignment with requirements identified by the paleogeosciences research coordination network, and their degree of adoption. This will lead to recommendations for adoption by participating resources (EarthChem, Flyover Country, IODP, LacCore/CSDCO, LinkedEarth, Neotoma) and documentation written for geoscientific audiences. 2) Alignment of participating CCDRs to recommended standards and development of a common API that will allow data exchange among CCDRs and to third-party users. 3) Development of an Annotation Engine, which will provide a credentialed, crowd-sourced system for scientists to flag changes to datasets, to connect datasets post hoc, to add context to legacy data, and to provide link-back notification among CCDRs when linked dataset attributes change. Annotation Engine will be embedded into existing scientific CCDR-based workflows, minimizing disruption to users. 4) Development of GeoNoteBase to enable scientists to generate citeable, reproducible workflows that draw information from across data resources, with workflows made available through keyword searches, with full attribution. This is a pilot effort to begin some of the work Through two pilot scientific projects, THROUGHPUT will test and evaluate these new capabilities and demonstrate kinds of new scientific insights that can be gained through integration.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740669,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740669
1740929,IA,IA,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative,ICER,OCE,9/1/2017,9/13/2017,Douglas Fils,DC,"Consortium for Ocean Leadership, Inc",38.900981,-77.028582,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$58,366.00 ",,dfils@oceanleadership.org,"1201 New York Avenue, N W.",Washington,DC,200056108,2024481236,GEO,6899,026Z|7433,"Data heterogeneity and accessibility are major barriers to scientific progress. Many community curated data repositories (CCDRs) have emerged in the paleogeosciences in response to the needs of their scientific communities, but these CCDRs are not well integrated. This project seeks to transform geoscientific research by breaking down the barriers among the CCDRs that serve geoscientists. All participating resources are closely engaged with their respective disciplinary communities and each is mobilizing data from its communities; the key need is to facilitate data interchange among CCDRs. The work will align several major CCDRs using a system that develops new shared services that rely on common standards, and demonstrates the kinds of new scientific insights that become possible with an integrated geoscientific infrastructure.  This collaborative project will accomplish the following: 1) A survey of existing data structures and standards, their suitability for paleogeoscience CCDRs and alignment with requirements identified by the paleogeosciences research coordination network, and their degree of adoption. This will lead to recommendations for adoption by participating resources (EarthChem, Flyover Country, IODP, LacCore/CSDCO, LinkedEarth, Neotoma) and documentation written for geoscientific audiences. 2) Alignment of participating CCDRs to recommended standards and development of a common API that will allow data exchange among CCDRs and to third-party users. 3) Development of an Annotation Engine, which will provide a credentialed, crowd-sourced system for scientists to flag changes to datasets, to connect datasets post hoc, to add context to legacy data, and to provide link-back notification among CCDRs when linked dataset attributes change. Annotation Engine will be embedded into existing scientific CCDR-based workflows, minimizing disruption to users. 4) Development of GeoNoteBase to enable scientists to generate citeable, reproducible workflows that draw information from across data resources, with workflows made available through keyword searches, with full attribution. This is a pilot effort to begin some of the work Through two pilot scientific projects, THROUGHPUT will test and evaluate these new capabilities and demonstrate kinds of new scientific insights that can be gained through integration.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740929,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740929
1440170,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,Collaborative,ICER,EarthCube,9/1/2014,8/19/2014,Douglas Fils,DC,"Consortium for Ocean Leadership, Inc",38.900981,-77.028582,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$189,416.00 ",,dfils@oceanleadership.org,"1201 New York Avenue, N W.",Washington,DC,200056108,2024481236,GEO,8074,7433,"The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.  A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440170,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440170
1245076,OTHER,OTHER,Collaborative Research: From Data to Users: A Prototype Open Modeling Framework,Collaborative Research: From Data to Users: A Prototype Open Modeling Framework,Collaborative,EAR,EarthCube,7/15/2012,7/20/2012,Richard Hooper,MA,Consortium of Universities for the Advancement of Hydrologic Sci,42.394434,-71.146102,Standard Grant,Barbara L. Ransom,6/30/2014,"$15,324.00 ",,richard.hooper@tufts.edu,150 Cambridge Park Drive,Cambridge,MA,21402479,3392215400,GEO,8074,0000|7433|7916|OTHR,"Because Earth is a complex coupled interacting system, where no one element is independent of any other, there are both pressing scientific and societal needs to improve our understanding how various physical, biological, and hydrological processes interact in surface Earth systems.  This requires the development of new and increasingly more sophisticated ways of mathematically describing these systems and improvements in software and user interfaces that will dramatically enhance our ability to simulate these systems to improve the accuracy and reliability of model predictions of weather, floods, droughts, and climate variability. Such improved models will allow researchers to make better use of available data across disciplines and improve theory and algorithms that are essential to understanding Earth system behavior. Unfortunately, at present there is significant overhead of time and effort needed for discovering, accessing, understanding, and preparing data required to populate these models, as well as long learning lead times on how to use presently available models, owing to their complexity.  This research overcomes some of these limitations by developing an innovative open modeling framework that can integrate data and models easily and is easy to use so that not only the research community and operational professionals can use it, but also policy makers and other interested parties. This EAGER award allows the construction of a prototype open meta-modeling framework that significantly reduces the time and effort on the part of users in the preparatory work for data and model comparisons, model testing and validations, for making fundamental knowledge discoveries in surface and ground water hydrological systems.  In this framework, components/modules interact via user-configured open interfaces that allow the addition and integration of hydrological models and data sources using a common meta-level architecture and scientific workflows. The proposed prototype is based on a recently completed modeling framework, HS-NWSRFS (Hydro-information System for improving the National Weather Service River Forecast System).  It represents a collaboration between investigators from three institutions, NASA, and NWS Ohio River Forecast Center (OHRFC). The funded effort will significantly expand the present code into an open community framework prototype.  Broader impacts of the work include interagency collaboration, improved hydrological forecasting for rivers, and support of a PI whose gender is under-represented in the sciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1245076,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1245076
1239703,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,Collaborative,EAR,EarthCube,4/1/2012,3/27/2012,Jennifer Arrigo,MA,Consortium of Universities for the Advancement of Hydrologic Sci,42.394434,-71.146102,Standard Grant,Barbara L. Ransom,12/31/2013,"$27,636.00 ",,jarrigo@cuahsi.org,150 Cambridge Park Drive,Cambridge,MA,21402479,3392215400,GEO,8074,7433|7916,"This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results. Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239703,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239703
1251557,WORKSHOP,WORKSHOP,EarthCube GEO Domain Workshop Proposal:   Envisioning a Digital Crust for Simulating Continental&#8208; Scale Subsurface Fluid Flow in Earth System Models,EarthCube GEO Domain Workshop Proposal:   Envisioning a Digital Crust for Simulating Continental&#8208; Scale Subsurface Fluid Flow in Earth System Models,One organization,EAR,EarthCube,9/1/2012,2/3/2015,Richard Hooper,MA,Consortium of Universities for the Advancement of Hydrologic Sci,42.394434,-71.146102,Standard Grant,Thomas Torgersen,2/28/2015,"$84,681.00 ",Ying Fan Reinfelder|Norman Jones,richard.hooper@tufts.edu,150 Cambridge Park Drive,Cambridge,MA,21402479,3392215400,GEO,8074,7433,"In order to advance the understanding of the critical zone and deeper crust and to better couple the exchange of mass and energy between the surface and the subsurface, this project will hold 3-day workshop to develop a long?]term vision of a digital representation of the continental crust of N. America and design concepts for prototype data model(s).  The digital catalog of crustal structure, composition and permeability (as well as parameters from which permeability could be inferred) define the mechanisms by which to integrate vast amounts of dcisparate data types and to construct a coherent, 3D picture of subsurface structure and material properties, so that we can begin to represent subsurface fluid flow in Earth system models and elucidate its critical controls in the evolution of the Earth system from the past to the present and the future.  Fluid circulation in the subsurface, from the critical zone to the deeper crust, plays an essential role in surface, near-surface, and crustal dynamics. In the critical zone (<50m), soil water is a ecologic filter and niche differentiator where energy is abundant, explaining patterns in plant distribution globally and locally; and shallow groundwater is a primary source for rivers, lakes and wetlands in dry seasons and regions, thereby sustaining and modifying land and aquatic ecosystems, influencing water quality, and buffering against droughts and temperature extremes. Deeper in the crust (<1km), the large sedimentary formations and fractured rocks hold the fresh?]water aquifers that support major societies in arid and semi-arid regions. In the deeper crust (>1km), fluid flow affects diagenesis, hydrocarbons, ore deposits, faulting, earthquakes, and geothermal fields and involves water, gas and hydrocarbon flow.   What are the flow paths through the soils and rocks? How fast are the flows and how long are the residence times? And how will they respond to changes in climate and land surface drivers? The answers depend on a quantitative description of the subsurface flow fields, driven by the hydraulic gradient but strongly controlled by the permeability of the Earth?fs material.  Creating a digital catalogue by which to reconstruct this poorly sampled region of the planet will enable multiple aspects of the Earth sciences to advance transformatively.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1251557,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1251557
1248152,OTHER,OTHER,Facilities Support: The CUAHSI Water Data Center,Facilities Support: The CUAHSI Water Data Center,One organization,EAR,HYDROLOGIC SCIENCES|INSTRUMENTATION & FACILITIES,4/1/2013,4/22/2016,Richard Hooper,MA,Consortium of Universities for the Advancement of Hydrologic Sci,42.394434,-71.146102,Cooperative Agreement,Russell C. Kelz,3/31/2017,"$2,685,070.00 ",Alva Couch|Diana Dalbotten|Antony Berthelote,richard.hooper@tufts.edu,150 Cambridge Park Drive,Cambridge,MA,21402479,3392215400,GEO,1579|1580,0,"This Cooperative agreement supports the Consortium for the Advancement of the Hydrologic Sciences (CUAHSI) to construct and maintain a web-accessible water-data center (WDC) that builds off the prototype Hydrologic Information System (HIS) developed at the University of Texas.  Over the next three years , WDC development will offer new access to water data holdings, discovery tools, archival and sharing/publishing capabilities and will build a consistent set of data format standards definitions, data format translators, analysis software tools, mobile platform applications and provide for user training and support.  WDC will provide access to a range of water data now held in a multitude of data formats and across numerous platforms with vastly different access tools.  Data to be ingested in WDC will include the data holdings of the USGS National Water Information Service, EPA and NOAAs National Climate Data Center (NCDC), other federal and state agency data holdings, and academic and private foundation water data holdings.  WDC will integrate the use of cloud computing and data services to facilitate data discovery and use and include tools for real time state-of-health monitoring of operational sensor networks.   The WDC concept directly addresses NSF data policies and will be integrated into in a growing network of geoscience information system services (e.g., Unidata, OpenTopography, EarthChem through participation in GEOs EarthCube initiative).  WDC PIs will continue international efforts for developing and adopting consistent data standards for hydrologic observation web-base publication through participation in international standards-setting bodies (e.g., the Open Geospatial Consortium (OGC) and the Global Earth Observation System of Systems (GEOSS)).  The PIs also plan a set of outreach activates focused on Native Americans (in collaboration with tribal college and governmental partners) for building and development of water management data tools in support of the tribal resources management needs.  ***",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1248152,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1248152
1829921,OTHER,OTHER,Collaborative Research: The role of a keystone pathogen in the geographic and local-scale ecology of eelgrass decline in the eastern Pacific,Collaborative Research: The role of a keystone pathogen in the geographic and local-scale ecology of eelgrass decline in the eastern Pacific,Collaborative,OCE,"BIOLOGICAL OCEANOGRAPHY|EDUCATION/HUMAN RESOURCES,OCE|EarthCube",9/1/2018,8/10/2018,C. Drew Harvell,NY,Cornell University,42.453449,-76.473503,Standard Grant,Daniel Thornhill,8/31/2021,"$408,947.00 ",Carla Gomes,cdh5@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,GEO,1650|1690|8074,006Z|1650|4444|7308|9117|9251,"Pathogens may be unrecognized key species in many ecosystems, causing massive impacts on other species and habitats despite the microscopic size of disease-causing organisms. Yet the triggers to disease epidemics likely involve complex interactions among changing environmental conditions and associated biological communities. In the ocean, understanding disease outbreaks has been hindered by inadequate knowledge of how these various influences interact to determine susceptibility and resilience to disease. This project integrates research in community and disease ecology with microbial genomics, geospatial analysis, and state-of-the-art computational approaches toward an unprecedented understanding of the causes and consequences of wasting disease in eelgrass, an important vegetation type supporting coastal and estuarine ecosystems throughout the northern hemisphere. The research advances frontiers in understanding the growing but poorly appreciated threat of marine diseases, how disease ecology interacts with environmental change, and its consequences for the extensive ecosystems and coastal communities that depend on eelgrass, across 23 degrees of latitude along the Pacific coast of North America. The research will inform better management of threatened seagrass ecosystems, which provide important services including fisheries habitat, erosion control, carbon storage, and capture of nutrient runoff. The research will foster integrative approaches in the next generation, including high school students, undergraduates, graduate students, and postdocs working on the project, and each investigator's institution will work to recruit participants from under-represented groups. Best practices developed under this award, including the Eelisa disease app and drone mapping, will be disseminated for broader surveillance of seagrass disease and coastal habitat quality by both professional and citizen scientists in coordination with the Global Ocean Observing System's (GOOS) develpoment of seagrass extent as an Essential Ocean Variable.  The triggers to marine disease epidemics are likely complex, and progress in understanding them has been hindered by a poor understanding of the multifaceted ecological context of the host-disease interaction. This project's overarching goal is to disentangle the web of direct and indirect interactions by which changing climate mediates prevalence of eelgrass wasting disease, and its consequences for threatened but important eelgrass ecosystems. The centerpiece is a comparative, cross-scale survey of eelgrass community composition, microbiome, and disease prevalence along thermal gradients of latitude and exposure to the ocean, providing the first coast-wide picture of disease dynamics in response to environmental change. In situ sampling will be linked to dynamics of eelgrass at landscape scales using unmanned aerial systems (drones) to quantify high-resolution changes in eelgrass extent and habitat quality. Experiments will test how the diverse biological community mediates impacts of the pathogen on eelgrass ecosystems.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1829921,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1829921
1440181,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Enabling Scientific Collaboration and Discovery through Semantic Connections,EarthCube Building Blocks: Collaborative Proposal: Enabling Scientific Collaboration and Discovery through Semantic Connections,Collaborative,ICER,EarthCube,9/1/2014,8/4/2014,Dean Krafft,NY,Cornell University,42.453449,-76.473503,Standard Grant,Eva Zanzerkia,7/31/2018,"$404,884.00 ",,dean.krafft@cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,GEO,8074,7433,"Data, information, ideas, and technologies diffuse through social and organizational networks, if the impediments to their adoption are low and the benefits of new approaches are clear. This project brings together the National Center for Atmospheric Research (NCAR), UNAVCO, and Cornell University to understand how to improve the processes of collaboration and resource sharing in the geosciences by demonstrating and encouraging the adoption of structured information systems rooted in common standards. Using two large geoscience research programs as case studies, this effort will demonstrate how semantic web and linked data technology can play an essential role in the coordination and organization of scientific virtual organizations and their products, thereby accelerating the pace of scientific discovery and innovation.    The researchers will use a well-developed open source web application as an integrating data layer to expose the informational relationships and organizational collaborations within the case studies. This project will be an exemplar of using linked data to support virtual organizations in the geosciences. These efforts will feed into new tools that leverage linked data to support information and data exchange, and will produce recommendations on engaging user communities in linked data projects. This project will provide insight into how the geosciences can leverage linked data to produce more coherent methods of information and data discovery for large multi-disciplinary projects and virtual organizations. They will use the open source VIVO software application to illustrate how linked data can transform scientific project communication and dissemination via front end discovery based on rich networked metadata. The VIVO platform provides new capabilities for researchers and educators to use structured, interpretable data, permitting direct interlinking of information and data across platforms and projects. The project will structure data into an ontology-based, standard data format (RDF) for re-use, leveraging web identifier and vocabulary structures that have been well developed and widely adopted in the geoscience and cyberinfrastructure communities.  ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440181,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440181
1722152,BB,BB,EarthCube Building Block:   GeoDataspace:   Simplifying Data Management for Geoscience Models,EarthCube Building Block:   GeoDataspace:   Simplifying Data Management for Geoscience Models,One organization,ICER,EarthCube,9/1/2016,5/15/2018,Tanu Malik,IL,DePaul University,41.925649,-87.654968,Standard Grant,Eva Zanzerkia,8/31/2018,"$209,153.00 ",,tanu@cdm.depaul.edu,1 East Jackson Boulevard,Chicago,IL,606042287,3123627595,GEO,8074,7433,"A big obstacle to such sharing is the inordinate amount of time and effort that must be spent in creating, communicating, receiving, and interpreting specifications of data, models, and associated knowledge. This inability to quickly and conveniently share is particularly a problem in computational geoscience, wherein scientists spend significant portions of their time managing the many input and output files that are typically associated with a model. When developing, testing, validating, and comparing models, particularly coupled models, the number of such data elements and the complexity associated with their management soon outgrows human memory capacity. The unfortunate consequence is that researchers often narrow the scope of a model analysis, compromise research quality, or conduct analysis within restricted teams. This pilot project will demonstrate a mechanism to overcome this challenge in the scientific community.  The GeoDataspace pilot will develop a new data-centric approach to describing models and associated data resources for computational geoscience. This new approach will both simplify model use and enhance the shareability, reusability, and reproducibility of models, data, and computations?properties widely sought by computational geoscientists. Specifically, the project will develop methods for defining, sharing, and accessing geounits, collections of descriptive metadata that define a m the entire collection of files needed to run a computational model, including details about the model run. In the case of files, processing and manipulation scripts, manifests, spreadsheets, or one-off databases, the encapsulation may consist simplify of the elements location and specification of each element.  The GeoDataspace team includes (a) experts in cyberinfrastructure, data management systems, and SaaS at UChicago; (b) experienced and leading geoscientists in four domains of solid earth, climate, hydrology, and space science, and a leading expert, as well as, geoscientist on model coupling frameworks. Together the team has identified a cross-cutting data management barrier that must be critically addressed in a domain-independent manner so as to extend capabilities to a broader set of geoscientists.All participating geoscientists are initiators, leaders, working-group chairs, and/or representatives of the five modeling communities we represent, including Computational Infrastructure for Geodynamics (CIG), Community Earth System Models (CESM), Consortium of Universities for the Advancement of Hydrological Science, Inc. (CUAHSI), and Community Coordinated Modeling Center (CCMC) at NASA, and finally Earth Systems Bridge (ESB), a community invested in developing model coupling frameworks. In total, the number of geoscientists either directly or indirectly involved in GeoDataspace is in the hundreds, if not thousands.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1722152,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1722152
1639759,BB,BB,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,Collaborative,ICER,EarthCube,9/1/2016,9/12/2018,Tanu Malik,IL,DePaul University,41.925649,-87.654968,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$783,999.00 ",Ian Foster,tanu@cdm.depaul.edu,1 East Jackson Boulevard,Chicago,IL,606042287,3123627595,GEO,8074,7433,"Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility.   GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639759,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639759
1661918,IA,IA,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,Collaborative,ICER,EarthCube,9/1/2016,1/27/2017,Tanu Malik,IL,DePaul University,41.925649,-87.654968,Standard Grant,Eva Zanzerkia,8/31/2018,"$82,994.00 ",,tanu@cdm.depaul.edu,1 East Jackson Boulevard,Chicago,IL,606042287,3123627595,GEO,8074,7433,"The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.  EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1661918,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1661918
1313866,WORKSHOP,WORKSHOP,Collaborative Project: EarthCube Education End-User Workshop,Collaborative Project: EarthCube Education End-User Workshop,Collaborative,ICER,EarthCube,2/1/2013,1/17/2013,Kim Kastens,MA,Education Development Center,42.370536,-71.218911,Standard Grant,Jill L. Karsten,1/31/2014,"$46,053.00 ",Ruth Krumhansl,kastens@ldeo.columbia.edu,43 Foundry Avenue,Waltham,MA,24538313,6176182227,GEO,8074,,"This award is being used to convene a workshop of ~40 participants to define end-user needs related to geoscience education within the EarthCube initiative.  The workshop brings together disciplinary faculty in the geosciences, educators experienced in teaching with geoscience data and developing associated curricula, representatives of NSF-sponsored research programs involved with generation of large data sets, as well as technologists, STEM education researchers, and learning scientists.  The workshop is being held at the Scripps Forum (Scripps Institution of Oceanography) during the Spring of 2013.  The workshop seeks to explore both the educational opportunities offered through the cyberinfrastructure capabilities of the EarthCube program and identify the educational needs for preparing undergraduate students and faculty to be the future contributors to the scientific research enabled by EarthCube.  A major goal of this workshop is to establish an initial roadmap for educational activities that should be associated with or enabled by EarthCube.  The workshop will consider the educational and instructional strategies not only to prepare students in undergraduate programs to be technologically-savvy users of EarthCube data and models, but also to build the future scientific capacity to advance Earth systems scientific research.  Consideration will also be given to how EarthCube may serve as a platform for advancing STEM education research.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1313866,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1313866
1213026,"DIBBS, BIGDATA, III",DIBBS,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,Collaborative,IIS,INFO INTEGRATION & INFORMATICS|ICER,10/1/2012,12/7/2018,Naphtali Rishe,FL,Florida International University,25.756576,-80.373949,Standard Grant,Maria Zemankova,9/30/2019,"$1,379,000.00 ",Tao Li,rishen@cs.fiu.edu,11200 SW 8TH ST,Miami,FL,331990001,3053482494,CSE,7364|7699,7364|7433|7925|9251,"Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.  This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1213026,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1213026
1540700,IA,IA,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Roy Nelson,FL,Florida State University,30.441878,-84.298489,Standard Grant,Eva E. Zanzerkia,2/28/2019,"$154,360.00 ",,gnelson@floridamuseum.ufl.edu,"874 Traditions Way, 3rd Floor",TALLAHASSEE,FL,323064166,8506445260,GEO,8074,7433,"Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.  The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist.  The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540700,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540700
1541028,IA,IA,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,Collaborative,ICER,EarthCube,9/1/2015,3/2/2018,Dena Smith,CO,Geological Society of America Today,40.03744,-105.250421,Standard Grant,Eva Zanzerkia,8/31/2018,"$82,734.00 ",,dena@colorado.edu,3300 PENROSE PL,Boulder,CO,803011806,3033571000,GEO,8074,7433,"Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.  The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist.  The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541028,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541028
1206274,OTHER,OTHER,"Coordinating Office for Research on the Sedimentary Crust, Deep-Time and the Earth-Life System","Coordinating Office for Research on the Sedimentary Crust, Deep-Time and the Earth-Life System",One organization,EAR,GLOBAL CHANGE|SEDIMENTARY GEO & PALEOBIOLOGY,3/15/2013,8/3/2016,Lisa Park Boush,CO,Geological Society of America Today,40.03744,-105.250421,Cooperative Agreement,Judith Ellen Skog,1/31/2017,"$975,707.00 ",Lisa Park Boush|Philip Gingerich|Howard Harper|Martin Perlmutter,lisa.park_boush@uconn.edu,3300 PENROSE PL,Boulder,CO,803011806,3033571000,GEO,1577|7459,1304|7459|EGCH,"This grant supports a sedimentary geology, deep-time, and Earth-life system science community coordinating Office (STEPPE, Sedimentary geology, Time, Environment, Paleontology, Paleoclimate, and Energy) to facilitate collaboration and communication among existing and new initiatives, build capacity, and promote research into the deep-time record of Earth processes. The Geological Society of America (GSA), the Society for Sedimentary Geology (SEPM), and the Paleontological Society (PS) will provide financial and in-kind support to the office.  Intellectual Merit and Broader Impacts: To predict the boundaries for human life on this planet--those imposed by climate change, energy, water issues, and our impact on the biosphere--we must have an integrated, deep-time perspective, or our vision will be incomplete, and our ability to make predictions about natural and human-made events and outcomes will be limited. Single sub-disciplines or even whole disciplines cannot provide the breadth and depth of information needed to address real-world issues. All sedimentary crust research groups examine different parts of a larger research problem, and current initiatives reflect different perspectives and/or emphases for sedimentary-crust research, especially in the deep past. It is clear that broad segments of the  community is working toward an integrated approach, but lack a platform to coordinate and integrate these efforts. The 2011 National Research Council report on Understanding Earth's Deep Past, states that it is essential to make ""A transition from single researcher or small group research efforts to a much broader-based interdisciplinary collaboration of observation-based scientists with climate modelers for team-based studies of important paleoclimate events,"" and this requires coordination. The STEPPE office will provide that platform and that coordination.  The STEPPE office will help facilitate the EarthCube vision for geoscience cyberinfrastructure by bringing together various relevant geoinformatics efforts, and work to ensure that other cyberinfrastructure needs are articulated and coordinated. In addition, the STEPPE office will work with the community and with education partners to develop state-of-the-art education and outreach programs involving K-12, decision makers, and the general public through formal and informal educational activities. The STEPPE office will enhance communication between the research community and State, Federal and international agencies and organizations, including industry, in order to build capacity and voice community perspectives. The office will ensure that the independence and importance of existing and planned community initiatives is maintained, and also enhanced through this group effort. The office will promote individual initiatives and coordinate efforts among them. Better communication, coordination and collaboration will help to develop more effective research strategies for the entire community and help meet goals of the 2009 NSF GeoVision Report. The office will help the community develop new strategies and tools for understanding Earth-environment-life relationships with greater sophistication, and for application to our understanding of Earth-system processes.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1206274,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1206274
1740693,IA,IA,EarthCube Integration: CyberWay--Integrated Capabilities of EarthCube Building Blocks for Facilitating Cyber-based Innovative Way of Interdisciplinary Geoscience Studies,EarthCube Integration: CyberWay--Integrated Capabilities of EarthCube Building Blocks for Facilitating Cyber-based Innovative Way of Interdisciplinary Geoscience Studies,One organization,AGS,EarthCube,10/1/2017,9/6/2017,Liping Di,VA,George Mason University,38.831488,-77.311944,Standard Grant,Subhashree (Shree) Mishra,9/30/2019,"$1,100,000.00 ",David Bromwich|Genong Yu|James Kinter,ldi@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,7433,"This NSF EarthCube project, termed ""CyberWay,"" facilitates interdisciplinary geoscience research with data/service/product interoperability in discovery, access, and data processing, enabling the work on grand challenge geoscience questions from a multidisciplinary perspective, and fostering interoperability and collaboration across existing EarthCube building blocks.  This project seeks to build a system of systems, named ""CyberWay,"" through integrating the capabilities and systems of multiple existing EarthCube building blocks, particularly BCube, CyberConnector, CHORDS, and GeoWS. BCube enables broker-based data discovery. CyberConnector unifies pre-processing, production virtualization, geoprocessing modeling, and data discovery, access, and interoperability through open geospatial standards.  CHORDS connects small instruments and sensors to the Internet in real time. GeoWS provides a framework and infrastructure for data management and distribution with unified RESTful interfaces.  Selected capabilities from other building blocks will be also integrated through standard service interfaces. Additional services will be developed to meet specific requirements identified for particular geoscience use cases.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740693,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740693
1342148,WORKSHOP,WORKSHOP,EarthCube Domain End-User Workshop:  Engaging the Atmospheric Cloud/Aerosol/Composition Community,EarthCube Domain End-User Workshop:  Engaging the Atmospheric Cloud/Aerosol/Composition Community,One organization,AGS,EarthCube,7/1/2013,6/26/2013,Liping Di,VA,George Mason University,38.831488,-77.311944,Standard Grant,Sylvia A. Edgerton,6/30/2014,"$99,850.00 ",Athanasios Nenes|Akua Asa-Awuku|Stefan Falke,ldi@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,1524|7433,"A workshop will be held to support U.S. scientists who are conducting research on atmospheric aerosol and cloud interactions to assist with forming a community consensus on what capabilities and functional requirements might be needed to assist with the development of a common cyber-based infrastructure for the geosciences.  This workshop is part of a series of geoscience domain end-user workshops to solicit the needs and requirements from end-user groups of EarthCube so that those needs and requirements can be addressed in the EarthCube design and implementation.  EarthCube is a community-driven activity sponsored through a partnership between the NSF Directorate of Geosciences and Office of Cyberinfrastructure to transform the conduct of geosciences research and education.  EarthCube aims to create a well-connected and facile environment to share data and knowledge in an open, transparent, and inclusive manner, thus accelerating the ability of the geosciences community to understand and predict the Earth system.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1342148,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1342148
1343759,"CC, GOVERNANCE",CC,Earth Cube Conceptual Design: Developing a Data-Oriented Human-centric Enterprise Architecture for EarthCube,Earth Cube Conceptual Design: Developing a Data-Oriented Human-centric Enterprise Architecture for EarthCube,One organization,ICER,EarthCube,9/15/2013,8/1/2014,Chaowei Yang,VA,George Mason University,38.831488,-77.311944,Standard Grant,Eva E. Zanzerkia,8/31/2016,"$288,272.00 ",Chen Xu,cyang3@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,7433,"This EarthCube enterprise conceptual architecture approach looks to develop a data-driven and human-centric EarthCube enterprise architecture for achieving the goal of EarthCube as a community-driven activity to transform the conduct of geoscience research and education. The proposed EarthCube enterprise architecture will have geoscientists and domain experts at its center and facilitate them to communicate and collaborate through data sharing, and ultimately bring geosciences forward in a holistic fashion. This project seeks to design a conceptual architecture that can bring geoscientists, computing scientists, and social scientists together to collaborate on networks of data, technology, applications, business models, and stakeholders. The design approach is guided by the following principles. It designs a new architecture as well as operational procedures for achieving the architecture based on comprehensive review and assessment of current enterprise architectures. Second, it suggests several important mechanisms to cross the disciplinary chasms, as EarthCube seeking to harmonize the geosciences communities? diverse approaches. Third, it proposes methods for forming collaborative networks of data, tools, standards and people as supported by geoscience cyberinfrastructure technology. Finally, the proposed project incorporates the concept of collaborative networks for maturing the conceptual design of the EarthCube enterprise architecture by including academia, agencies, industry, and other organizations as autonomous participants that continuously seek common ground for collectively improving geosciences.  The proposed EarthCube enterprise conceptual design will be validated through the EarthCube workshops, research coordination networks, building blocks, and other venues. The Federation of Earth Science Information Partners (ESIP) will provide validation from many NSF and non-NSF funded projects. The project will be sustained and make a long standing impact in geoscience communities as well as the geoscience cyberinfrastructure communities with a scalable, interoperable, sustainable, and evolvable conceptual architecture",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343759,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343759
1440294,BB,BB,"EarthCube Building Blocks:  CyberConnector:  Bridging the Earth Observations and Earth Science Modeling for Supporting Model Validation, Verification, and Inter-comparison","EarthCube Building Blocks:  CyberConnector:  Bridging the Earth Observations and Earth Science Modeling for Supporting Model Validation, Verification, and Inter-comparison",One organization,ICER,EarthCube,9/1/2014,8/12/2014,Liping Di,VA,George Mason University,38.831488,-77.311944,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$1,000,000.00 ",Ben Domenico|Xiaoqing Wu|Haosheng Huang|Daniel Tong,ldi@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,7433,"The project will 1) significantly increase research productivity in the Earth science modeling community, 2) enable the effective use of the existing Sensor Web data and Earth Observations through open Web interfaces and metadata standards, 3) foster collaborations among Earth system modelers, geospatial information scientists, and information technologists, and 4) enhance infrastructure for Earth science research and education. CyberConnector will free scientists from the laborious preparation of model inputs and release of model outputs. It will automatically process the Earth Observation data into the right products in the right form needed for Earth Systems Model  initialization, validation, and inter-comparison.  This project developes an EarthCube building block, called CyberConnector, for facilitating the automatic preparation and feeding of both historic and near-real time Earth Observation customized data and on-demand derived products into Earth science models. will automatically process the EO data into the right products in the right form needed for ESM initialization, validation, and inter-comparison. It can support many different ESMs through its standard interfaces under a unified framework. CyberConnector can also automatically serve the model outputs in interoperable forms through standard data services to facilitate rapid inter-model comparison and support the societal applications of the model outputs. Recent EarthCube end-user workshops indicate the proposed capabilities of the CyberConnector are at the top of the wish lists of multiple Earth science communities. To achieve these capabilities, this project leverages the online availability of huge volume of EO data at EO cyberinfrastructure of NSF (e.g., Unidata, NEON), other federal agencies (NASA, NOAA, USGS), and international EO organizations (e.g., CEOS members), advancements in standard-based geospatial web service and sensor web technologies, and successful cyber-systems built by the investigators of this proposal and others (e.g., GeoBrain, SEPS, GEOSS, and CWIC). The proposed project will closely collaborate with other EarthCube building block teams and end-user communities. The ISO geospatial data and metadata standards and standard-based geospatial web service, workflows, and sensor web technologies are the foundation for this project.The Cloud-Resolving Model (CRM), the Community Multi-scale Air Quality Model (CMAQ), the Finite Volume Coastal Ocean Model (FVCOM), and the Grassland and Agroecosystem Dynamics Model (CENTURY) will be used as examples in this project to test, validate, and demonstrate the capabilities and functionality of CyberConnector.The CyberConnector approach is a general one that can support many different Earth system models through the standard interfaces and the geospatial processing model (GPM) mechanism",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440294,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440294
1835507,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Elements: Data: HDR: Developing On-Demand Service Module for Mining Geophysical Properties of Sea Ice from High Spatial Resolution Imagery,Collaborative Research: Elements: Data: HDR: Developing On-Demand Service Module for Mining Geophysical Properties of Sea Ice from High Spatial Resolution Imagery,Collaborative,OAC,DATANET|EarthCube,1/1/2019,8/8/2018,Chaowei Yang,VA,George Mason University,38.831488,-77.311944,Standard Grant,Amy Walton,12/31/2021,"$249,270.00 ",,cyang3@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,CSE,7726|8074,062Z|077Z|7923,"Sea ice acts as both an indicator and an amplifier of climate change. At present, there are multiple sources of  sea ice observations which are obtained from a variety of networks of sensors (in situ, airborne, and space-borne).  By developing a smart cyberinfrastructure element for the analysis of high spatial resolution (HSR) remote sensing images over sea ice, the science community is better able to extract important geophysical parameters for climate modeling. The project contributes new domain knowledge to the sea ice community.  This is accomplished by integrating HSR images that are spatiotemporally discrete to produce a more rapid and reliable identification of ice types, and by a standardized image processing that allows creating compatible sea ice products.  The cyberinfrastructure module is a value-added on-demand web service that can be naturally integrated with existing infrastructure.  The key objective is to develop a reliable and efficient on-demand Open Geospatial Consortium-compliant web service, which is capable of extracting accurate geographic knowledge of water, submerged ice, bare ice, melt ponds, deformed 'ridging' ice, ridge shadows, and other information from HSR images with limited human intervention. The embedded spatial-temporal analysis framework provides functions to search, explore, visualize, organize, and analyze the discrete HSR images and other related remote sensing data and field data. The project creates a data and knowledge web service for the Arctic sea ice community by integrating computer vision and machine learning algorithms, computing resources, and HSR image data and other useful datasets. The conceptual model improves data flow, so users would query data, download value-added data, and have more consistent results across various sources of information.  This creates new opportunities for scientific analysis that minimizes the investment of time in processing complex and spatiotemporally-discrete HSR imagery. The project includes a strong emphasis on teaching and development of the next-generation workforce through course curricula development, involvement of graduate and undergraduate students in research, and the offering of summer workshops for K-12 teachers (funded by other agencies). The collected images and results of the image analyses will be shared with the public in a timely manner through the NSF Arctic Data Center.  This award by the Office of Advanced Cyberinfrastructure is jointly supported by EarthCube and the Office of the Polar Programs Arctic Natural Sciences Program, within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835507,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835507
1239615,"EAGER, RAPID, INSPIRE",EAGER,EAGER:  Collaborative Research:  Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER:  Collaborative Research:  Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities,Collaborative,EAR,EarthCube,4/1/2012,3/28/2012,Liping Di,VA,George Mason University,38.831488,-77.311944,Standard Grant,Barbara L. Ransom,3/31/2013,"$18,000.00 ",,ldi@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,7433|7916,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239615,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239615
1540997,IA,IA,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Mark Uhen,VA,George Mason University,38.831488,-77.311944,Standard Grant,Eva Zanzerkia,8/31/2018,"$252,843.00 ",,muhen@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,7433,"Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.  The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540997,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540997
1540998,IA,IA,EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment,EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment,Collaborative,ICER,EarthCube,9/1/2015,9/9/2015,Chaowei Yang,VA,George Mason University,38.831488,-77.311944,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$144,364.00 ",,cyang3@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,7433,"EarthCube is supporting the creation of interoperable tools and services for Earth science research, but no environment currently exists for integration and testing of these components.  The EarthCube Integration and Test Environment (ECITE), an outgrowth of activities of the EarthCube Testbed Working Group. The ECITE approach focuses on integrating existing effective technologies and resources as well as capabilities being built by the EarthCube community to provide a federated and interoperable test environment. ECITE?s nationwide cyberinfrastructure for the geosciences will also advance the understanding of regional cyberinfrastructure and collaborative geosciences across geographic locations and disciplines by contributing relevant scheduling tools and a working integration and testing environment. A hallmark of the ECITE effort will be engagement of scientists and technologists from multiple disciplines and geographic regions across the geosciences community to develop requirements, prototype, design, build, and test an integration test-bed that will support cross-disciplinary research.  The multi-disciplinary ECITE team is led by Sara Graves of the University of Huntsville in Alabama (UAH) and includes participants from all areas of the United States. ECITE activities will enable EarthCube to further support other members and contribute leadership to the broader scientific community. The ECITE federated Integration and Test (I&T) environment has the potential to scale and extend to an NSF wide integration and test capability that can serve as a model and example for other agencies. The proposed ECITE functionality is vital to ensure that the broader goals of the EarthCube are achieved.  The ECITE team will actively engage EarthCube and the wider geosciences community in definition of requirements, design, and testing of the system. ECITE will consist of a seamless federated system of scalable and location independent distributed computational resources (nodes) across the US.  The hybrid federated system will provide a robust set of distributed resources to include both public and private cloud capabilities.  The nodes will provide compute and storage resources requiring minimal system administration.ECITE is an important step in ensuring that EarthCube components will be able to work together to provide a successful framework that can continue to evolve to meet the needs of the geosciences community.  This research addresses timely issues of integration, test and evaluation methodologies and best practices with a strong interoperability theme to advance disciplinary research through the integration of diverse and heterogeneous data, algorithms, systems and sciences. The results and findings will provide guidance for EarthCube evolution and future integration efforts. The ECITE team aims to make the Integration and Test (I&T) environment easy to use and readily available to the EarthCube community. Access to the resulting platform will enable and encourage the EarthCube community to develop prototypes, try out new technologies, and to share ideas, concepts and experiments",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540998,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540998
1540929,IA,IA,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Mark Uhen,VA,George Mason University,38.831488,-77.311944,Standard Grant,Eva Zanzerkia,8/31/2018,"$115,394.00 ",,muhen@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,8074,7433,"Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.  The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist.  The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540929,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540929
1338427,OTHER,OTHER,Predictability and Prediction of Climate from Days to Decades,Predictability and Prediction of Climate from Days to Decades,One organization,AGS,CLIMATE & LARGE-SCALE DYNAMICS|EarthCube,5/1/2014,4/10/2017,James Kinter,VA,George Mason University,38.831488,-77.311944,Continuing grant,Eric DeWeaver,5/31/2019,"$5,699,932.00 ",,ikinter@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,GEO,5740|8074,1324|4444|7433|OTHR,"This award provides continued funding for the Center for Ocean-Land-Atmosphere Studies (COLA).  COLA is a climate science research center established to explore, establish and quantify the variability and predictability of Earth's climate variations on seasonal to decadal time scales, and to harvest this predictability for societally beneficial predictions.  The Center is jointly funded by NSF, NOAA and NASA.  Work supported through this award includes activities devoted to 1) basic research on predictability on intraseasonal, seasonal, interannual, and decadal timescales; 2) evaluation of the predictability, skill, and fidelity of US national climate models; and 3) contributions to the development of next generation seamless prediction systems. Research performed under item 1 includes testing of land data assimilation schemes in multiple models, performing hindcasts of El Nino/Southern Oscillation (ENSO) events investigate inter-event diversity of ENSO, performing dynamical prediction experiments for the Indian monsoon, and determining the dependence of drought probability on surface boundary conditions including land cover change.  Work under item 2 focuses on the use of optimal spatial structures derived from information theoretic analysis, which represent the most predictable modes, or modes for which predictability differs the most between two models. This activity is intended to support climate prediction efforts at US national centers and contribute to COLA's research-to-operations effort.  Work under item 3 involves collaborators at the NOAA National Centers for Environmental Prediction (NCEP) and includes the development of optimal methods of initializing high-resolution coupled models including version 2 of the Coupled Forecast System (CFSv2), a model used operationally at NCEP.  The work has broader impacts due to its focus on research leading to improved climate prediction, given the substantial societal consequences of climate variability and change.  In addition, COLA benefits the US climate research enterprise through community integration, education, seminars, workshops, and software and information services.  COLA also serves an important function in transferring the results of basic climate science research on predictability and prediction into operational use.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338427,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338427
1345052,WORKSHOP,WORKSHOP,Climate Informatics Workshop,Climate Informatics Workshop,One organization,IIS,INFORMATION TECHNOLOGY RESEARC|Computer Systems Research (CSR|INFO INTEGRATION & INFORMATICS|EarthCube,9/15/2013,9/4/2013,Claire Monteleoni,DC,George Washington University,38.899715,-77.048599,Standard Grant,Sylvia Spengler,8/31/2018,"$90,702.00 ",,cmontel@colorado.edu,1922 F Street NW,Washington,DC,200520086,2029940728,CSE,1640|7354|7364|8074,1640|7354|7364|7433|7484|7556,"Understanding and responding to climate change is a key scientific and societal challenge of the 21st century. Recent advances in satellites and environmental sensors have made it possible to gather vast quantities of data concerning temperature, sea ice, sea level, rainfall, vegetation, etc. There is an urgent need for scientific and technical expertise for developing and effectively applying computational tools that can make use of such data to build increasingly accurate predictive models that offer insights to inform our understanding of, and response to, climate change.   This award supports a series of three workshops on Climate Informatics, an emerging discipline at the intersection of climate sciences and data sciences. The workshops, through a combination of tutorials that introduce climate scientists and data scientists to each other's disciplines, invited talks by established researchers in climate informatics, breakout sessions and for identifying research challenges and opportunities for interdisciplinary collaborations, serve a critically important role in building a vibrant Climate Informatics research community. The award provides support for the participation of approximately 60 to graduate students in each of the three workshops. The workshops contribute to the education and interdisciplinary training of a diverse workforce in STEM areas that span Climate Sciences and Data Sciences (including Machine Learning, Data Mining, Inference, Decision Making) as well as efforts to broaden the participation of women and other underrepresented groups in STEM research and education. Additional information about the Climate Informatics Workshop Series can be found at: https://sites.google.com/site/1stclimateinformatics/",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1345052,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1345052
1238409,WORKSHOP,WORKSHOP,Collaborative workshop proposal: Drawing the roadmap for the semantic/ontology based infrastructure for Geosciences,Collaborative workshop proposal: Drawing the roadmap for the semantic/ontology based infrastructure for Geosciences,Collaborative,EAR,EarthCube,4/1/2012,3/27/2012,Hassan Babaie,GA,"Georgia State University Research Foundation, Inc.",33.754045,-84.384464,Standard Grant,Barbara L. Ransom,8/31/2013,"$9,940.00 ",,hbabaie@gsu.edu,58 Edgewood Avenue,Atlanta,GA,303032921,4044133570,GEO,8074,7433,"EarthCube is focused on community-driven development of an integrated, and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems.  This award funds a series of broad community interactions to gather adequate information and requirements to create a roadmap for a critical cyberinfrastructure capability (semantics and ontologies) in the development of EarthCube.  In the context of cyberinfrastructure, semantics and ontologies are what allows heterogeneous and distributed data systems to become interoperable. They enable scientists to register, discover, access, and integrate data irrespective of its structural heterogeneity.  This work convenes public, online/virtual meetings and seeks broad community input in the development of a process to have the geoscience and cyberinfrastructure communities converge on a way forward in the realm of semantics and ontologies for data, with the end product being a capability implementation roadmap. Also involved in the process is the identification of appropriate community agreed upon use cases. Broader impacts of the work include development of approaches, protocols, and standards that may be applicable across the sciences and the fostering of close interaction between communities that do not commonly interact, to a great extent, with one another moving them toward a common goal of the creation of a new paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238409,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238409
1443061,"DIBBS, BIGDATA, III",DIBBS,CIF21 DIBBs: Systematic Data-Driven Analysis and Tools for Spatiotemporal Solar Astronomy Data,CIF21 DIBBs: Systematic Data-Driven Analysis and Tools for Spatiotemporal Solar Astronomy Data,One organization,OAC,OFFICE OF MULTIDISCIPLINARY AC||DATANET|EarthCube,11/1/2014,8/14/2014,Rafal Angryk,GA,"Georgia State University Research Foundation, Inc.",33.754045,-84.384464,Standard Grant,Amy Walton,10/31/2019,"$1,499,933.00 ",Petrus Martens|Katharine Reeves,angryk@cs.gsu.edu,58 Edgewood Avenue,Atlanta,GA,303032921,4044133570,CSE,1253|1798|7726|8074,7433|7480|8048,"The large quantities of data produced by modern solar telescopes provide a rich and rapidly growing opportunity for discovery.  These large data sets create an unprecedented ability to observe correlations between phenomena that have previously gone unexplored.   However, to harness the power of these large data sets, it is necessary to provide the solar physics and space weather communities with software tools that will rapidly and accurately catalog, explore, track and correlate solar phenomena.  This project develops tools for processing large volumes of spatio-temporal solar data.  Initially, the team enables tracking of all solar events previously identified by an international consortium (the Feature Finding Team of the Solar Dynamics Observatory) and reported to the Heliophysics Event Knowledgebase (HEK).  Next, the team develops systematic spatiotemporal characterizations of solar event types, and identifies spatiotemporal co-occurrence patterns.  Throughout the project, the team disseminates the generated data, discovered patterns, and developed software tools to the community. By adding an ability to track features previously identified by an international consortium, the project has potential to advance knowledge of solar phenomena, and the impact of such phenomena on space weather.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443061,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443061
1343709,BB,BB,EarthCube Building Blocks:  Deploying Web Services Across Multiple Geoscience Domains,EarthCube Building Blocks:  Deploying Web Services Across Multiple Geoscience Domains,One organization,ICER,EarthCube,9/15/2013,9/9/2013,Timothy Ahern,DC,Incorporated Research Institutions for Seismology,34.07351,-106.918781,Standard Grant,Eva Zanzerkia,8/31/2016,"$1,783,919.00 ",Michael Gurnis|Mohan Ramamurthy|Suzanne Carbotte|Ilya Zaslavsky,tim@iris.washington.edu,"1200 New York Avenue, NW",Washington,DC,200056142,2026822220,GEO,8074,7433,"This Building Blocks project intends to extend the promotion of simple web services to simplify the task of discovering, accessing and using data from multiple sources. The investigators will promote the use of this system to manage data from the long tail of science and make it discoverable, removing it from the domain of ""dark data"". Long tail data will come from both funded partner centers and from collaborators. They will extend their approach of exposing data sets through web services to those managed by non-NSF data centers both within the US as well as international data sets by providing resources to stand up web services to expose the data holdings of other centers. A recurring theme in the EarthCube Domain Workshops was the need to simplify the workflows for sharing and discovery of data in geosciences. A significant amount of time is currently spent as ""hunters and gatherers"" of information and once finding that information to determine how to understand and use data from domains outside a given researcher?s area of expertise. The development of the web services building block will significantly change the way in which much of the preparatory work will be accomplished. This building block will also develop the ability to expose ""dark data"". The balance between the time spent on preparing and doing science will be reversed from the current state where the majority of time is spent in preparation and the minority of the time spent on doing the science. This will in itself have extremely broad impacts in geosciences research. The web services building blocks inherently enable horizontal integration across the geosciences with a resulting impact on the breadth of geosciences problems that can be addressed.  The proposed expansion of simple web services into the geosciences will fundamentally change the way geoscientists do their research, combine information from across disciplines and communicate their results to the public, policy makers and educators.Exposing such data will significantly add to the body of knowledge that can be brought to bear on geosciences problems. As problems become more and more complex, the diversity of data sets that must be considered and integrated for a better understanding of a vast range of geoscience problems will increase, and enhanced technologies and procedures will be required to synthesize and communicate the resulting knowledge between scientist and with the public. This building block is an effort to support that transition by engaging EarthCube cyberinfrastructure in developing, establishing and adopting international standards to allow geoscientists to focus on the science, thus increasing their productivity.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343709,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343709
1239065,IA,IA,Service Based Integration Platform for EarthCube (SBIP-E),Service Based Integration Platform for EarthCube (SBIP-E),One organization,EAR,EarthCube,4/1/2012,3/22/2012,Timothy Ahern,DC,Incorporated Research Institutions for Seismology,34.07351,-106.918781,Standard Grant,Barbara L. Ransom,3/31/2013,"$200,953.00 ",,tim@iris.washington.edu,"1200 New York Avenue, NW",Washington,DC,200056142,2026822220,GEO,8074,7433|7916,"This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of experts in geoscience data management, this project focuses on developing a loosely coupled web service approach to allow geoscience data repositories to more effectively make their data holdings discoverable and available to the public. One project goal will be to test the utility of the RESTful (representative state transfer) approach. Its target will be more to link together of disparate geoscience data types from widely distributed data repositories so new types of data-enabled science can be realized. The project engages data management groups from most of the major NSF-funded geoscience data facilities as well as those from a variety of major European geoscience data holdings. This interaction will not only allow broader testing of developed web services, but will also provide a much needed forum to exchange ideas and approaches allowing a better return on investment. One key aspect of this project is the development of URL builders to help users formulate web service requests. Broader impacts of the work include the development of new infrastructure for science and engineering and the likelihood that what results from this project will be applicable to fields outside of the geosciences. An additional broader impact is an international component that engages Italian and other European scientists and data networks as collaborators in the activity.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239065,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239065
1639719,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Deploying Multi-Facility Cyberinfrastructure in Commercial and Private Cloud-based Systems. (GeoSciCloud),EarthCube Building Blocks: Collaborative Proposal: Deploying Multi-Facility Cyberinfrastructure in Commercial and Private Cloud-based Systems. (GeoSciCloud),Collaborative,ICER,EarthCube,9/1/2016,9/15/2016,Timothy Ahern,DC,Incorporated Research Institutions for Seismology,34.07351,-106.918781,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$814,790.00 ",Chad Trabant,tim@iris.washington.edu,"1200 New York Avenue, NW",Washington,DC,200056142,2026822220,GEO,8074,7433,"It is common to hear that it is optimal to perform computations necessary for the operation of corporations in the ?cloud? and it is true that many commercial companies are moving their information technology into that environment. Scientific data centers funded by the NSF have unique constraints that they must accommodate.  Funding is limited and costs of managing data centers using cloud technology can be quite costly.  Additionally, government funded research organizations typically have much smaller IT staffs than do corporations. The impact of managing IT operations in the cloud is not identical between large corporations and NSF funded data centers.  In the GeoSciCloud project, two medium-size NSF funded data centers plan to deploy data collections along with cloud-based services in different environments in order to assess the feasibility and impact.  These environments include: - Commercial cloud environments such as those offered by Amazon, Google, and Microsoft and - NSF supported large computing facilities that are just beginning to offer services that have characteristics of cloud computing The operation of these infrastructures in these two cloud environments will be compared to current in-house environments and assessed. This project will thereby help NSF/EarthCube  identify the most suitable IT environment in which the EarthCube should deploy and support shared infrastructure.  The potential reliability and cost-savings are excellent motivating factors.  IRIS and UNAVCO operate data centers with several hundred terabytes of data and services that match our community's needs and requirements.  Each organization currently operates its own infrastructure. GeoSciCloud tasks will include moving subsets of our archives, as a test, into commercial cloud and XSEDE cloud environments where we will compare and contrast several aspects of working in different infrastructures. GeoSciCloud partners will also deploy key services developed under the GeoWS building block to enable access to data sets by domain scientists.   GeoSciCloud will help EarthCube compare and contrast the three environments (XSEDE, Commercial Cloud, and current infrastructure) in the following areas: - Gain an understanding of issues related to the ingestion of large data sets into the cloud and curating the data in a cloud environment. - Compare processing times for real world requests for data by practicing domain scientists - Test elasticity of the cloud for doing large amounts of digital signal processing of seismic data and reprocessing GPS solutions for long periods of time. - Compare the speed of data egress from multiple environments including tests of using higher access systems such as Grid-FTP. - Compare overall costs of operating in the three environments - Document what the best practices are that emerge from the GeoSciCloud test that should be promoted within EarthCube. - Perform conversion of data held in domain formats to more widely used formats such as HDF5 for improved interoperability. - Test the reliability of streaming real time data into the cloud. GeoSciCloud will also explore providing some infrastructure in support of other EarthCube partners so that multiple data centers can cohabitate within the GeoSciCloud.  IRIS and UNAVCO will commit to ultimately demonstrate the utility of shared infrastructure and how it can improve the efficiency and economics within EarthCube and specifically shared infrastructure in a cloud environment.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639719,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639719
1238061,WORKSHOP,WORKSHOP,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,One organization,EAR,Software Institutes|IIS SPECIAL PROJECTS|EarthCube,4/1/2012,3/27/2012,Marlon Pierce,IN,Indiana University,39.17457,-86.512946,Standard Grant,Barbara L. Ransom,3/31/2013,"$14,999.00 ",Suresh Marru|Chathura Herath,marpierc@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,GEO,8004|7484|8074,7433,"EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences. They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238061,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238061
1245171,OTHER,OTHER,Collaborative Research: From Data to Users: A Prototype Open Modeling Framework,Collaborative Research: From Data to Users: A Prototype Open Modeling Framework,Collaborative,EAR,EarthCube,7/15/2012,7/20/2012,Yao Liang,IN,Indiana University,39.17457,-86.512946,Standard Grant,Barbara L. Ransom,6/30/2014,"$88,495.00 ",,yliang@cs.iupui.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,GEO,8074,7433|0000|7916|OTHR,"Because Earth is a complex coupled interacting system, where no one element is independent of any other, there are both pressing scientific and societal needs to improve our understanding how various physical, biological, and hydrological processes interact in surface Earth systems. This requires the development of new and increasingly more sophisticated ways of mathematically describing these systems and improvements in software and user interfaces that will dramatically enhance our ability to simulate these systems to improve the accuracy and reliability of model predictions of weather, floods, droughts, and climate variability. Such improved models will allow researchers to make better use of available data across disciplines and improve theory and algorithms that are essential to understanding Earth system behavior. Unfortunately, at present there is significant overhead of time and effort needed for discovering, accessing, understanding, and preparing data required to populate these models, as well as long learning lead times on how to use presently available models, owing to their complexity. This research overcomes some of these limitations by developing an innovative open modeling framework that can integrate data and models easily and is easy to use so that not only the research community and operational professionals can use it, but also policy makers and other interested parties. This EAGER award allows the construction of a prototype open meta-modeling framework that significantly reduces the time and effort on the part of users in the preparatory work for data and model comparisons, model testing and validations, for making fundamental knowledge discoveries in surface and ground water hydrological systems. In this framework, components/modules interact via user-configured open interfaces that allow the addition and integration of hydrological models and data sources using a common meta-level architecture and scientific workflows. The proposed prototype is based on a recently completed modeling framework, HS-NWSRFS (Hydro-information System for improving the National Weather Service River Forecast System). It represents a collaboration between investigators from three institutions, NASA, and NWS Ohio River Forecast Center (OHRFC). The funded effort will significantly expand the present code into an open community framework prototype. Broader impacts of the work include interagency collaboration, improved hydrological forecasting for rivers, and support of a PI whose gender is under-represented in the sciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1245171,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1245171
1445821,WORKSHOP,WORKSHOP,Workshop Support for Focused Technical Workshop on Improving Data Mobility & Management for International Climate Science,Workshop Support for Focused Technical Workshop on Improving Data Mobility & Management for International Climate Science,One organization,OAC,Campus Cyberinfrastrc (CC-NIE),7/1/2014,6/25/2014,Jennifer Schopf,IN,Indiana University,39.17457,-86.512946,Standard Grant,Kevin L. Thompson,5/31/2016,"$44,316.00 ",,jmschopf@indiana.edu,509 E 3RD ST,Bloomington,IN,474013654,8128550516,CSE,8080,7556,"The Focused Technical Workshop on Improving Data Mobility & Management for International Climate Science (FTW for Climate Science) will enable an active dialogue between climate scientists, climate data managers, and cyberinfrastructure engineers with the goal of setting longer-term relationship building in motion. The workshop also hopes to provide climate researchers with information about a set of broad, concrete, and immediately useful tools and resources for improved data transport and management.  The FTW on Climate Science is sponsored by ESnet, Internet2, Indiana University (IU), National Center for Atmospheric Research (NCAR), and National Oceanic and Atmospheric Administration (NOAA) and will be hosted at the NOAA Boulder Labs, in Boulder, Colorado, in July 2014.  The workshop will bring together experts to discuss recent research technology advances and research techniques in data management for climate science. The format is being designed to encourage lively, interactive discussions with the goal of developing a set of tangible next steps for supporting this data-intensive science community.  Participation key stakeholders from multiple agencies and programs provides the climate science community with the knowledge, tools, and partners necessary to improve data transfer performance as data scale continues to increase. This has the potential to have broad reaching effects in a science area that is critical to society. By increasing performance to match increased data scale, scientific productivity for this community is expected to increase. This workshop will leverage existing NSF supported projects, including work with EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1445821,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1445821
1315956,OTHER,OTHER,Infrastructure for Broadening Participation in STEM (IBP-STEM),Infrastructure for Broadening Participation in STEM (IBP-STEM),One organization,EAR,"GLOB LEARN & OBSER TO BEN ENVI|RSCH EXPER FOR UNDERGRAD SITES|SPECIAL PROGRAMS IN ASTRONOMY|INFRASTRUCTURE PROGRAM|AGEP|EDUCATION AND HUMAN RESOURCES|EDUCATION/HUMAN RESOURCES,OCE|Antarctic Education|POSTDOCTORAL FELLOWSHIPS|EarthCube|Integrative Activities in Phys|EPSCoR Co-Funding",9/1/2013,4/7/2016,David Siegfried,ME,Institute for Broadening Participation,44.031073,-69.527718,Continuing grant,Lina C. Patino,8/31/2017,"$1,299,990.00 ",,dsiegfried@ibparticipation.org,P.O. Box 607,Damariscotta,ME,45430607,2075635929,GEO,1053|1139|1219|1260|1515|1575|1690|5294|7137|8074|9134|9150,7433|9150,"The underlying mission of the Infrastructure for Broadening Participation in STEM (IBP-STEM) initiative is to increase diversity in the Science, Technology, Engineering and Mathematics (STEM) workforce. The Institute for Broadening Participation (IBP) operates on a model of targeted activities supported by strategic infrastructure to support underrepresented students in their efforts to seek and successfully apply to research, funding, mentoring, and professional development opportunities, and succeed in their chosen academic and career pathways; assist faculty and administrators in their efforts to support and mentor students, build partnerships, and contribute to the pool of best practices; and grow diversity awareness and cultural competency in programs, departments, and institutions. IBP's four-pronged approach to broadening participation and increasing diversity in STEM includes: (1) Catalyzing partnerships to cultivate a community of practice and culture of diversity, reduce isolation among diversity practitioners and increase information sharing; (2) Extensive face-to-face and virtual outreach to draw constituents to the resources available via IBP that support students and faculty through the entire STEM pathway; (3) Creating and maintaining strategic web resources, open to all members of the STEM academy nationally, to make resources and information on programs, best practices, and references easily available and accessible; and (4) Synthesizing information to compile and translate research and best practices into materials and resources that are engaging, usable, and directly relevant to a broad constituency of STEM faculty, administrators, program staff, and students.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1315956,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1315956
1823267,"DIBBS, BIGDATA, III",DIBBS,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,Collaborative,IIS,INFO INTEGRATION & INFORMATICS,8/16/2017,6/27/2018,Goce Trajcevski,IA,Iowa State University,42.026619,-93.646465,Standard Grant,Maria Zemankova,9/30/2019,"$121,310.00 ",,gocet25@iastate.edu,1138 Pearson,AMES,IA,500112207,5152945225,CSE,7364,7364|7925|9251,"Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.  This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1823267,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1823267
1835640,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Framework: Data: Toward Exascale Community Ocean Circulation Modeling,Collaborative Research: Framework: Data: Toward Exascale Community Ocean Circulation Modeling,Collaborative,OAC,PHYSICAL OCEANOGRAPHY|DATANET|EarthCube,11/1/2018,8/23/2018,Thomas Haine,MD,Johns Hopkins University,39.329901,-76.620518,Standard Grant,Amy Walton,10/31/2022,"$1,850,538.00 ",Renske Gelderloos|Gerard Lemson|Alexander Szalay,Thomas.Haine@jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,1610|7726|8074,062Z|077Z|1324|7925,"This project designs and implements a software framework for handling petabyte-scale datasets; the focus is on global ocean circulation.  A team of three universities (Johns Hopkins University, MIT, and Columbia University) builds a unified data system that is capable of delivering global ocean circulation model output at 1 km horizontal resolution. The product will be hosted in an open portal, providing the community with scalable software tools to enable analysis of the dataset. The team will use this data to answer specific questions about mixing and dissipation processes in the ocean.   The goal of this effort is the creation and demonstration of a complete and replicable cyberinfrastructure for sharing and analysis of massive simulations.  The focus is on high resolution ocean circulation modeling, with software tools that will enable efficient storage. Two major challenges to the study of ocean and climate dynamics are addressed: handling large datasets from high-resolution simulations, and understanding the role of small-scale ocean processes in large-scale ocean/climate systems.  Resolving the first challenge would significantly facilitate ongoing and future studies of the ocean/atmosphere/climate system; addressing the second challenge would profoundly improve understanding of ocean/climate dynamics. The project builds a unified data system consisting of high-resolution global ocean circulation simulations, a petascale portal for data sharing, and scalable software tools for interactive analysis.   The software framework from this project is expected to handle petascale to exascale datasets for users.  Several pre-existing capabilities are leveraged for this project: the JHU regional numerical model of the Spill Jet on the East Greenland continental slope, software from the Pangeo project, the SciServer data-intensive software infrastructure, and lessons learned from the North East Storage Exchange multi-petabyte regional data store.  The broader target is next generation simulation software in the geosciences and other disciplines.    This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Division of Ocean Sciences and the Integrative and Collaborative Education and Research Program within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835640,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835640
1743030,OTHER,OTHER,SuperMAG: High Time-resolution Data Enabling Global UltraLow Frequency (ULF) Studies,SuperMAG: High Time-resolution Data Enabling Global UltraLow Frequency (ULF) Studies,One organization,AGS,EarthCube|Space Weather Research,9/1/2018,8/17/2018,Jesper Gjerloev,MD,Johns Hopkins University,39.329901,-76.620518,Standard Grant,S. Irfan Azeem,8/31/2021,"$453,769.00 ",Robin Barnes|Tetsuo Motoba|Shin-ichi Ohtani|Kazue Takahashi,Jesper.Gjerloev@jhuapl.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,GEO,8074|8089,062Z|4444,"This research will develop and provide a new SuperMAG project capability for organizing, storing, and disseminating high time resolution data from world-wide arrays of fluxgate and induction coil magnetometer for magnetospheric ultralow frequency (ULF) waves and substorm-related investigations. SuperMAG is a worldwide collaboration of organizations and national agencies that currently operate >300 ground-based magnetometers. This research effort will gather and organize high-time resolution data, write software packages to pre-process and process high time resolution fluxgate and induction coil magnetometers data, and disseminate them to the community on the SuperMAG website. The resulting data product will enable studies of global ULF activity by allowing easy access to high time resolution measurement (<5sec), derived data products, plots and other tools. Availability of the new data product will provide new opportunities of research to students. The project will also foster education and public outreach activities, which are already a key component of SuperMAG.  This research will enhance the current SuperMAG capabilities by expanding its ground-based magnetometer data holdings from 1-minute cadence to higher sampling rates (< 5 sec) of both fluxgate and induction coil arrays and by developing additional data products that will make observations of ULF waves and substorm-related variations in these high-cadence data more easily accessed and understood by the wider geospace science community. The high time-resolution magnetometer dataset will enhance studies of substorm-related processes because of the availability of data on Pi1b wave activity (higher frequency than Pi2, but also generated in association with nightside magnetic field dipolarizations), and studies of radiation belt enhancement and loss processes because of the availability of the full range of ULF waves, including in particular electromagnetic ion cyclotron (EMIC) waves generated in the middle and inner magnetosphere. The implementation of high time-resolution data, along with the new addition of satellite footpoints to SuperMAG, will foster collaborations between the satellite community and the ground community for new scientific areas such as ULF waves. The project will foster education and public outreach (EPO) activities, which are already a key component of SuperMAG.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1743030,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1743030
1541009,IA,IA,EarthCube IA: Magnetosphere-Ionosphere-Atmosphere Coupling,EarthCube IA: Magnetosphere-Ionosphere-Atmosphere Coupling,One organization,ICER,EarthCube,9/15/2015,9/15/2015,Jesper Gjerloev,MD,Johns Hopkins University,39.329901,-76.620518,Standard Grant,Eva Zanzerkia,8/31/2018,"$697,809.00 ",Brian Anderson|Gary Bust|Robin Barnes|Ethan Miller,Jesper.Gjerloev@jhuapl.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,GEO,8074,7433,"The scientific work proposed here will carry out the research and development necessary to create a new, unique set of high-latitude electro-dynamic, ionospheric-thermospheric-&#8208;magnetospheric cyberbased tools and products that will be available to the entire geosciences community. In combination, the data products from this project will allow the derivation of a first principle electromagnetic solution for the auroral ionosphere. Project will develop a new set of data resources for the geoscience community in the form of a complete electromagnetic solution of the auroral ionosphere and will focus on developing the ?Data Infrastructure for Communities? component of the EarthCube Integrative Activities. The project will thus allow access to not only the desired derived products, but also provide support for other modeling efforts by allowing access to the database of input data and intermediary products. The system will also be designed to be extensible, allowing additional data products and models to be integrated into the system. The system will fully support existing standards that are used in the broader geosciences community such as the Data Access Protocol (DAP).The research undertaken in this proposal will enable transformative research in two otherwise separated fields: magnetosphere-&#8208;ionosphere and neutral atmosphere.   The MIAC project addresses the complete electromagnetic solution of the auroral ionosphere, through an implementation that matches the goals of the EarthCube program. The intent is to develop a series of interlocking web services that provide access to the underlying MIAC datasets (AMPERE, SuperDARN and SuperMAG), that apply the science algorithms to derive the desired electro- dynamic products, and provide data translation and visualization services. This mesh of services will be open to the community and will allow users to access any individual service. The research undertaken in this project will enable transformative research in two otherwise separated fields: magnetosphere-&#8208;ionosphere and neutral atmosphere through a) the high-&#8208;latitude electro-&#8208;dynamics couple to the incoming solar wind and magnetosphere along magnetic field lines; b) the changes in the ionosphere and thermosphere at high latitudes provide changes to the conductivities throughout the polar region, which then effect the dynamics in the magnetosphere; c) the electrodynamic energy and momentum inputs get deposited in the upper atmosphere and launch neutral winds that then couple to ion velocities and transport compositional changes to the mid and low latitudes; d) the winds and composition couple to waves impinging from the lower atmosphere.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541009,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541009
1633124,"DIBBS, BIGDATA, III",DIBBS,BIGDATA: IA: Democratizing Massive Fluid Flow Simulations via Open Numerical Laboratories and Applications to Turbulent Flow and Geophysical Modeling,BIGDATA: IA: Democratizing Massive Fluid Flow Simulations via Open Numerical Laboratories and Applications to Turbulent Flow and Geophysical Modeling,One organization,OCE,PHYSICAL OCEANOGRAPHY|EarthCube|Big Data Science &Engineering,10/1/2016,9/13/2016,Charles Meneveau,MD,Johns Hopkins University,39.329901,-76.620518,Standard Grant,Baris Uz,9/30/2019,"$952,570.00 ",Alexander Szalay|Gregory Eyink|Randal Burns|Tamer Zaki,meneveau@jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,GEO,1610|8074|8083,4444|7433|8083,"Computer simulations of turbulent fluid flows are playing an increasingly vital role in engineering applications (e.g. reducing drag forces on vehicles and predicting wind turbine aerodynamic efficiency) and in geophysical sciences (e.g. describing the fate of pollutant dispersion or Lagrangian transport and mixing in the ocean). Simulations consist of discretizing and integrating the partial differential equations governing fluid flow and transport forward in time, providing solutions for physical variables (fields such as velocity and pressure) as function of time and space in the entire domain of interest. Since such simulations generate enormous amounts of data, the prevailing approach has been for researchers to analyze the data ""on the fly"" during the simulation runs while only a small subset of time-steps are stored for subsequent analysis. As a result, often large simulations of the same process must be repeated after new questions arise that were not initially obvious. Many (or even most) breakthrough concepts cannot be anticipated in advance, as they will be motivated in part by output data and must then be tested against it. As a result, there is a need for methods to store entire space-time data from such simulations.  This project develops innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling and makes these available to the entire community. Several of the datasets to be included into the Open Numerical Laboratory will be contributed by external researchers. In addition to enhancing engineering and geophysical fluid mechanics and turbulence research, democratized access to large-scale turbulent flow simulation data will also play a crucial role in education and training for the next generation of researchers. Active learning through new educational modules that allow students to query simulation datasets in unprecedented detail will provide new educational paradigms. More broadly, the lessons learned from this project will be generalizable to many other fields where numerical simulations generate very large datasets that are difficult to access using prevailing approaches. In this way, the project will enhance the scientific and broader impacts of the US high-performance scientific computing infrastructure.   This project will develop innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling. An ingest pipeline to be developed will enable users to transfer data from file systems containing the output of their massive direct numerical simulations, build a database, and serve it to the community for open exploratory data analysis and innovative turbulence and oceanic mixing research. To date, the investigators involved in this project have built an Open Numerical Laboratory focusing on direct numerical simulations (DNS) of canonical turbulent flows, in which the entire space-time data are available to the wider research community. However, the existing datasets are few in number and databases have been created one by one, using methodologies difficult to replicate on a massive scale.  Moreover, emerging Exascale simulations will potentially result in data sets of unprecedented scale (tens to hundreds of PetaBytes). Advanced computer science algorithms will be required to tackle these challenges. This project will (a) develop automated, and scalable data management algorithms to ingest, index and serve very large data sets generated by a wide range of groups, (b) explore novel algorithms using spatio-temporal subsampling combined with online interpolation with re-simulation, yielding large compression factors depending on the subsampling stride, and (c) use machine learning algorithms to identify localized regions of interest in the simulations and save these 4D domains in a database for detailed follow-up analytics. The new databases will include data from (1) the largest channel flow DNS, (2) rotating and stratified turbulence of geophysical interest, (3) a DNS of developing wall boundary layer and (4) detailed ocean circulation models with complex boundary conditions. As part of the innovative domain science applications, data sets will be used to improve turbulence models using data-assimilation concepts, study Lagrangian vortex dynamics, and explore geophysical transport in a regional general circulation model of the North Atlantic Ocean.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1633124,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1633124
1550346,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,Collaborative,OAC,Software Institutes|EarthCube,9/1/2016,8/19/2016,Dimitri Sverjensky,MD,Johns Hopkins University,39.329901,-76.620518,Standard Grant,Micah Beck,8/31/2019,"$217,827.00 ",,sver@jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,8004|8074,7433|8004|8009,"Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science.  They model the chemistry of melting of the interiors of planets as a result of heat flow within the body.  They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits.  They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles.  They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids.  Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies.   It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization.    This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics.  ENKI will provide software tools in computational thermodynamics and fluid dynamics.  It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks.  ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research.  ENKI development will be community driven.  Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples.  All software associated with this project will be released as open source.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550346,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550346
1540994,IA,IA,EarthCube IA:  Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,EarthCube IA:  Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Alison Smith,OH,Kent State University,41.149063,-81.341465,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$78,000.00 ",,alisonjs@kent.edu,OFFICE OF THE COMPTROLLER,KENT,OH,442420001,3306722070,GEO,8074,7433,"Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.  The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540994,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540994
1339782,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,Collaborative,OAC,PHYSICAL OCEANOGRAPHY|SPECIAL PROJECTS - CISE|SPECIAL PROJECTS - CCF|Software Institutes|EarthCube,10/1/2014,8/26/2014,Hartmut Kaiser,LA,Louisiana State University & Agricultural and Mechanical College,30.413258,-91.180002,Standard Grant,Bogdan Mihaila,9/30/2019,"$970,835.00 ",Robert Twilley,hkaiser@cct.lsu.edu,202 Himes Hall,Baton Rouge,LA,708032701,2255782760,CSE,1610|1714|2878|8004|8074,7433|8009|9150,"The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography. The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339782,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339782
1440195,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,Collaborative,ICER,EarthCube,9/1/2014,8/19/2014,Thomas Narock,VA,Marymount University,38.905351,-77.127762,Standard Grant,Eva Zanzerkia,12/31/2016,"$144,401.00 ",,tnarock@ndm.edu,2807 NORTH GLEBE ROAD,Arlington,VA,222074299,7035266978,GEO,8074,7433,"The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.  A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440195,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440195
1835576,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: HDR: Data-Driven Earth System Modeling,Collaborative Research: HDR: Data-Driven Earth System Modeling,Collaborative,AGS,PHYSICAL OCEANOGRAPHY|CLIMATE & LARGE-SCALE DYNAMICS|EarthCube,11/1/2018,9/7/2018,Raffaele Ferrari,MA,Massachusetts Institute of Technology,42.360091,-71.09416,Continuing grant,Eric T. DeWeaver,10/31/2023,"$1,000,000.00 ",,rferrari@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,GEO,1610|5740|8074,026Z|062Z|4444|7925|8004,"Global weather and climate models represent the atmosphere on computational grids with horizontal spacing of perhaps 100km, stacked in layers which can be over a kilometer thick.  Such grids suffice to capture the dynamics of cyclones, fronts, and other large-scale atmospheric phenomena, but these phenomena depend critically on processes with spatial scales much smaller than the grid spacing.  The small-scale processes must be represented indirectly, through parameterization schemes which estimate their net impact on the resolved atmospheric state.  For example clouds are typically too small for the grid spacing yet they are critical for moving moisture from the ocean surface to the mid-troposphere, thus cloud parameterizations play a key role in determining atmospheric humidity even on the largest spatial scales.  Parameterization schemes are inherently approximate, and the development of schemes which produce realistic simulations is a central challenge of model development.  Shortcomings in parameterization limit the usefulness of weather and climate models both for scientific research and for societal applications.  Most parameterization schemes depend critically on various parameters whose values cannot be determined a priori but must instead be found through trial and error.  This task, referred to as ""tuning"", is laborious as it is performed separately for each parameterization scheme and involves multiple integrations of the model in multiple configurations. It is also inefficient in its use of observations, which is unfortunate given the large amount of observational data available from satellites and other sources. The resulting parameter sets may not be optimal and may produce unexpected results when all the schemes interact with each other in global simulations.  Finally, manual tuning is not conducive to uncertainty quantification, which would be valuable for estimating the uncertainty in future climate change projections.   The goal of this project is to replace ad hoc manual tuning with a combination of data assimilation, machine learning, and fine-scale process modeling using large eddy simulation (LES) models.  LES models have grid spacings of a few tens of meters and can explicitly simulate the clouds and turbulence represented by parameterization schemes.  These ingredients are combined to create a global Machine Learning Atmospheric Model (MLAM), in which LES models embedded in selected grid columns of a global model explicitly simulate subgrid-scale processes which are represented by parameterization schemes in the other columns. Machine learning is used to tune the schemes to emulate the behavior of the LES simulations, so that explicit simulations become an online benchmark for parameterization.  In this way all the schemes can be tuned together and interactively within a running global simulation.  Observational data from a variety of sources is assimilated during the model integration to provide a further constraint on parameter values, and estimates of parameter uncertainty are generated as part of the automated tuning.  A similar tuning process is implemented in an ocean general circulation model, and the two are combined to produce a machine learning climate model.  Model tuning is generally viewed as a necessary but mundane activity which is not in itself a research topic.  But a model capable of learning its parameters from observations and process models offers a new path forward, toward both better models and better ways of using models.  The work has broader impacts due to the societal value of better forecasts and projections from weather and climate models.  The work directly addresses uncertainty in forecasts and projections used by decision makers to plan for weather and climate impacts.  In addition, the modeling strategy developed here is applicable to a broad class of research areas which face the problem of relating large-scale behaviors to small-scale unresolved processes (the problem of relating genotypes to phenotypes in evolutionary biology, for example).  In addition, the PIs will establish a cross-disciplinary graduate program on data-driven Earth system modeling. The program bridges the gap between environmental and computational sciences which currently hinders progress in environmental modeling.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835576,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835576
1442997,"DIBBS, BIGDATA, III",DIBBS,CIF21 DIBBs: An Infrastructure for Computer Aided Discovery in Geoscience,CIF21 DIBBs: An Infrastructure for Computer Aided Discovery in Geoscience,One organization,OAC,AERONOMY|DATANET|EarthCube,11/1/2014,8/14/2014,Victor Pankratius,MA,Massachusetts Institute of Technology,42.360091,-71.09416,Standard Grant,Amy Walton,10/31/2019,"$1,424,765.00 ",Frank Lind|Philip Erickson,pankrat@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,1521|7726|8074,7433|8048,"Next-generation Geoscience needs to handle rapidly growing data volumes from ground-based and space-based sensor networks. As real-world phenomena are mapped to data, the scientific discovery process essentially becomes a search process across multidimensional data sets. The extraction of meaningful discoveries from this sea of data therefore requires highly efficient and scalable machine assistance to enhance human contextual understanding. This is necessary both for testing new hypotheses as well as for the detection of novel events and monitoring for natural hazards.  This project develops a computer-aided discovery approach that provides scientists with better support to answer questions such as: What inferences can be drawn from an identified feature?  What does a finding mean and how does it fit into the big theoretical picture? Does it contradict or confirm previously established models and findings? How can  concepts and ideas be tested effectively? To achieve this, scientists can programmatically express hypothesized Geoscience scenarios, constraints, and model variations. This approach helps delegate the automatic exploration of the combinatorial search space of possible explanations in parallel on a variety of data sets. Furthermore, programmable crawlers can scale the search and discovery of interesting phenomena on cloud-based infrastructures. The computer-aided discovery prototype is evaluated in case studies from Geospace science, including the exploration of structures in space and time using combined GPS, optics, and Geospace radar data.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1442997,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1442997
1640829,"DIBBS, BIGDATA, III",DIBBS,CIF21 DIBBs: PD: - Metadata Toolkits for Building Multi-Faceted Data - Relationship Models,CIF21 DIBBs: PD: - Metadata Toolkits for Building Multi-Faceted Data - Relationship Models,One organization,OAC,PLASMA PHYSICS|COMPUTATIONAL PHYSICS|DATANET|EarthCube,10/1/2016,8/3/2016,Martin Greenwald,MA,Massachusetts Institute of Technology,42.360091,-71.09416,Standard Grant,Amy Walton,9/30/2019,"$500,000.00 ",,g@psfc.mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,1242|7244|7726|8074,7433|7569|8048,"Scientific research is challenged by ever-larger, more complex data sets, stored in disparate form in complicated repositories, making it difficult to discover useful content.  One reason is the relative scarcity of 'navigational' metadata - metadata that explicitly reveals the multitude of relationships between data elements.  This project develops improved data management tools allowing data managers to create metadata schemas that reveal the multiple and complex relationships existing between data elements. The team develops these tools while collaborating directly with three different research communities:  plasma physics (with the MIT Plasma Science and Fusion Center), ocean monitoring and modeling (with the MIT Department of Earth Sciences) and uncertainty quantification (with the University of Texas Institute for Computational Engineering and Sciences).   The project provides tools that allow data managers to easily develop metadata schemas that represent and expose the multiple and complex relationships that exist between data elements and which are typically not well represented in data systems. Such data elements include data source, provenance, physical properties represented in the data, data versioning, annotation threads, data dictionaries, data catalogs and data shape (which typically determines which applications can consume or display the data), and larger organizational entities such as research campaigns, experimental proposals and research products (e.g., publications, presentations and public databases).  Schemas and data are manipulated through a Representational State Transfer - Application Programming Interface (RESTful API). Relationships among the data are represented as mathematical graph structures that are all built upon a common meta-schema. There is an emphasis on recording the full data lifecycle using a RESTful API and granular data object uniform resource identifier (URI) schema that facilitate instrumenting complex and varied workflows.  A modern web based exploration tool is built upon these technologies in the initial application areas of plasma physics, ocean monitoring and modeling, and uncertainty quantification.  By viewing meta-data and programs more generally as a collection of graphs whose nodes are the data files or records, the project creates a set of programs which can explore these graphs and make the system much more general and easily extensible.  Also, by allowing users to create data objects at any level of specificity, the graphs of which the data is a member can be used to label object groupings.  This ability to represent data relationships would be of use to a broad contingent of the scientific community and could be useful to the scientific enterprise in many domains.    This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Geosciences, and the NSF Directorate for Mathematical & Physical Sciences (Division of Physics).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1640829,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1640829
1835512,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Elements: Data: HDR: Developing On-Demand Service Module for Mining Geophysical Properties of Sea Ice from High Spatial Resolution Imagery,Collaborative Research: Elements: Data: HDR: Developing On-Demand Service Module for Mining Geophysical Properties of Sea Ice from High Spatial Resolution Imagery,Collaborative,OAC,DATANET,1/1/2019,8/8/2018,Xin Miao,MO,Missouri State University,37.2005546,-93.2828693,Standard Grant,Amy Walton,12/31/2021,"$127,966.00 ",,XinMiao@missouristate.edu,901 South National,Springfield,MO,658970027,4178365972,CSE,7726,062Z|077Z|7923,"Sea ice acts as both an indicator and an amplifier of climate change. At present, there are multiple sources of  sea ice observations which are obtained from a variety of networks of sensors (in situ, airborne, and space-borne).  By developing a smart cyberinfrastructure element for the analysis of high spatial resolution (HSR) remote sensing images over sea ice, the science community is better able to extract important geophysical parameters for climate modeling. The project contributes new domain knowledge to the sea ice community.  This is accomplished by integrating HSR images that are spatiotemporally discrete to produce a more rapid and reliable identification of ice types, and by a standardized image processing that allows creating compatible sea ice products.  The cyberinfrastructure module is a value-added on-demand web service that can be naturally integrated with existing infrastructure.  The key objective is to develop a reliable and efficient on-demand Open Geospatial Consortium-compliant web service, which is capable of extracting accurate geographic knowledge of water, submerged ice, bare ice, melt ponds, deformed 'ridging' ice, ridge shadows, and other information from HSR images with limited human intervention. The embedded spatial-temporal analysis framework provides functions to search, explore, visualize, organize, and analyze the discrete HSR images and other related remote sensing data and field data. The project creates a data and knowledge web service for the Arctic sea ice community by integrating computer vision and machine learning algorithms, computing resources, and HSR image data and other useful datasets. The conceptual model improves data flow, so users would query data, download value-added data, and have more consistent results across various sources of information.  This creates new opportunities for scientific analysis that minimizes the investment of time in processing complex and spatiotemporally-discrete HSR imagery. The project includes a strong emphasis on teaching and development of the next-generation workforce through course curricula development, involvement of graduate and undergraduate students in research, and the offering of summer workshops for K-12 teachers (funded by other agencies). The collected images and results of the image analyses will be shared with the public in a timely manner through the NSF Arctic Data Center.  This award by the Office of Advanced Cyberinfrastructure is jointly supported by EarthCube and the Office of the Polar Programs Arctic Natural Sciences Program, within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835512,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835512
1743321,RCN,RCN,"EarthCube RCN: Towards Integration of Heliophysics Data, Modeling, and Analysis Tools","EarthCube RCN: Towards Integration of Heliophysics Data, Modeling, and Analysis Tools",One organization,AGS,EarthCube,4/1/2018,4/12/2018,Gelu Nita,NJ,New Jersey Institute of Technology,40.742335,-74.179341,Standard Grant,Subhashree Misha,3/31/2020,"$299,754.00 ",Alexander Kosovichev|Vincent Oria,gnita@njit.edu,University Heights,Newark,NJ,71021982,9735965275,GEO,8074,7433,"Heliophysics is in the core of the Geospace science because the solar activity directly determines the conditions of the Earth space environment and atmosphere. For understanding the physical mechanisms of the complex multi-scale processes on the Sun and developing Space Weather forecasting techniques, it is critical to develop a common cyberinfrastructure to collect, access, analyze, share and visualize all forms of data from ground-based and space observatories, as well as from data-driven numerical simulations and modeling, and develop capabilities for their efficient analysis using advanced computer science techniques. The main goal of this project is to create a Research Coordination Network (RCN) that will foster new collaborations between heliophysics and computer scientists, which will result in ideas and concrete plans for developing building blocks supporting the goals of the EarthCube initiative. This RCN will actively encourage involvement of a diverse pool of community members and will provide an organized virtual structure that will promote a science transforming open source knowledge collaboration. This collaboration will enhance the science return from individual research projects run by the RCN participants.   The activities of the RCN will be overseen by a steering committee composed of academic Heliophysicists and computer scientists from leading universities and research centers in the field. The steering committee will organize three topical working groups led by the members of the principal investigator (PI) team, which will address specific challenges related to: 1) Finding data and discovering knowledge, 2) Working with data and cross-disciplinary data, and 3) Simulations and modeling. The steering committee will organize topical working groups that will have as primary goals to build and strengthen the partnership between heliopyhsicists and cyber/computer scientists, foster new collaborations that will lead to better science outcomes, develop and discuss new ideas, methodologies and tools for efficient integration and analysis of the existing and upcoming large databases generated by space and ground-based observatories and supercomputer modeling centers. The RCN working groups will be led by the members of the PI Team, who will organize virtual seminars, as well as special sessions during general conferences in the field (such as the annual meeting of the American Geophysical Union and the Solar Heliospheric and Interplanetary Environment conference). In addition, the PI team will organize annual plenary technical interchange meetings attended by all working groups. The RCN steering committee will closely work with the EarthCube Governance and participate in the annual EarthCube meetings. The RCN will actively involve students and young researchers in its working groups and promote and support their participations in the EarthCube meetings. The project outcomes will be published in regular project reports, scholarly articles, and presented at the EarthCube meetings and scientific conferences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1743321,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1743321
1419015,WORKSHOP,WORKSHOP,"EarthCube Domain End-User Workshop:  Science-Driven Cyberinfrastructure Needs in Solar-Terrestrial Research; Newark, New Jersey; Spring 2014","EarthCube Domain End-User Workshop:  Science-Driven Cyberinfrastructure Needs in Solar-Terrestrial Research; Newark, New Jersey; Spring 2014",One organization,AGS,EarthCube,3/1/2014,2/19/2014,Gelu Nita,NJ,New Jersey Institute of Technology,40.742335,-74.179341,Standard Grant,Ilia I. Roussev,2/28/2015,"$99,979.00 ",Alexander Kosovichev|Gregory Fleishman|Dale Gary|Andrew Gerrard,gnita@njit.edu,University Heights,Newark,NJ,71021982,9735965275,GEO,8074,1523|4444|7433|7556|OTHR,"The purpose of this 1-year project is to organize a 2.5-day EarthCube Workshop that brings together experts in observations, theory, data analysis, data-driven 3D modeling, data management and high performance computing of the Sun-Earth system.  The goal is to identify the current challenges and cyberinfrastructure needs related the access, sharing, visualization and synthesis of the existing and future large, multi-wavelength datasets covering solar-terrestrial observations and modeling all the way from the surface of the Sun to the Earth's upper atmosphere.  The intellectual merit of this activity will materialize in two ways. The workshop will introduce the solar-terrestrial community to the general vision behind the EarthCube framework while providing consensus feedback from this community to the EarthCube initiative.  The scientific challenges and related cyberinfrastructure needs identified during this workshop will drive subsequent activities aiming to implement cyberinfrastructure solutions.  These activities will result in expanding the computing infrastructure of the participating universities and accommodate postdoctoral and graduate student involvement from a wide range of disciplines including physics, computer sciences, and mathematics; thus, these activities will advance discovery and understanding while promoting teaching, training and learning, which will directly impact the students' careers.  Such activities will facilitate the transfer of innovative data analysis, data visualization, and data-driven modeling techniques to other fields of research that may benefit from a similar framework.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1419015,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1419015
1639683,DI,DI,EarthCube Data Infrastructure: Intelligent Databases and Analysis Tools for Geospace Data,EarthCube Data Infrastructure: Intelligent Databases and Analysis Tools for Geospace Data,One organization,ICER,AGS|EarthCube,8/15/2017,8/21/2017,Alexander Kosovichev,NJ,New Jersey Institute of Technology,40.742335,-74.179341,Standard Grant,Eva E. Zanzerkia,7/31/2019,"$500,000.00 ",Gelu Nita|Vincent Oria,alexander.g.kosovichev@njit.edu,University Heights,Newark,NJ,71021982,9735965275,GEO,6897|8074,026Z|7433,"Solar activity and variability are among the key factors determining the state of the Earth?s atmosphere, global trends and climate changes. Explosive events in the form of high-energy radiation and mass ejections cause geomagnetic storms in the ionosphere and magnetosphere, affecting biological systems, disrupting power grids, and communications.  For understanding and predicting the complex and evolving Earth system, it is critical to investigate its coupling to the space environment and to solar variability. To facilitate interdisciplinary research on solar influences, PI and the team will develop a unique data environment that will integrate new and archived satellite and ground-based observational data. The integrated data environment will allow researchers to efficiently access solar and geospace data and use them for studying fundamental problems of solar activity and variability and their impacts on Earth systems, as well as for developing new predictive capabilities. The innovative interdisciplinary approach for building an intelligent integrated database, developed in collaboration between heliophysicists and computer scientists, will contribute to knowledge discovery in the EarthCube and associated fields. The proposed activities will facilitate the transfer of innovative data analysis, data visualization, and data-driven modeling techniques to in-class teaching at the undergraduate and graduate levels and to other fields of research that may benefit from a similar framework.  The primary goal is to develop tools for data access and analysis that can be easily used by the Geoscience community for studying and modeling various components of the coupled Earth system. The project will develop innovative tools to extract and analyze the available observational and modeling data in order to enable new physics-based and machine-learning approaches for understanding and predicting solar activity and its influence on the geospace and Earth systems. The geospace data are abundant: several terabytes of solar and space observations are obtained every day. Finding the relevant information from numerous spacecraft and ground-based data archives and using it is a paramount, and currently a difficult task.   The scope of the project is to develop and evaluate data integration tools to meet common data access and discovery needs for two types of Heliophysics data: 1) long-term synoptic activity and variability, and 2) extreme geoeffective solar events. The project will integrate existing data resources, such as the Heliophysics Knowledge Database (HEK), Solar Dynamics Observatory Joint Science Operations Center (SDO JSOC), Virtual Solar Observatory (VSO), Heliophysics Integrated Observatory (HELIO), and others.   The methodology consists in the development of a data integration infrastructure and access methods capable of 1) automatic search and identification of image patterns and event data records produced by space and ground-based observatories, 2) automatic association of parallel multi-wavelength/multi-instrument database entries with unique pattern or event identifiers, 3) automatic retrieval of such data records and pipeline processing for the purpose of annotating each pattern or event according to a predefined set of physical parameters inferable from complimentary data sources, and 4) generation of a pattern or catalog and associated user-friendly graphical interface tools that are capable to provide fast search, quick preview, and automatic data retrieval capabilities",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639683,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639683
1740450,IA,IA,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative,ICER,ANTARCTIC EARTH SCIENCES|EarthCube,10/1/2017,9/14/2017,Mark Salvatore,AZ,Northern Arizona University,35.18519,-111.654707,Standard Grant,Gregory J.  Anderson,9/30/2020,"$167,228.00 ",,mark.salvatore@nau.edu,"ARD Building #56, Suite 240",Flagstaff,AZ,860110001,9285230886,GEO,5112|8074,7433,"Satellite imagery is rapidly transforming the way we see the planet, including our ability to study the most remote parts of the Arctic and Antarctic. Satellite imagery can help us map networks of rivers, study changes in the flow and thickness of glaciers, identify rock and soil types, and even find animals like penguins and seals. Because the availability of imagery in polar areas has increased rapidly over the last decade, we are now faced with a challenge: How do we scale-up the scientific discoveries that have been enabled by satellite imagery to larger spatial scales? Moving from small pilot-studies to pan-Arctic or pan-Antarctic analyses of geological and biological processes requires new infrastructure to link scientists, satellite imagery, and high performance computers. This new imagery-computing superhighway will make it easier for scientists to study processes at much larger spatial scales than has been previously possible. The project, called ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, aims to build the cyberinfrastructure required to make the most of satellite imagery for geosciences, starting with researchers working in polar areas, and then branching out to the larger non-polar community. The Broader Impacts of this proposal include the training of undergraduate and graduate students, as well as young and female scientists. Moreover, the scientific findings enabled by this proposed cyberinfrastructure will have immediate benefits for our ability to predict the future dynamics of the polar regions, and will be critical to the management of Arctic and Antarctic resources.  Polar geosciences stands at the precipice of a revolution, one enabled by the confluence of cutting edge analytical tools, petabytes of high-resolution imagery, and an ever growing array of high performance computing resources. With these tools at hand, we can look beyond incremental improvements in our understanding of the polar regions. Near-real time datasets of geological and biological importance at the continental scale are within our reach if we create those critical cyberinfrastructure components that allow the geosciences community to exploit existing assets and establish a common workflow for reproducible imagery-enabled science. The research objective of this proposal is to understand the biological, geological, and hydrological functioning of the polar regions at spatial scales heretofore beyond the reach of individual PIs, and to develop tools for imagery-enabled science that can be applied globally.The resulting cyberinfrastructure, which we call ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, is an extensible system for coupling open-source image analysis tools with the use of high performance and distributed computing (HPDC) for imagery-enabled geoscience research. We propose an Integration project to (1) develop open source image classification tools tailored to high-resolution satellite imagery of the Arctic and Antarctic to be used on HPDC resources, (2) create easy-to-use interfaces to facilitate the development and testing of algorithms for application specific geoscience requirements, (3) apply these tools through use cases that span the biological, hydrological, and geoscience needs of the polar community, (4) transfer these tools to the larger non-polar community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740450,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740450
1740667,IA,IA,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative,ICER,EarthCube,9/1/2017,9/13/2017,Nicholas McKay,AZ,Northern Arizona University,35.18519,-111.654707,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$69,277.00 ",,Nicholas.McKay@nau.edu,"ARD Building #56, Suite 240",Flagstaff,AZ,860110001,9285230886,GEO,8074,7433,"Data heterogeneity and accessibility are major barriers to scientific progress. Many community curated data repositories (CCDRs) have emerged in the paleogeosciences in response to the needs of their scientific communities, but these CCDRs are not well integrated. This project seeks to transform geoscientific research by breaking down the barriers among the CCDRs that serve geoscientists. All participating resources are closely engaged with their respective disciplinary communities and each is mobilizing data from its communities; the key need is to facilitate data interchange among CCDRs. The work will align several major CCDRs using a system that develops new shared services that rely on common standards, and demonstrates the kinds of new scientific insights that become possible with an integrated geoscientific infrastructure.  This collaborative project will accomplish the following: 1) A survey of existing data structures and standards, their suitability for paleogeoscience CCDRs and alignment with requirements identified by the paleogeosciences research coordination network, and their degree of adoption. This will lead to recommendations for adoption by participating resources (EarthChem, Flyover Country, IODP, LacCore/CSDCO, LinkedEarth, Neotoma) and documentation written for geoscientific audiences. 2) Alignment of participating CCDRs to recommended standards and development of a common API that will allow data exchange among CCDRs and to third-party users. 3) Development of an Annotation Engine, which will provide a credentialed, crowd-sourced system for scientists to flag changes to datasets, to connect datasets post hoc, to add context to legacy data, and to provide link-back notification among CCDRs when linked dataset attributes change. Annotation Engine will be embedded into existing scientific CCDR-based workflows, minimizing disruption to users. 4) Development of GeoNoteBase to enable scientists to generate citeable, reproducible workflows that draw information from across data resources, with workflows made available through keyword searches, with full attribution. This is a pilot effort to begin some of the work Through two pilot scientific projects, THROUGHPUT will test and evaluate these new capabilities and demonstrate kinds of new scientific insights that can be gained through integration.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740667,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740667
1540996,IA,IA,EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology,EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology,Collaborative,ICER,EarthCube,9/1/2015,7/28/2015,Nicholas McKay,AZ,Northern Arizona University,35.18519,-111.654707,Standard Grant,Eva Zanzerkia,8/31/2018,"$113,015.00 ",,Nicholas.McKay@nau.edu,"ARD Building #56, Suite 240",Flagstaff,AZ,860110001,9285230886,GEO,8074,7433,"Natural climate variability signficantly modulates anthropogenic global warming, and only paleoclimate observations can adequately constrain it. Moreover, such observations are most powerful when many records are brought together to provide a spatial understanding of past variability. However, there is currently no universal way to share paleoclimate data between users or machines, hindering integration and synthesis. Large-scale, international, paleoclimate data syntheses have a long and successful history, but have been needlessly labor-intensive. Recognizing that (1) paleoclimate data curation requires expert knowledge; (2) top-down data management approaches are ineffectual; (3) existing infrastructure does not foster standardization; there emerges a critical need for a flexible platform enabling crowdsourced data curation and standards development.The platform will be combined with editorial and community-driven processes which will result in a system that has the potential to engage a broad user base in geoscientific data curation. The proposed framework will lower barriers to participation in the geosciences, enabling more ""dark data"" to join the public domain using community-sanctioned protocols. The pilot project will facilitate the work of hundreds of paleoclimate scientists, accelerating scientific discovery and the dissemination of its results to society.  Semantic wikis provide a simple, intuitive interface to semantic languages and infrastructure that build on open Web architecture. Like traditional wikis, they enable the collaborative authoring of content. Secure access and time-stamped content also enable the tracking of changes and the accountability of users, as well as moderation capabilities by community members of recognized expertise. In contrast to traditional wikis, semantic wikis allow contributors to assign meaning to their content, specifying relationships between the objects they describe. This enables artificial intelligence reasoners to parse, process and translate these data into more useful forms. The technology is well-proven, scalable, and completely transparent to the user, requiring no computer science knowledge or more sophisticated technology than a web browser. The LinkedEarth Wiki will automatically translate this information into Linked Open Data, a universal format to share data across the Web. To demonstrate this concept?s broad applicability across paleoclimate science, the project?s target community is the PAGES2k consortium, an international collaboration dedicated to the climate of the Common Era. Social technologies will be developed to power collective curation, standards development and quality control by the community itself. The project will demonstrate applicability to other paleogeosciences, serving as a potential template for other geoscientific disciplines.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540996,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540996
1540938,IA,IA,EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science,EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science,Collaborative,ICER,EarthCube,9/1/2015,8/18/2015,Aaron Packman,IL,Northwestern University,42.056459,-87.675267,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$99,836.00 ",,a-packman@northwestern.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,GEO,8074,7433,"The Critical Zone (CZ) is the Earth's permeable near-surface layer from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. There has been a recent movement in the US Critical Zone Observatory (CZO) program to promote cross-CZO collaborations, with a major emphasis on biogeochemistry and related microbial ecology research. The project enable the CZ community to use software via training workshops, and better use CZ biogeochemistry and microbial ecology data. These objectives will be accomplished through a set of virtual and in-person workshops where CZ scientists have the opportunity to learn how to use the new cyberinfrastructure products, and use them to synthesize important biogeosciences and microbial ecology data from across numerous CZ sites. This effort will concurrently support the development of community-led standards for data collection and sharing. Direct involvement of software development teams as IA project personnel and collaborators will facilitate the training of members of the CZ community to use newly developed software. CZ scientists will then use these tools in a set of real-life use cases, in the form of synthesis of existing CZO data and analysis of collaboratively designed cross-CZO biogeochemical and metagenomic sample collection and analysis and ancillary measurements. This effort will not only train CZ scientists to use newly emerging EC CI tools, but also solicit community input on software improvements and identify remaining gaps and needs for further EarthCube CI development.  This project lays the groundwork for the whole-earth analysis and simulation capability envisioned through EarthCube, by bringing critical zone scientists together with hands-on training to test available cyberinfrastructure tools with comprehensive multiparameter datasets spanning a wide range of scales. The project will further improve access to the products of critical zone research by promoting the sharing, standardization, synthesis and analysis of biogeochemical and metagenomic data via EarthCube cyberinfrastructure, enabling a broader array of geosciences communities to shape future EarthCube activities and outcomes. This effort will support synthesis of broad swaths of data currently being collected at critical zone sites in the US and worldwide, as well as identify and fill key data gaps. The project will answer key biogeochemistry and microbial ecology questions, such as 1) measuring and modeling the fate of phosphorus during soil formation, and the relative role of bedrock vs. dust inputs to ecosystem phosphorus across diverse systems, and 2) evaluating nutrient availability and its impacts on microbial communities, growth rates and functions, across diverse systems. This project will also facilitate integrative scientific applications using critical zone data. The project will engender broad scientific dissemination of key EarthCube and Critical Zone Observatory products through targeted scientific outreach activities and engagement of diverse types of scientists, including a unique interaction between the computational science and geoscience communities. Key findings will be communicated through collaborative research and synthesis papers and presentations. This project will contribute extensive capacity-building in early-career researchers through targeted workshop participation. Finally, project findings and products will be used to inform future EarthCube development through the activity of the PIs and collaborators in the EarthCube Science Committee and Technology and Architecture Committee, as well as through the broader engagement of critical zone scientists into earthcube activities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540938,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540938
1213038,"DIBBS, BIGDATA, III",DIBBS,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,Collaborative,IIS,INFO INTEGRATION & INFORMATICS,10/1/2012,9/18/2012,Goce Trajcevski,IL,Northwestern University,42.056459,-87.675267,Standard Grant,Maria Zemankova,3/31/2018,"$300,000.00 ",,gocet25@iastate.edu,1801 Maple Ave.,Evanston,IL,602013149,8474913003,CSE,7364,7925,"Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.  This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1213038,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1213038
1550482,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,Collaborative,OAC,PETROLOGY AND GEOCHEMISTRY|Software Institutes|EarthCube,9/1/2016,8/19/2016,Mark Ghiorso,WA,OFM Research,47.650035,-121.961948,Standard Grant,Micah Beck,8/31/2019,"$734,907.00 ",,ghiorso@ofm-research.org,28430 NE 47th Place,Redmond,WA,980538841,4258804418,CSE,1573|8004|8074,7433|8004,"Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science.  They model the chemistry of melting of the interiors of planets as a result of heat flow within the body.  They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits.  They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles.  They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids.  Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies.   It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization.    This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics.  ENKI will provide software tools in computational thermodynamics and fluid dynamics.  It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks.  ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research.  ENKI development will be community driven.  Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples.  All software associated with this project will be released as open source.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550482,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550482
1829640,OTHER,OTHER,Collaborative Research: Inferring Cellular Lysis and Regeneration of Organic Matter by Marine Viruses,Collaborative Research: Inferring Cellular Lysis and Regeneration of Organic Matter by Marine Viruses,Collaborative,OCE,BIOLOGICAL OCEANOGRAPHY|EarthCube,10/1/2018,8/18/2018,Matthew Sullivan,OH,Ohio State University,40.0141905,-83.033103,Continuing grant,David L. Garrison,9/30/2021,"$275,268.00 ",,mbsulli@gmail.com,Office of Sponsored Programs,Columbus,OH,432101016,6146888735,GEO,1650|8074,1097|1315|1389|4444|8811|9117,"Viral infections of marine microbes can transform the fate of microbial populations that fuel global ocean biogeochemical cycles. For example, viral infections of microbes lead to the release of carbon and nutrients back into the environment. This regeneration of carbon and nutrients stimulates the activity of other microbes and diverts carbon and nutrients from larger organisms in marine food webs. Because virus-microbe infections are relatively specific, it is critical to identify those pairs of viruses and microbes that may disproportionally contribute to the turnover of carbon and nutrients in the ocean. This project will develop quantitative approaches and tools to quantify which viruses infect which microbes and to use these data to quantify how viral infections of microbes collectively shape nutrient and carbon cycles in the North Atlantic Ocean.  The project will analyze virus-microbe interactions in mesocosms at the Bigelow Laboratory for Ocean Sciences in mid-coast Maine and during open ocean expeditions to the Bermuda Atlantic Time-Series Study (BATS) site. An interdisciplinary team will leverage recent advances in molecular biology, computational biology, and mathematical modeling to identify virus-host partners and their impact on the movement of elements through marine systems. This project will support three graduate students, six undergraduate students and one postdoctoral researcher in an interdisciplinary context.  Research advances will be translated into reproducible software methods to be disseminated via the community cyberinfrastructure platform iVirus, with additional training materials presented as part of a viral methods and informatics workshop held at The Ohio State University.  The translation of discoveries to the public will be furthered by the involvement of journalism undergraduate students at the University of Tennessee-Knoxville.   This project builds upon advances in the molecular toolkit of viromics to develop an integrated approach to characterize lineage-specific rates of infection, lysis, and nutrient release induced by marine viruses in open ocean ecosystems. It will combine theory, in vitro experiments, and in situ sampling to (i) extend a robust inference method for estimating virus-microbe cross-infection networks from time-series data; (ii) establish and characterize in-vitro protocols for inferring cross-infectivity in complex communities using culture-independent methods; (iii) estimate lineage-specific rates of lysis and regeneration of nutrients in marine systems, including applications to coastal and open ocean ecosystems. Project aims focus on quantifying the extent to which virus-induced lysis and regeneration of carbon and nutrients is heterogeneously distributed across microbial populations. To do so, the project will incorporate time series measurements of abundance information (via metagenomes) and activity information (via metatranscriptomes). In so doing, it will advance efforts to understand community-scale interactions rather than those amongst a single virus-host pair. Theoretical methods and in vitro protocols will directly infer lineage-specific infection, lysis, and nutrient release rates in coastal- and open-ocean ecosystems in the North Atlantic Ocean.  Results will be used to identify key links that disproportionately influence bulk nutrient release.  A novel PCR-based approach will augment and validate the core inference approach. Overall, the project aims to enhance our understanding of how viruses contribute to marine ecosystem function.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1829640,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1829640
1343761,BB,BB,"EarthCube Building Blocks:   Specifying and Implementing ODSIP, A Data-Service Invocation Protocol","EarthCube Building Blocks:   Specifying and Implementing ODSIP, A Data-Service Invocation Protocol",One organization,ICER,EarthCube,9/15/2013,9/19/2013,David Fulker,RI,Open Source Project for Network Data Access Protocols,41.488606,-71.426829,Standard Grant,Eva E. Zanzerkia,1/31/2017,"$802,000.00 ",Mohan Ramamurthy|Steven Businger|Brian Blanton|Peter Cornillon,d.fulker@opendap.org,165 Dean Knauss Drive,Narragansett,RI,28821124,4012841304,GEO,8074,7433|9150,"This EarthCube Building Blocks project intends to build  ODSIP (Open Data Services Invocation Protocol) to provide a range of open specification in client/server libraries. The core idea is that key parts of EarthCube can be built effectively around clients and servers that employ a common and conceptually rich protocols for data acquisition. The components will be developed 1) an open specification for ODSIP (as a DAP4 extension); 2) a reference implementation of ODSIP in open-source libraries; and 3) client-server demonstrations that show how ODSIP supports three selected geoscience scenarios, each demonstration to be guided by a geoscientist. The three scenarios are: 1) accelerated visualization/analysis of model outputs on non-rectangular meshes (over coastal North Carolina); 2) dynamic downscaling of climate predictions for regional utility (over Hawaii); and 3) feature-oriented retrievals of satellite imagery (focusing on satellite-derived sea-surface-temperature fronts).  The broader implications of ODSIP include democratizing the use of geoscience data, illustrated in particular by how two of the three geoscience scenarios will benefit emergency managers and inform decision makers about region-specific risks of climate change. The broader implications also include strengthening common understandings across the EarthCube community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343761,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343761
1740627,IA,IA,Collaborative Research: EarthCube Integration--Brokered Alignment of Long-Tail Observations (BALTO),Collaborative Research: EarthCube Integration--Brokered Alignment of Long-Tail Observations (BALTO),Collaborative,AGS,EarthCube,9/15/2017,9/15/2017,James Gallagher,RI,Open Source Project for Network Data Access Protocols,41.488606,-71.426829,Standard Grant,Subhashree (Shree) Mishra,8/31/2020,"$326,435.00 ",David Fulker,j.gallagher@opendap.org,165 Dean Knauss Drive,Narragansett,RI,28821124,4012841304,GEO,8074,7433|9150,"This project, Brokered Alignment for Long-Tail Observations (BALTO), is supported under the EarthCube program.  The development team seeks to build a tool and infrastructure to allow the community to easily submit long-tail observational data that cannot easily fit into existing data repositories.  A data brokering technique will be developed to accomplish the goals of the study.  Graduate students, including from underrepresented minority groups, will receive training opportunities via this project.   To facilitate access to long-tail observations this work seeks to develop a core capability for the future EarthCube (EC) architecture in the Architecture and Implementation Plan - Brokered Alignment for Long-Tail Observations (BALTO). BALTO entails an open-source interface to discover, access and transform geoscience data sources through a brokering solution implemented by user-developed accessors. BALTO integrates core attributes of successful prior EC Building Blocks, BCube and ODSIP, to create a next generation EC capability. Leveraging its large installed base and its open-source flexibility, BALTO will extend Hyrax OPeNDAP's data server for ODSIP with capabilities for distributed brokering. Results from this project will demonstrate improved access and its impacts on scientific discovery via three NSF funded interdisciplinary use-cases that span geodesy, seismology, hydrology, oceanography, and geodynamics.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740627,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740627
1428421,OTHER,OTHER,MRI:  Acquisition of an X-Ray Fluorescence scanner for automated high-resolution sensing of Earth system archives,MRI:  Acquisition of an X-Ray Fluorescence scanner for automated high-resolution sensing of Earth system archives,One organization,EAR,MAJOR RESEARCH INSTRUMENTATION|INSTRUMENTATION & FACILITIES,8/1/2014,8/6/2014,Anders Carlson,OR,Oregon State University,44.563781,-123.279444,Continuing grant,David Lambert,7/31/2016,"$392,000.00 ",Joseph Stoner|Alan Mix|Julie Pett-Ridge|Robert Wheatcroft,acarlson@coas.oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,GEO,1189|1580,1189,"The growing evidence for pervasive impacts of humanity on Earth's natural systems makes it critical to assess natural variability in these diverse systems, the extent to which humans perturbed the mean state or extreme ends, and if these perturbations are beyond the systems natural variance. Changes in sediment chemistry reflect changes in physical, biological and anthropogenic processes shaping Earth's surface, recording change in climate, rivers, glacial ice, and ocean conditions and productivity, and humans. This Major Research Instrumentation award funds the acquisition of a high-resolution scanner for rapid, cost-effective and non-destructive analyses of major and trace elemental content of sedimentary records to address this research theme. Next-generation high-resolution scanners measure elemental concentrations from Aluminum to Uranium at high precision and high resolution, and co-register a high-resolution color image of the sample and/or an internal image. These data are collected orders of magnitude faster than traditional wet-chemistry and imaging approaches (hours vs. weeks-months), and the high resolution of scanning is impossible to achieve by physical sampling. This rapidity of data acquisition via next generation high resolution scanning at otherwise impossible resolutions opens new doors for tackling questions of Earth's natural systems behaviors over their full dynamic range including human impacts. The acquisition of a high-resolution elemental scanner and its pairing with the Oregon State University-Marine Geology Repository will have an immediate broad impact on the Pacific Northwest research community where this instrument is greatly needed, and service will extend to national and international research communities. The instrument will enhance at least 10 courses with for experiential learning, and train graduate and undergraduate students in data-intensive geochemical studies. The scanner will promote diversity in Earth sciences through its use of Research Experience for Undergraduates and Increasing Diversity in Earth Sciences programs, coaching underrepresented groups in state-of-the-art studies of Earth's natural systems.  Researchers at Oregon State and the College of Earth, Ocean, and Atmospheric Sciences (CEOAS) will use rapid, high-resolution, and accurate measurements of geochemical changes in sedimentary records to track variations in Earth's natural systems from sediment source to sink. A next-generation X-ray fluorescence (XRF) scanner purchased with this award will be an essential tool for the study of sedimentary geochemical archives of Earth system processes. OSU's acquisition of an XRF scanner would be the first such instrument in the Pacific Northwest, significantly advancing scientific exploration. CEOAS has extensive experience managing large labs, analytical equipment, and serving external users. The NSF-funded OSU Marine Geology Repository will house the XRF scanner, efficient for application to one of the nation's largest core archives and complementing existing tools including Geotek multisensing core logging tracks and medical CT-scanner. These tools will serve the OSU, regional, national and international research communities. Availability of advanced high-resolution sensing tools will support data-intensive projects consistent with modern ""big data"" initiatives like NSF's EarthCube. Specific research programs that the instrument will immediately catalyze include: 1) Reconstructing the Quaternary history of the Greenland, Cordilleran, Laurentide and Antarctic ice sheets and their sensitivity to global warming using existing and new sediment archives. 2) Paleoclimate studies of ocean climate adjacent to these ice sheets, tropical Pacific changes and their impact on the carbon cycle, and late-Holocene seasonal to century-scale changes in the high latitudes, all of which are to determine the range of natural variability relative to recent deviations. 3) Construct seasonal to century-scale changes in Earth's critical zone that extends from the top of vegetation to the base of weathered bedrock upon which humanity depends and is impacting. 4) Investigate preindustrial paleoenvironments and human-landscape interactions, a baseline for recent critical zone changes. 5) Document the frequency and severity of past earthquakes in the Pacific Northwest and their impacts on the critical zone.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1428421,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1428421
1440015,OTHER,OTHER,Collaborative Research: USG Support for the Past Global Changes Project International Program Office,Collaborative Research: USG Support for the Past Global Changes Project International Program Office,Collaborative,EAR,GLOBAL CHANGE,9/1/2014,7/20/2017,Loutre Marie-France,,Past Global Changes,46.9546808,7.4328125,Continuing grant,Jonathan Wynn,8/31/2018,"$1,833,884.00 ",,marie-france.loutre@pages.unibe.ch,Zaehringerstrasse 25,Bern          3012,,,316315608,GEO,1577,1304|5950|EGCH,"The Past Global Changes Program, is an open and international organization that coordinates global change science internationally, prioritizes key topics, facilitates cross-disciplinary research, promotes syntheses of results, and ensures dissemination of data, results, and knowledge. PAGES fills a unique niche and adds value to individual and national research. Over the next four years, PAGES will organize interdisciplinary working groups and cross-cutting activities that address relevant community-driven science issues, via open and international workshops, and synthesize knowledge and data. Its objectives are to link data products with Earth system modeling, translate regional knowledge of climatic and environmental changes into actionable information useful for decision-makers, and build capacity among young scientists and in nations less established in science. PAGES' activities all center around four themes: the Climate theme will inform climate projection efforts, and combined with modern and historical observational evidence will contribute to climate services. The Environment theme will address research topics central to Future Earth and inform environmental management efforts such as landscape conservation, ecosystem management, and fire control. The Humans theme will inform adaptation strategies and contribute to specific solutions for policy makers and resource managers; there is transformative potential to develop novel approaches involving social scientists or economists within this theme. Results from the cross-topical integrated activities on tipping points, extreme events, and warmer worlds, are targeted to inform risk assessments and natural disaster mitigation.  PAGES will exist under the new Future Earth program and intensify its partnership with the World Climate Research Program. The community-built scientific structure proposed here will align with these programs' agendas. PAGES' new structure will encourage integrative activities related to the sustainability issues prioritized by Future Earth and the World Climate Research Program.  In addition to the research output generated by scientific activities, PAGES will ensure broad impact by: identifying key science issues that can only be addressed through a transnational community approach; advocating for the incorporation of scientific evidence into wider Earth system science and international assessments; communicating scientific results to Global Environmental Change scientists, the media and public; contributing to data management in collaboration with NSF-EarthCube and NOAA; and building capacity among developing country and young scientists through active involvement, educational meetings, mentorships, and by organizing the Open Science and Young Scientists Meetings.  PAGES has a record of producing scientific output, including over 300 publications since 2010, with numerous major syntheses. Many publications obtained wide attention in the broader scientific community and contributed substantially to the latest Intergovernmental Panel on Climate Change (IPCC) assessment. Long-lived value was created by coherent data compilations that increased the number of available data by ~5 times. PAGES intends to support transnational working groups, to provide vehicles for data-model integration, and to facilitate community data syntheses that add expertise and value to individual results and contribute to international assessments such as the IPCC and Intergovernmental Platform on Biodiversity and Ecosystem Services. Under the new structure the Climate theme will address climate dynamics at the regional to global scales to obtain improved records of climate forcing, sensitivity and Earth system feedback. It will also assess model skills and provide insight into non-linearities, thresholds and the predictability of climate over long time intervals. The Environment theme will address the components of the biosphere that interact with climate change and introduce long-term feedback into the Earth system including biogeochemical cycling, ecosystem dynamics and ecosystem services. The Humans theme will address long-term environmental changes where humans are a major agent and where environmental changes have an effect on the functioning and well-being of ecosystem services and societies. In addition, cross-topical integrated activities such as thresholds and tipping points, extreme events, warmer worlds and data management, will encourage an interdisciplinary, synthesizing approach among the scientific community and other stakeholders.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440015,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440015
1238036,WORKSHOP,WORKSHOP,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,One organization,EAR,IIS SPECIAL PROJECTS|Software Institutes|EarthCube,4/1/2012,3/27/2012,Christopher Duffy,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,Barbara Ransom,3/31/2013,"$15,000.00 ",,cxd11@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,GEO,7484|8004|8074,7433,"EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences.  They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238036,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238036
1234050,WORKSHOP,WORKSHOP,Workshop: MYRES V - The Sedimentary Record of Landscape Dynamics,Workshop: MYRES V - The Sedimentary Record of Landscape Dynamics,One organization,EAR,GEOPHYSICS|GEOMORPHOLOGY & LAND USE DYNAM|SEDIMENTARY GEO & PALEOBIOLOGY|EarthCube,8/15/2012,8/21/2012,Elizabeth Hajek,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,H. Richard Lane,7/31/2014,"$70,000.00 ",,hajek@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,GEO,1574|7458|7459|8074,7433,"Sedimentary deposits comprise important records of information necessary to 1) quantitatively reconstruct and predict landscape dynamics across a range of timescales, 2) identify ancient tectonic and climatic conditions on Earth, and 3) understand landscape response to tectonic and climatic forcing. An outstanding challenge for geoscientists is to decode this archive in order to understand the evolution of Earth's environments over a range of temporal and spatial scales. To this end, the research interests of geomorphologists, sedimentologists, and stratigraphers have started to converge on processes that produce, transport, and deposit sediment over millennial timescales and beyond. Virtual Workshop and the final two days will revolve around discussion-stimulating field trips through erosional landscapes and stratigraphic deposits in Central Utah. This will be the fifth biennial Meeting of Young Researchers in Earth Science (MYRES) meeting. Early-career faculty and research scientists who participated in previous MYRES workshops have become leaders in their fields and helped build foundations for ongoing interdisciplinary collaborations. Continued support of MYRES will sustain and strengthen this grassroots initiative that has helped jumpstart research in important cutting-edge areas of Earth science.  As part of interdisciplinary community building and communication during MYRES V, time will be dedicated to learning about the NSF's EarthCube initiative and discussing how collaborative efforts between geodynamicists, geomorphologists, sedimentologists and stratigraphers (and others) could be aided by EarthCube. To this end, plenary discussion on the third day of the workshop will comprise a virtual workshop about EarthCube. This workshop will be hosted online (e.g., via Skype), will include EarthCube representatives, and, if possible, other interested virtual attendees.  Throughout the MYRES V workshop we will be discussing many topics listed in the EarthCube GEO Domain Virtual Workshop Goals, including 1) science drivers within and beyond MYRES V fields in the immediate future and up to 15 years out, 2) current challenges and limitations to interdisciplinary science (including data discovery, modeling, integrating disparate data types and sources, etc.), 3) existing database and modeling resources, and 4) tools, databases, and modeling capabilities that MYRES V communities would like to see developed.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1234050,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1234050
1343133,WORKSHOP,WORKSHOP,EarthCube End-User Domain Workshop for Rock Deformation and Mineral Physics Research,EarthCube End-User Domain Workshop for Rock Deformation and Mineral Physics Research,One organization,EAR,EarthCube,6/15/2013,6/7/2013,Chris Marone,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,Robin Reichlin,5/31/2015,"$99,999.00 ",Jay Bass,cjm38@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,GEO,8074,7433,"This workshop is to bring together the Rock Mechanics and COMPRESS Mineral Physics communities to gather requirements for the NSF-funded EarthCube initiative whose goal is to design and implement a new data and knowledge management system for the geosciences. The workshop will assemble a group of about 70 experts in rock deformation and high-pressure mineral physics to discuss their cyberinfrastructure needs in terms of data, modeling, and visualization. Goals will be to surface cyberinfrastructure needs that are presently holding these communities back and to enable their ability to address fault-slip behaviors, brittle-ductile transitions in lithologic materials, scientific drilling, deformation processes in subduction zones, and the physical, chemical, and electronic properties of geologic materials in the deep Earth. The two and a half day workshop will be held in Alexandria, Virginia in early November of 2013. A catalyzing issue of the workshop concerns the nature and reporting of experimental and observational data. Addressing these cyberinfrastructure needs represents a fundamental challenge to digital representation/integration and allowance of broad public access to data from this field that can be aided by involvement with EarthCube. This project is important for both the scientific and cyberinfrastructure development of the geosciences. Future progress of the geosciences will be based on the integration of rich and diverse datasets. This workshop will identify the needs of one of the most important and societally relevant groups in Earth Science. There will be a vast array of intellectually challenging tasks in describing and integrating data across a spectrum of scales as well as granularity that will be addressed at the workshop. Broader impacts of the work include provisions for improving public access to data from these fields, especially for those interested in studying earthquakes or assessing and manageing their impacts.  it also builds infrastructure for science in terms of helping create more effective and interoperable data and modeling frameworks. The workshop will also emphasize the inclusion of early career researchers, thus ensuring the needs are met of the next generation of rock deformation professionals.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343133,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343133
1450405,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,Steven Greybush,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,Alan Sussman,7/31/2018,"$99,953.00 ",,sjg213@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,CSE,1525|8004|8074,4444|7433|8009,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450405,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450405
1440291,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences,Collaborative,ICER,EarthCube,9/1/2014,8/14/2014,Christopher Duffy,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,Eva Zanzerkia,8/31/2016,"$147,000.00 ",,cxd11@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,GEO,8074,7433,"Geosciences software embodies crucial scientific knowledge, and as such it should be explicitly captured, curated, managed, and disseminated. The goal of this project is to create a system for software stewardship in geosciences that will empower scientists to manage their software as valuable scientific assets. Scientific software stewardship requires a combination of cyberinfrastructure, social infrastructure, and professional development infrastructure. The  framework will result in an open transparent and broader access to scientific software to other scientists, software professionals, students, and decision makers. It will significantly improve the adoption of open data and open software initiatives, improve reproducibility, and advance scientific scholarship.  The proposed research will advance knowledge and understanding of scientific software as a valuable community asset that is worth sharing, curating, cataloging, validating, reusing, and maintaining.  1) Facilitating software publication through TurboSoft, a personal assistant (analogous to TurboTax) that guides a user through best practices. Users will choose the degree of investment they are willing to make in componentizing, describing, licensing, and maintaining their software. The system will encourage open source publication, the formation of communities around the software, and set up mechanisms for software citation and credit.  2) Enabling broad software dissemination through GeoSoft, a ""software commons"" for geosciences that will support software contributions (prepared through TurboSoft or otherwise), software discovery through multi-faceted search, and foster social interactions through dynamic formation of communities of interest. GeoSoft will interoperate with existing software repositories and modeling frameworks in geosciences.  3) Providing just-in-time training materials through GeoCamp, an annotated collection of educational units ranging from basic education to professional training on all aspects of software stewardship. GeoCamp will be seamlessly integrated with TurboSoft and GeoSoft, and present a wide range of options for learning in the context of a user?s context of interaction with the framework or independently.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440291,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440291
1639707,BB,BB,EarthCube Building Blocks: Collaborative Proposal: The Power of   Many: Ensemble Toolkit for Earth Sciences,EarthCube Building Blocks: Collaborative Proposal: The Power of   Many: Ensemble Toolkit for Earth Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/8/2016,Guido Cervone,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,Eva Zanzerkia,8/31/2019,"$391,000.00 ",Michael Mann,guc18@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,GEO,8074,026Z|7433,"The study of hazards and renewable energy are paramount for the development and sustainability of society. Similarly, the emergence of new climatic patterns pose new challenges for future societal planning.  Geospatial data are being generated at unprecedented rate exceeding our analysis capabilities and leading towards a data-rich but knowledge-poor environment.  The use of advanced computing tools and techniques are playing an increasingly important role in contributing to solutions to problems of societal importance. This project will create specialized computational tools that will enhance the ability of scientists to effectively and efficiently study natural hazards and renewable energy. The use of these tools will support novel methods and the use of powerful computing resources in ways that are not currently possible.  Many scientific applications in the geosciences are increasingly reliant on ""ensemble-based"" methods to make scientific progress.  This is true for applications that are both net producers of data, as well as aggregate consumers of data.   In response to the growing importance and pervasiveness of ensemble-based applications and analysis, and to address the challenges of scale, simplicity and flexibility, the research team will develop the Ensemble Toolkit for Earth Sciences.  The Ensemble Toolkit will provide an important addition to the set of capabilities and tools that will enable the geosciences community to use high-performance computing resources more efficiently, effectively and in an extensible fashion. This project represents the co-design of Ensemble Toolkit for Earth Sciences and is a collective effort of an interdisciplinary team of cyberinfrastructure and domain scientists. It will also support the integration of the Ensemble Toolkit with a range of science applications, as well as its use in solving scientific problems of significant societal impact that are currently unable to utilize the collective capacity of supercomputers, campus clusters and clouds",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639707,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639707
1639710,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,Collaborative,ICER,EarthCube,9/1/2017,8/18/2017,Chris Marone,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,Eva Zanzerkia,8/31/2020,"$63,665.00 ",,cjm38@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,GEO,8074,7433,"When viewed at the micro-scale, rocks reveal structures that help to interpret the processes and forces responsible for their formation.  These microstructures help to explain phenomena that occur at the scale of mountains and tectonic plates.  Interpretation of microstructures formed in nature during deformation is aided by comparison with those formed during experiments, under known conditions of pressure, temperature, stress, strain and strain rate, and experimental rock deformation benefits from the ground truth offered through comparison with rocks deformed in nature.  However, the ability to search for relevant naturally or experimentally deformed microstructures is hindered by the lack of any database that contains these data.  The researchers collaborating on this project will develop a single digital data system for rock microstructures to facilitate the critical interaction between and among the communities that study naturally and experimentally deformed rocks.  To aid in the comparison of microstructures formed in nature and experiment, we will link to commonly used analytical tools and develop a pilot project for automatic comparison of microstructures using machine learning.     Rock microstructures relate processes at the microscopic scale to phenomena at the outcrop, orogen, and plate scales and reveal the relationships among stress, strain, and strain rate.  Quantitative rheological information is obtained through linked studies of naturally formed microstructures with those created during rock deformation experiments under known conditions.  The project will develop a single digital data system for both naturally and experimentally deformed rock microstructure data to facilitate comparison of microstructures from different environments.  A linked data system will facilitate interaction between practitioners of experimental deformation, those studying natural deformation and the cyberscience community.  The data system will leverage the StraboSpot data system currently under development in Structural Geology and Tectonics.  To develop this system requires: 1) Modification of the StraboSpot data system to accept microstructural data from both naturally and experimentally deformed rocks; and 2) Linking the microstructural data to its geologic context ? either in nature, or its experimental data/parameters.  The researchers will engage the rock deformation community with the goal of establishing data standards and protocols for data collection, and integrate our work with ongoing efforts to establish protocols and techniques for automated metadata collection and digital data storage.  To analyze the microstructures studied and/or generated by these communities, we will ensure StraboSpot data output is compatible with commonly used microstructural tools.  They will develop a pilot project for comparing and analyzing microstructures from different environments using machine-learning.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639710,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639710
1540979,IA,IA,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Russell Graham,PA,Pennsylvania State Univ University Park,40.814796,-77.865313,Standard Grant,Eva Zanzerkia,8/31/2019,"$199,895.00 ",Brian Bills,rwg12@psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,GEO,8074,7433,"Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.  The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540979,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540979
1639698,BB,BB,EarthCube Building Blocks: Collaborative Proposal: The Power of Many: Ensemble Toolkit for Earth Sciences,EarthCube Building Blocks: Collaborative Proposal: The Power of Many: Ensemble Toolkit for Earth Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/8/2016,Jeroen Tromp,NJ,Princeton University,40.343989,-74.651448,Standard Grant,Eva Zanzerkia,8/31/2019,"$339,754.00 ",Matthieu Lefebvre,jtromp@princeton.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,GEO,8074,7433,"The study of hazards and renewable energy are paramount for the development and sustainability of society. Similarly, the emergence of new climatic patterns pose new challenges for future societal planning.  Geospatial data are being generated at unprecedented rate exceeding our analysis capabilities and leading towards a data-rich but knowledge-poor environment.  The use of advanced computing tools and techniques are playing an increasingly important role in contributing to solutions to problems of societal importance. This project will create specialized computational tools that will enhance the ability of scientists to effectively and efficiently study natural hazards and renewable energy. The use of these tools will support novel methods and the use of powerful computing resources in ways that are not currently possible.  Many scientific applications in the geosciences are increasingly reliant on ""ensemble-based"" methods to make scientific progress.  This is true for applications that are both net producers of data, as well as aggregate consumers of data.   In response to the growing importance and pervasiveness of ensemble-based applications and analysis, and to address the challenges of scale, simplicity and flexibility, the research team will develop the Ensemble Toolkit for Earth Sciences.  The Ensemble Toolkit will provide an important addition to the set of capabilities and tools that will enable the geosciences community to use high-performance computing resources more efficiently, effectively and in an extensible fashion. This project represents the co-design of Ensemble Toolkit for Earth Sciences and is a collective effort of an interdisciplinary team of cyberinfrastructure and domain scientists. It will also support the integration of the Ensemble Toolkit with a range of science applications, as well as its use in solving scientific problems of significant societal impact that are currently unable to utilize the collective capacity of supercomputers, campus clusters and clouds",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639698,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639698
1835739,"DIBBS, BIGDATA, III",DIBBS,Elements: Data: U-Cube: A Cyberinfrastructure for Unified and Ubiquitous Urban Canopy Parameterization,Elements: Data: U-Cube: A Cyberinfrastructure for Unified and Ubiquitous Urban Canopy Parameterization,One organization,OAC,SPECIAL INITIATIVES|DATANET|LARS SPECIAL PROGRAMS|EarthCube,1/1/2019,8/18/2018,Daniel Aliaga,IN,Purdue University,40.4237054,-86.9233833,Standard Grant,Amy Walton,12/31/2021,"$599,999.00 ",Dev Niyogi|Rajesh Kalyanam,aliaga@cs.purdue.edu,Young Hall,West Lafayette,IN,479072114,7654941055,CSE,1642|7726|7790|8074,062Z|077Z|1525|4444|7923,"Urban canopy parameters (UCPs) can be used in model simulations to study the health and behavior of a city, determine the ability to sustain a growing population, and study potential impacts of extreme weather events.  The ability to identify and compute urban canopy parameters has been a missing element in city models; this project develops that capability for use in city design and analysis, integrating weather models and remote sensing data to infer a 3D model of cities of various sizes.  The project deploys innovative science-based analysis tools within an extensible, broadly-available cyberinfrastructure portal, allowing users to ingest satellite imagery and other geographic information system (GIS) data to calculate urban canopy parameters.  The cyberinfrastructure would improve urban modeling and planning, particularly for extreme weather events.  The tools and high-performance computing and storage resources would be usable by other researchers through a portal.  Potential beneficiaries include smaller and disadvantaged cities and countries without the resources for urban characterization and modeling necessary for such urban planning.  There are also plans to transfer the results of this research to communities beyond college students -- to local teachers and secondary students and museums, and to the GIS urban planning user communities at local, state, and international levels.  The project develops cyberinfrastructure which would use a novel inverse modeling approach incorporating satellite images, social science and urban zonal data, to infer a 3D model of a city from which urban canopy parameters could be derived for use in simulation models.   The focus is on weather modeling, urban parameterization and a desire to better understand sustainable urbanization.  The main cyberinfrastructure products will be 3D urban models and UCP values for urban locations.  These UCP parameters will be used for fine-scale urban weather modeling, and evaluation of various classification techniques and simulation models in an integrated portal.   The approach differs from prior work that relied on simple urban canopy models, either tuned for a large metropolis or assuming that all cities are the same.  The team uses a cyberinfrastructure platform at Purdue (HubZERO) and the Geospatial Data Analysis Building Blocks (GABBs), a suite of software modules developed during a previously funded NSF Data Infrastructure project.  The resulting platform can be deployed using Amazon Web Services, extending built-in geospatial data capabilities and providing a scalable CI solution.  This platform can be used by researchers to test predictive models or deploy applications that have been developed.  The team has cultivated relationships with the research communities and stakeholders relevant to the proposed research.  Through the World Urban Database and Access Portal Tools (WUDAPT) project -- a community-based project to gather a census of cities around the world -- the team is already connected to the urban planning community globally.  The project will improve urban weather modeling accuracy and increase availability of and access to the new techniques, capabilities and dedicated cyberinfrastructure.   The results have the potential to support city officials and urban planners, especially in regions with the fastest rate of urbanization and/or those in developing countries, where access to computational resources is likely to be limited.    This award by the NSF Office of Advanced Cyberinfrastructure will be jointly supported by the Division of Chemical, Bioengineering, Environmental, and Transport Systems, within the NSF Directorate for Engineering; and the Division of Atmospheric and Geospace Sciences and the Integrative and Collaborative Education and Research (ICER) Program, within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835739,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835739
1240144,OTHER,OTHER,"EarthCube Assessment of the 2012 State of Geoinformatics: A Community and Interagency Exploration of the LifeCycle, Citation, and Integration of Geoscience Data","EarthCube Assessment of the 2012 State of Geoinformatics: A Community and Interagency Exploration of the LifeCycle, Citation, and Integration of Geoscience Data",One organization,EAR,EarthCube,6/1/2012,2/12/2014,Peter Fox,NY,Rensselaer Polytechnic Institute,42.730172,-73.678803,Standard Grant,Barbara L. Ransom,5/31/2015,"$99,999.00 ",,foxp@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,GEO,8074,7433,"EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems.  This award funds broad, inclusive community interactions and a follow-on workshop to GeoData 2011 which will address gaps in the funding portfolio and development of EarthCube, a major new NSF initiative.  Some of these gaps include unresolved issues related to data accessibility and attribution.  Others involve interagency planning for improving interoperability and integration of large Federal data repositories with academic datasets and data management facilities.  The funded workshop and associated conversations will be open and available to the public via virtual participation of interested parties not included in the list of invitees. Broader impacts of the work include fostering of close interaction between communities and federal agencies that do not presently effectively interact with one another and to build alignment around a common goal of creating a new, interoperable paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1240144,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1240144
1639686,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Frank Spear,NY,Rensselaer Polytechnic Institute,42.730172,-73.678803,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$138,165.00 ",,spearf@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,GEO,8074,7433,"Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information.  The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams.  Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field.  The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return.  They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community.  The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks).  By the end of the project,  geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.  The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines.  The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in.  They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows.  The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo.  This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects.  At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists.  The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639686,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639686
1541017,IA,IA,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Collaborative,ICER,EarthCube,9/1/2015,8/19/2015,Frank Spear,NY,Rensselaer Polytechnic Institute,42.730172,-73.678803,Standard Grant,Eva Zanzerkia,12/31/2018,"$29,920.00 ",Sibel Adali,spearf@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,GEO,8074,7433,"A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services.   Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541017,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541017
1550281,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes,Collaborative,OAC,Software Institutes|EarthCube,9/1/2016,8/19/2016,Peter Fox,NY,Rensselaer Polytechnic Institute,42.730172,-73.678803,Standard Grant,Bogdan Mihaila,8/31/2019,"$450,001.00 ",,foxp@rpi.edu,110 8TH ST,Troy,NY,121803522,5182766000,CSE,8004|8074,7433|8004,"Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science.  They model the chemistry of melting of the interiors of planets as a result of heat flow within the body.  They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits.  They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles.  They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids.  Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies.   It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization.    This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics.  ENKI will provide software tools in computational thermodynamics and fluid dynamics.  It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks.  ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research.  ENKI development will be community driven.  Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples.  All software associated with this project will be released as open source.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550281,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550281
1639652,BB,BB,Earthcube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web,Earthcube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web,Collaborative,ICER,POLAR CYBERINFRASTRUCTURE|EarthCube,9/1/2016,9/16/2016,Ruth Duerr,NJ,Ronin Institute for Independent Scholarship Incorporated,40.8419109,-74.2000812,Standard Grant,Gregory J.  Anderson,8/31/2019,"$129,571.00 ",,ruth.duerr@ronininstitute.org,127 Haddon Place,Montclair,NJ,70432314,9737072485,GEO,5407|8074,7433,"This project develops an NSF EarthCube Building Block focused on Polar Data Science. The system will build upon work in Information Retrieval and Data Science and upon existing investment from NSF Polar, EarthCube, and from DARPA and NASA in this area. The system will collect, analyze, and make interactive the wealth of textual and scientific Polar data collected to date across the Deep web of scientific information -- scientific journals, multimedia information, scientific data, web pages, etc. The system builds upon fundamental research in text analysis, search, and visualization. Its primary goal is to unlock unstructured scientific data from 90+ data formats and to scale to 10s-100s of millions of records using the NSF XSEDE supercomputing resources. The system will perform information retrieval and machine learning on data crawled from the Polar Deep and Scientific web. Crawling will be informed by science questions crowdsourced through the EarthCube and Polar communities. The project is a collaboration with NSIDC, Ronin Institute, and the broader community including the newly funded Arctic Data Center led by NCEAS, to build our proposed system.  The result of periodic and regular crawling will be a Crawl Data Repository (CDR) of raw textual data e.g., web pages containing richly curated dataset abstract descriptions, news stories tied to datasets, ASCII note files and dataset descriptions, and other textual data available on or pointed to by Polar repositories as well as scientific data (HDF, Grib, NetCDF, Matlab, etc.). The CDR will be made available for historical and future analysis by the broader EarthCube and Polar communities. In addition, an extraction pipeline will generate an Extraction Data Repository (EDR) of machine learning features not previously present (geospatial, temporal, people, places, scientific publications and topics, etc.) that will be the basis of interactive, visual analytics over the Polar data resources. Information collected will assist in answering scientific questions such as these derived from the President?s National Strategy for the Arctic Region. To date, the team has also crowd sourced 30+ questions from the Polar community represented on CRYOLIST https://goo.gl/4dDyIS and will continue to solicit this feedback and use the information collected to aid science as prioritized by the community. They will also engage the community to assist in validating our system. This is not a predictive tool per-se ? though it can help to enable such predictions. Its focus is on building an operational and core capability for textual scientific data analysis, both retrospective, and prospective.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639652,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639652
1740572,IA,IA,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative,ICER,EarthCube,10/1/2017,9/14/2017,Shantenu Jha,NJ,Rutgers University New Brunswick,40.500819,-74.447399,Standard Grant,Gregory J.  Anderson,9/30/2020,"$622,786.00 ",,shantenu.jha@rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,GEO,8074,7433,"Satellite imagery is rapidly transforming the way we see the planet, including our ability to study the most remote parts of the Arctic and Antarctic. Satellite imagery can help us map networks of rivers, study changes in the flow and thickness of glaciers, identify rock and soil types, and even find animals like penguins and seals. Because the availability of imagery in polar areas has increased rapidly over the last decade, we are now faced with a challenge: To move from small pilot-studies to pan-Arctic or pan-Antarctic analyses of geological and biological processes requires new infrastructures that link scientists, satellite imagery, and fast computing. The project, called ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, aims to build the cyberinfrastructure required to make the most of satellite imagery for geosciences, starting with researchers working in polar areas, and then branching out to the larger community. The Broader Impacts of this proposal include the training of undergraduate and graduate students, as well as young investigators and female scientists. Moreover, the scientific findings enabled by this proposed cyberinfrastructure will have immediate benefits for our ability to predict the future dynamics of the polar regions, and critical to the management of Arctic and Antarctic resources.   Polar geosciences stands at the precipice of a revolution, one enabled by the confluence of cutting edge analytical tools, petabytes of high-resolution imagery, and an ever growing array of high performance computing resources. With these tools at hand, we can look beyond incremental improvements in our understanding of the polar regions. Near-real time datasets of geological and biological importance at the continental scale are within our reach if we create those critical cyberinfrastructure components that allow the geosciences community to exploit existing assets and establish a common workflow for reproducible imagery-enabled science. The research objective of this proposal is to understand the biological, geological, and hydrological functioning of the polar regions at spatial scales heretofore beyond the reach of individual PIs, and to develop tools for imagery-enabled science that can be applied globally. The resulting cyberinfrastructure, which we call ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, is an extensible system for coupling open-source image analysis tools with the use of high performance and distributed computing (HPDC) for imagery-enabled geoscience research. We propose a project to (1) develop open source image classification tools tailored to high-resolution satellite imagery of the Arctic and Antarctic to be used on HPDC resources, (2) create easy-to-use interfaces to facilitate the development and testing of algorithms for application specific geoscience requirements, (3) apply these tools through use cases that span the biological, hydrological, and geoscience needs of the polar community, (4) transfer these tools to the larger non-polar community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740572,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740572
1835692,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative,OAC,DATANET|EarthCube|Big Data Science &Engineering,1/1/2019,8/27/2018,Ivan Rodero,NJ,Rutgers University New Brunswick,40.500819,-74.447399,Standard Grant,Amy Walton,12/31/2022,"$899,139.00 ",Juan Jose Villalobos,irodero@cac.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,7726|8074|8083,062Z|077Z|7925|8083,"This project develops a real-time processing system capable of handling a large mix of sensor observations. The focus of this system is automation of the detection of natural hazard events using machine learning, as the events are occurring.  A four-organization collaboration (UNAVCO, University of Colorado, University of Oregon, and Rutgers University) develops a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  This work will support rapid analysis and understanding of data associated with hazardous events (earthquakes, volcanic eruptions, tsunamis).    This project uses a collaboration between computer scientists and geoscientists to develop a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  It focuses on the aggregation and integration of a large number of data streams into a coherent system that supports analysis of the data streams in real-time. The framework will offer machine-learning-based tools designed to detect signals of events, such as earthquakes and tsunamis, that might only be detectable when looking at a broad selection of observational inputs.  The architecture sets up a fast data pipeline by combining a group of open source components that make big data applications viable and easier to develop. Data sources for the project draw primarily upon the 1500+ sensors from the EarthScope networks currently managed by UNAVCO and the Incorporated Research Institutions for Seismology (IRIS), as well as the Ocean Observatories Initiative (OOI) cabled array data managed by Rutgers University.  Machine learning (ML) algorithms will be researched and applied to the tsunami and earthquake use cases.  Initially, the project plans to employ an advanced convolutional neural network method in a multi-data environment.  The method has only been applied to seismic waveforms, so the project will explore extending the method to a multi-data environment.  The approach is expected to be extensible beyond detection and characterization of earthquakes to include the onset of other geophysical signals such as slow-slip events or magmatic intrusion, expanding the potential for new scientific discoveries.  The framework is applied to use cases in the Cascadia subduction zone and Yellowstone: these locations combine the expertise of the science team with locations where EarthScope and OOI have the greatest concentration of instruments.  The architecture will be transportable and scalable, running in a Docker environment on laptops, local clusters and the cloud.  Integral to the project will be development, documentation and training using collaborative online resources such as GitLab and Jupyter Notebooks, and utilizing NSF XSEDE resources to make larger datasets and computational resources more widely available.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Program and Division of Earth Sciences within the NSF Directorate for Geosciences, the Big Data Science and Engineering Program within the Directorate for Computer and Information Science and Engineering, and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the Office of Advanced Cyberinfrastructure.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835692,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835692
1440288,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Digital Crust: An Exploratory Environment for Earth Science Research and Learning,EarthCube Building Blocks: Collaborative Proposal: Digital Crust: An Exploratory Environment for Earth Science Research and Learning,Collaborative,ICER,EarthCube,9/1/2014,8/8/2014,Ying Fan Reinfelder,NJ,Rutgers University New Brunswick,40.500819,-74.447399,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$249,570.00 ",,yingfan@eps.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,GEO,8074,7433,"This project develops the Digital Crust, an online workspace where the geosciences community can contribute data and knowledge, visualize, explore, synthesize and test multiple hypotheses across space-time and themes, and derive 4D data product from multiple data.The platform can serve as a resource to bring together geoscientists working on separate aspects of the Earth system, by bringing their data/ideas together and by providing an environment to view the Earth from different perspectives. It will also be a ""one-stop shop"" for Earth science educators to expose the growing minds to the multi-faceted nature of Earth science problems and to see data and knowledge gaps which are powerful motivators for the young (not all problems have been solved ? there is a place for me to contribute).   The Digital Crust platform prototype will demonstrate technology that has the potential to transform the way geoscientists  conduct research and learning, by (1) linking existing data repositories on all aspects of the Earth?s crust created by all disciplines of geosciences, communities as well as individuals, (2) creating a multi-context environment (e.g., tectonics, structural geology, stratigraphy, sedimentology, geomorphology, paleontology, archeology, mineralogy, geochemistry, soil science, hydrology, terrestrial ecology) at any given space (xyz) and time (t) for synthesis-type explorations, hypothesis-testing or learning, (3) allowing for multi-scale (e.g., outcrop to continent) data extractions and downloads for all research and learning applications, and (4) exposing data-knowledge gaps to identify the most rewarding future investments. Hosting multiple data types and sometimes conflicting interpretations and hypotheses of Earth processes will promote community discussion and debate on Earth processes that will foster interaction, collaboration, and data/idea sharing among scientists who might otherwise never have met. From the CI perspective, Digital Crust leverages and links with existing Building Blocks, explores the application of ""loose-schema"", noSQL databases to allow the flexibility necessary in a geoscience research database, and utilizes a modular software design to facilitate long-term maintenance and evolution of the platform.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440288,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440288
1639694,BB,BB,EarthCube Building Blocks: Collaborative Proposal: The Power of Many: Ensemble Toolkit for Earth Sciences,EarthCube Building Blocks: Collaborative Proposal: The Power of Many: Ensemble Toolkit for Earth Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/8/2016,Shantenu Jha,NJ,Rutgers University New Brunswick,40.500819,-74.447399,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$509,643.00 ",,shantenu.jha@rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,GEO,8074,7433,"The study of hazards and renewable energy are paramount for the development and sustainability of society. Similarly, the emergence of new climatic patterns pose new challenges for future societal planning.  Geospatial data are being generated at unprecedented rate exceeding our analysis capabilities and leading towards a data-rich but knowledge-poor environment.  The use of advanced computing tools and techniques are playing an increasingly important role in contributing to solutions to problems of societal importance. This project will create specialized computational tools that will enhance the ability of scientists to effectively and efficiently study natural hazards and renewable energy. The use of these tools will support novel methods and the use of powerful computing resources in ways that are not currently possible.  Many scientific applications in the geosciences are increasingly reliant on ""ensemble-based"" methods to make scientific progress.  This is true for applications that are both net producers of data, as well as aggregate consumers of data.   In response to the growing importance and pervasiveness of ensemble-based applications and analysis, and to address the challenges of scale, simplicity and flexibility, the research team will develop the Ensemble Toolkit for Earth Sciences.  The Ensemble Toolkit will provide an important addition to the set of capabilities and tools that will enable the geosciences community to use high-performance computing resources more efficiently, effectively and in an extensible fashion. This project represents the co-design of Ensemble Toolkit for Earth Sciences and is a collective effort of an interdisciplinary team of cyberinfrastructure and domain scientists. It will also support the integration of the Ensemble Toolkit with a range of science applications, as well as its use in solving scientific problems of significant societal impact that are currently unable to utilize the collective capacity of supercomputers, campus clusters and clouds",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639694,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639694
1542110,RCN,RCN,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,Collaborative,ICER,EarthCube,9/1/2015,8/4/2015,Shantenu Jha,NJ,Rutgers University New Brunswick,40.500819,-74.447399,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$200,879.00 ",,shantenu.jha@rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,GEO,8074,7433,"One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs.  Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.  The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed.  This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training.  The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1542110,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1542110
1639658,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,Collaborative,ICER,EarthCube,9/1/2017,8/18/2017,Matty Mookerjee,CA,Sonoma State University,38.338608,-122.674836,Standard Grant,Eva E. Zanzerkia,8/31/2020,"$93,791.00 ",Gurman Gill,matty.mookerjee@sonoma.edu,1801 East Cotati Avenue,Rohnert Park,CA,949283609,7076643972,GEO,8074,7433,"When viewed at the micro-scale, rocks reveal structures that help to interpret the processes and forces responsible for their formation.  These microstructures help to explain phenomena that occur at the scale of mountains and tectonic plates.  Interpretation of microstructures formed in nature during deformation is aided by comparison with those formed during experiments, under known conditions of pressure, temperature, stress, strain and strain rate, and experimental rock deformation benefits from the ground truth offered through comparison with rocks deformed in nature.  However, the ability to search for relevant naturally or experimentally deformed microstructures is hindered by the lack of any database that contains these data.  The researchers collaborating on this project will develop a single digital data system for rock microstructures to facilitate the critical interaction between and among the communities that study naturally and experimentally deformed rocks.  To aid in the comparison of microstructures formed in nature and experiment, we will link to commonly used analytical tools and develop a pilot project for automatic comparison of microstructures using machine learning.     Rock microstructures relate processes at the microscopic scale to phenomena at the outcrop, orogen, and plate scales and reveal the relationships among stress, strain, and strain rate.  Quantitative rheological information is obtained through linked studies of naturally formed microstructures with those created during rock deformation experiments under known conditions.  The project will develop a single digital data system for both naturally and experimentally deformed rock microstructure data to facilitate comparison of microstructures from different environments.  A linked data system will facilitate interaction between practitioners of experimental deformation, those studying natural deformation and the cyberscience community.  The data system will leverage the StraboSpot data system currently under development in Structural Geology and Tectonics.  To develop this system requires: 1) Modification of the StraboSpot data system to accept microstructural data from both naturally and experimentally deformed rocks; and 2) Linking the microstructural data to its geologic context ? either in nature, or its experimental data/parameters.  The researchers will engage the rock deformation community with the goal of establishing data standards and protocols for data collection, and integrate our work with ongoing efforts to establish protocols and techniques for automated metadata collection and digital data storage.  To analyze the microstructures studied and/or generated by these communities, we will ensure StraboSpot data output is compatible with commonly used microstructural tools.  They will develop a pilot project for comparing and analyzing microstructures from different environments using machine-learning.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639658,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639658
1340265,RCN,RCN,"EC3 - Earth-Centered Communication for Cyberinfrastructure:  Challenges of field data collection, management, and integration","EC3 - Earth-Centered Communication for Cyberinfrastructure:  Challenges of field data collection, management, and integration",One organization,ICER,EarthCube,9/15/2013,8/26/2013,Matty Mookerjee,CA,Sonoma State University,38.338608,-122.674836,Standard Grant,Eva Zanzerkia,8/31/2016,"$299,329.00 ",Thomas Shipley|Basil Tikoff|Amy Ellwein|James Bowring,matty.mookerjee@sonoma.edu,1801 East Cotati Avenue,Rohnert Park,CA,949283609,7076643972,GEO,8074,7433,"Scientists who work in the field have a common set of issues when it comes to documenting,storing, and representing data. Members from the different geological communities would benefitgreatly from the opportunity to discuss the types of data that they collect in the field with a group of cyberinfrastructure and software development professionals and researchers. By holding meetings in the field, the computer scientists will gain a better appreciation for the types of data that are typically collected in the field, common methods for collecting those data, the field tools/technology that are employed, data recording conventions, and the types of question typically addressed with these data. ""The field"" is an ideal location for appreciating geological concepts, and the very act of being in the field, together with other professionals, often foster personal connections that promote successful collaborations and the exchange of ideas.   Work on this RCN will facilitate digitization of geological field data.  The researchers will take steps to: 1) Document what exists currently for field data collection; 2) Assemble a community for discussing and exploring field data collection issues, specifically targeting young investigators; 3) Motivate distinct communities to work together on common issues associated with digitization; 4) Evaluate what is missing in the creation of open and accessible data. The objective of the RCN Proposal is to develop communication between cyberinfrastructure community and those involved in field-based, solid earth geoscience.  In order to facilitate knowledge of the activities, they will conduct a series of both informal and formal meetings as national meetings - workshops at GSA and townhall meetings at AGU and AAPG).  The goal of the initial meetings will be to: 1) foster community awareness of EarthCube-related activities, 2) discover and catalog the additional existing resources, 3) determine ways of giving publication ?credit? for recording and sharing digital data, 4) identify attributes of a clearinghouse website that would be most useful, and 5) find ways of motivating the community to move quickly toward digital data collection/conversion and data sharing.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1340265,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1340265
1450170,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,William Capehart,SD,South Dakota School of Mines and Technology,44.07343,-103.206296,Standard Grant,Bogdan Mihaila,7/31/2019,"$183,956.00 ",,William.Capehart@sdsmt.edu,501 East Saint Joseph Street,Rapid City,SD,577013995,6053941218,CSE,1525|8004|8074,4444|7433|8009|9150,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450170,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450170
1835573,"SI2, CSSI",SI2,Elements: Software: The Integrated Geoscience Observatory (InGeO),Elements: Software: The Integrated Geoscience Observatory (InGeO),One organization,OAC,Software Institutes|EarthCube|Space Weather Research,1/1/2019,9/11/2018,Asti Bhatt,CA,SRI International,37.45738,-122.175802,Standard Grant,Stefan Robila,12/31/2021,"$599,750.00 ",Russell Cosgrove,asti.bhatt@sri.com,333 RAVENSWOOD AVE,Menlo Park,CA,940253493,6508592651,CSE,8004|8074|8089,026Z|062Z|077Z|4444|7923|8004,"This award will support the development of the Integrated Geoscience Observatory (InGeO). InGeO is an online platform that integrates data and associated software tools contributed by researchers into a unified toolset to enable studying the convergent, systems science. Complex processes in the Sun-Earth system affect the habitability of earth. As technological progress continues, our society also becomes increasingly vulnerable to the disruptions introduced by these complex processes. Study of the Sun-Earth system is traditionally broken-up into separate geoscience disciplines, typically focusing on a specific region of the system. However, often the interaction between several regions end up significantly affecting terrestrial systems. For example, a chain of processes occurring between the Sun, magnetosphere, and ionosphere often result in loss of GPS signal that severely affects all the communication/navigation and infrastructure that depends on this technology. To broach the larger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods.  To promote systems science, InGeO creates an integrated package of software tools specifically designed to help researchers find and integrate diverse observational data and distributes this toolkit to the community in the most flexible way possible. Building on the pilot project supported by the NSF EarthCube program, the specific features of the toolkit include: (a) linking diverse data sets from multiple observational data repositories; (b) using these data within a shareable computing environment, complete with a full selection of standard numerical and data-processing tools; and  (c) enabling an ever growing assortment of targeted, user-contributed tools, such as assimilative models or interpolation methods. The toolkit can be accessed and used either through a web-based computing environment or by downloading Docker containers for local installation, with a nearly seamless transition between the two. The toolkit is open-source and ensures credit attribution to data and software contributors, and the InGeO team works with members of scientific community (especially students and early career researchers) to improve the toolkit and build a sustainable, more connected user-base.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Activities Program within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835573,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835573
1639741,BB,BB,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Asti Bhatt,CA,SRI International,37.45738,-122.175802,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$104,999.00 ",,asti.bhatt@sri.com,333 RAVENSWOOD AVE,Menlo Park,CA,940253493,6508592651,GEO,8074,7433,"Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility.   GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639741,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639741
1541057,IA,IA,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,Collaborative,ICER,EarthCube,9/1/2015,7/28/2015,Asti Bhatt,CA,SRI International,37.45738,-122.175802,Standard Grant,Eva E. Zanzerkia,12/31/2017,"$517,718.00 ",Russell Cosgrove,asti.bhatt@sri.com,333 RAVENSWOOD AVE,Menlo Park,CA,940253493,6508592651,GEO,8074,7433,"The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.  EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541057,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541057
1252238,WORKSHOP,WORKSHOP,EarthCube Domain End-User Workshop:  Engaging the Critical Zone community to bridge long tail science with big data,EarthCube Domain End-User Workshop:  Engaging the Critical Zone community to bridge long tail science with big data,One organization,EAR,EarthCube,10/1/2012,9/26/2012,Anthony Aufdenkampe,PA,Stroud Water Research Center,39.859249,-75.783142,Standard Grant,Enriqueta Barrera,9/30/2013,"$99,922.00 ",Christopher Duffy|Gregory Tucker,aaufdenkampe@limno.com,970 Spencer Road,Avondale,PA,193119514,6102682153,GEO,8074,7433,"Critical Zone (CZ) scientists take as their charge the effort to integrate theory, models and data from the multitude of disciplines studying processes on the Earth's surface - from the atmosphere at the vegetation's canopy to the lower boundary of actively cycling ground waters.  As such, critical zone scientists and their data managers are at the front line of efforts to effectively compile and use the ""dark data in the Long Tail"" of earth science and integrate that data with the ""Big Data"" produced by hydrologists, atmospheric scientists, geospatial modelers and molecular biologists.    The NSF EarthCube initiative recently solicited proposals for domain workshops ""designed to listen to the needs of the end-user groups that make up the geosciences and to understand better how data-enabled science can help them achieve their scientific goals.""  The proponents will convene a workshop to bring together critical zone domain scientists with computer scientists active in EarthCube.   This workshop would thus serve two objectives: (1) engage approximately 45 cyber-literate critical zone scientists in the EarthCube process; and (2) inform about 20 of EarthCube's cyberscientists of the diversity needs of CZ science.  The overall goal of the workshop would be to develop a set of unifying requirements for the integration of ""long tail"" data and ""big data"" and to develop an interactive community of domain and cyber scientists to pursue solutions.    There are many examples of how cyber-infrastructure developed for geoscientists have broader impacts to the public.  The national weather service data and model forecasts are highlighted on television and other media outlets.  Fishermen, rafters and canoeists rely on USGS gauging data for their recreational activities.  The Model My Watershed platform is harnessing GIS and hydrological modeling for educational purposes in classrooms and informal settings and also by citizen scientists.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252238,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252238
1339834,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: The Community-Driven BiG CZ Software System for Integration and Analysis of Bio- and Geoscience Data in the Critical Zone,Collaborative Research: SI2-SSI: The Community-Driven BiG CZ Software System for Integration and Analysis of Bio- and Geoscience Data in the Critical Zone,Collaborative,OAC,ECOSYSTEM STUDIES|EAR|GEOBIOLOGY & LOW TEMP GEOCHEM|CZO: CRITICAL ZONE OBSER SOLIC|Software Institutes|EarthCube,12/1/2013,9/20/2013,Anthony Aufdenkampe,PA,Stroud Water Research Center,39.859249,-75.783142,Standard Grant,Rajiv Ramnath,11/30/2017,"$1,366,089.00 ",Kerstin Lehnert|Jeffery Horsburgh|Robert Cheetham|Emilio Mayorga,aaufdenkampe@limno.com,970 Spencer Road,Avondale,PA,193119514,6102682153,CSE,1181|6898|7295|7693|8004|8074,7433|8009,"The Critical Zone (CZ) science community takes as its charge the effort to integrate theory, models and data from the multitude of disciplines collectively studying processes on the Earth's surface. The Critical Zone is Earth's permeable near-surface layer - from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. The Critical Zone was a term coined by the National Research Council's Basic Research Opportunities in the Earth Sciences (BROES) Report (2001) to highlight the imperative for a new approach to thoroughly multi-disciplinary research on the zone of the Earth?s surface that is critical to sustaining terrestrial life on our planet. In January 2013, 103 members of the CZ community met for the CZ-EarthCube Domain Workshop (NSF Award #1252238) to prioritize the CZ community's key science drivers, key computational and information technology (""cyber"") challenges and key cyber needs. They identified that the central scientific challenge of the critical zone science community is to develop a ""grand unifying theory"" of the critical zone through a theory-model-data fusion approach.  Work participants unanimously described that the key missing need of this approach was a future cyberinfrastructure for seamless 4D visual exploration of the integrated knowledge (data, model outputs and interpolations) from all the bio and geoscience disciplines relevant to critical zone structure and function, similar to today?s ability to easily explore historical satellite imagery and photographs of the earth's surface using Google Earth.  This project takes the first ""BiG"" steps toward answering that need.  The overall goal of this project is to co-develop with the CZ science and broader community, including natural resource managers and stakeholders, a web-based integration and visualization environment for joint analysis of cross-scale bio and geoscience processes in the critical zone (BiG CZ), spanning experimental and observational designs. Our Project Objectives are to: (1) Engage the CZ and broader community to co-develop and deploy the BiG CZ software stack; (2) Develop the BiG CZ Portal web application for intuitive, high-performance map-based discovery, visualization, access and publication of data by scientists, resource managers, educators and the general public; (3) Develop the BiG CZ Toolbox to enable cyber-savvy CZ scientists to access BiG CZ Application Programming Interfaces (APIs); and (4) Develop the BiG CZ Central software stack to bridge data systems developed for multiple critical zone domains into a single metadata catalog. The entire BiG CZ Software system will be developed on public repositories as a modular suite of fully open source software projects.  It will be built around a new Observations Data Model Version 2.0 (ODM2) that is being developed by members of the BiG CZ project team, with community input, under separate funding (NSF Award #1224638).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339834,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339834
1332257,OTHER,OTHER,Integrated Data Management System for Critical Zone Observatories,Integrated Data Management System for Critical Zone Observatories,One organization,EAR,GLOBAL CHANGE|GEOBIOLOGY & LOW TEMP GEOCHEM|CZO: CRITICAL ZONE OBSER SOLIC,12/1/2012,5/2/2014,Anthony Aufdenkampe,PA,Stroud Water Research Center,39.859249,-75.783142,Standard Grant,Paul Filmer,3/31/2016,"$1,532,537.00 ",,aaufdenkampe@limno.com,970 Spencer Road,Avondale,PA,193119514,6102682153,GEO,1577|7295|7693,7693,"The objective of the project is to develop a comprehensive, integrated data management system for the NSF-funded Critical Zone Observatory (CZO) program, called CZOData. The overall goal for CZOData is to support, empower, and broaden the impact of CZO science and maximize the return on investment of the CZO program by transforming capabilities to easily share, integrate, analyze and preserve the wide range of multi-disciplinary data generated within and across CZOs.   The CZOData design is based on the experience of the collaborative project team in building the current CZOData prototype and on other foundational cyber-infrastructure systems.  The principal investigators at the University of Boulder and the Stroud Water Research Center are Earth surface scientists who provided high-level oversight of the CZOData prototype and provide a direct link to the scientific community collecting and using CZO data.  Team members at San Diego Supercomputing Center (SDSC) and Utah State University (USU) are primary developers of the Hydrological Information System (HIS) developed by the Consortium for the Advancement of Hydrological Sciences, Inc. (CUAHSI).  Team members at Columbia University developed and lead the Integrated Earth Data Applications (IEDA), Geoinformatics for Geochemistry (GfG), EarthChem and the System for Earth Sample Registration (SESAR) projects.  Team members at the Applied Physics Laboratory at the University of Washington developed and maintain the Northwest Association for Ocean Observing Systems (NANOOS) Visualization System (NVS).    This project combines state-of-the-art computer science and cyber-infrastructure technologies and international metadata standards with a strong effort to engage the science community in the process of developing and testing the CZOData system.  This collaborative, community-based approach to developing scientific cyber-infrastructure has been actively encouraged by the NSF-supported EarthCube initiative and thus complements those goals (http://www.nsf.gov/geo/earthcube/). The approach with CZOData is based on integrating site-based data with system capabilities' such as consistent data publication, cataloguing, discovery and access infrastructure. These new capabilities will strongly leverage other CI efforts described above. The resulting system will support new CZO research that was not possible before while easing the data management burden on CZO scientists.  The vision is that the proposed CZOData will serve as a model for the greater Earth surface science community. The CZOData project is a collaborative, community-guided cyber-infrastructure project for integrating multi-disciplinary data and providing interoperability with other systems. Thus, CZOData will inform the development of other large geoinformatics initiatives, such a the Open Geospatial Consortium (OGC), Long-Term Environmental Research (LTER) observatories, DataOne, OpenTopography, the Implementing Organization of the International Geosample Number (IGSN e.v.), and the Integrated Ocean Observing System (IOOS). Also, by incorporating system research and development with graduate education, we will move towards cultivating a new generation of researchers skilled in both different facets of environmental research and in advanced information management and computing.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1332257,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1332257
1450195,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,Robert Fovell,NY,SUNY at Albany,42.68827,-73.819492,Standard Grant,Bogdan Mihaila,7/31/2019,"$246,111.00 ",,rfovell@albany.edu,1400 WASHINGTON AVE MSC 100A,Albany,NY,122220100,5184374974,CSE,1525|8004|8074,4444|7433|8009,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450195,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450195
1821311,OTHER,OTHER,Collaborative Research: Using Precursor Information to Update Probabilistic Hazard Maps,Collaborative Research: Using Precursor Information to Update Probabilistic Hazard Maps,Collaborative,DMS,OFFICE OF MULTIDISCIPLINARY AC|XC-Crosscutting Activities Pro|CDS&E-MSS|EarthCube,9/1/2018,8/1/2018,Abani Patra,NY,SUNY at Buffalo,43.000809,-78.78897,Standard Grant,Christopher Stark,8/31/2020,"$200,000.00 ",E. Bruce Pitman|Greg Valentine,abani@buffalo.edu,520 Lee Entrance,Buffalo,NY,142282567,7166452634,MPS,1253|7222|8069|8074,9263,"In many natural hazard scenarios, precursory information becomes available before an event. Responding to an impending hazard means that time is limited; analysis and decision-making must proceed on an accelerated timetable. This project develops methodology for responding to signals from a variety of data sources that have been interpreted as suggesting that a volcanic eruption is threatened. Prior research has attempted to elucidate how physical processes predict an eruption. For example, seismic signals, gas emissions, and tilt data have all been implicated as volcanic eruption precursors. But none of these signals have been shown to make robust predictions. This project undertakes a different approach, developing methods to integrate precursor data, decide on the likely evolution of eruption scenarios, and rapidly build simulation studies and statistical emulators, to provide timely and actionable information on which to decide a course of action. The new methodology will provide tools to rapidly construct probability-based hazard forecast maps for cascading geophysical events.  The prediction and management of extreme events, from volcanic eruptions to floods to stock market crashes, requires a careful analysis of the hazard event, its inputs, and its consequences. Data of different kinds, and of differing fidelity, must be incorporated into a detailed analysis of the impending hazard. The investigators will build upon their past research characterizing volcanic hazards. This work provides long-term hazard analysis and provides a bridge from incoming precursory information, such as seismic signals and gas emission, to eruption impacts, such as likely paths of mass flows. The investigators aim to develop methodology to update input distributions for physical simulations and to integrate outcomes into new adaptive designs for surrogate construction, rapid evaluations of limited simulations, and massive parallel emulation. The project will also investigate a methodology based on observed power-law relationships between precursory information and their growth to estimate the time to eruption and other outcomes under uncertain data.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1821311,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1821311
1837544,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Exploring a community driven data-model framework for testing the stability of the Greenland Ice Sheet,EAGER: Exploring a community driven data-model framework for testing the stability of the Greenland Ice Sheet,One organization,OPP,EarthCube,9/1/2018,8/16/2018,Jason Briner,NY,SUNY at Buffalo,43.000809,-78.78897,Standard Grant,Gregory Anderson,8/31/2019,"$278,843.00 ",Beata Csatho|Abani Patra|Kristin Poinar,jbriner@buffalo.edu,520 Lee Entrance,Buffalo,NY,142282567,7166452634,GEO,8074,062Z|1079|7916,"In the wake of devastating flooding related to recent hurricane strikes on densely inhabited areas, the potential impact of sea level rise has never been more evident. Rising sea level is challenging societies around the globe, but current predictions of future sea level rise contain uncertainty. Greenland's ice, if fully melted, would raise global sea levels more than 7 m. However, at present, we do not have data or models that allow for a definitive consensus view of Greenland Ice Sheet vulnerability to climate change, and our sea level predictions are only as good as our ability to model Greenland Ice Sheet change using computer simulations and the data driving those simulations. Vast datasets of observations and increasingly sophisticated computer models are being employed to solve this problem. Yet, significant knowledge and disciplinary barriers make collaboration between data and model groups the exception rather than the norm. The PIs propose to establish a community-building scientific and educational cyber hub to enable seamless access to data, and coordination and synergy between different scientific disciplines. The overarching goal is to increase the accuracy of predictions of the Greenland Ice Sheet contribution to sea level rise by 2050, 2100 and beyond. The project will support two female PIs (one of which is a young investigator) and partial funding for two graduate students.  Observational datasets of Greenland Ice Sheet change, both from the satellite era and the recent geologic past, are rapidly expanding. Some of these observations have been used for calibration and validation of ice sheet models thereby improving the physical understanding of ice sheet behavior and estimates of future sea level rise. But substantial data-model gaps remain due to the knowledge barrier of understanding and using satellite- and paleo-data and the lack of a standard framework for using available observational datasets in ice sheet modeling experiments. There is significant potential to generate a long-lasting cyberinfrastructure framework with ice sheet data, software tools, online cloud-based execution and educational materials. When combined, this would lead to rapid progress in improving ice sheet modeling capability and decreasing uncertainty in sea level rise forecasting. The PIs will bring together experts in ice sheet observation, data analysis and modeling to guide the creation of a community hub that will enable two-way communication between data generators and modelers. The PIs will pilot software tools necessary to facilitate interoperability among the various data sets and modeling tools and investigate new metrics for model-data intercomparison and model assessment.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1837544,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1837544
1846400,WORKSHOP,WORKSHOP,Tephra  Workshop 2020,Tephra  Workshop 2020,One organization,ICER,NSF Public Access Initiative|EarthCube,10/1/2018,8/29/2018,Marcus Bursik,NY,SUNY at Buffalo,43.000809,-78.78897,Standard Grant,Eva Zanzerkia,9/30/2020,"$49,960.00 ",,mib@buffalo.edu,520 Lee Entrance,Buffalo,NY,142282567,7166452634,GEO,7414|8074,7556,"This workshop will bring together an international community of experts from multiple disciplines to take action on the outcomes and recommendations from Tephra workshops in 2014 and 2017, and seed the implementation and use of cyber based tools and technologies in tephra studies. Tephra studies relate a unique volcanic product that helps researchers to understand volcanic behavior, past eruptions, and the effects of volcanoes on climate and the environment. They provide time markers for geologic and prehistoric human events. The workshop and follow on activities will be useful to provide information for paleoclimatologists, archeologists and others who study environmental change and its impacts on society, and will provide tools for consistent evaluation of tephra layers, which are used extensively to date climatological and environmental transitions. The Broader Impacts of these efforts include the increased information access to a broad scientific community, and collaboration and communication between diverse researchers. The 50 researchers will include participants from under-represented groups in the geosciences.  The researchers intend to hold a series of focused, international tephra workshops in 2019 to 2021.The goals are to produce: (1) publication of a consensus paper to draw attention to the demand, and to develop a coordination plan for creating comparable datasets across disciplines, (2) multiple open access products, for example, best practice templates, data collection and processing templates with end-user oriented minimum sets of required data, and (3) collation of databases and already built tools/code/software for data processing. These products are linked to future directions for the communities interested in tephra.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1846400,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1846400
1339765,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: Building Sustainable Tools and Collaboration for Volcanic and Related Hazards,SI2-SSI: Collaborative Research: Building Sustainable Tools and Collaboration for Volcanic and Related Hazards,Collaborative,OAC,PETROLOGY AND GEOCHEMISTRY|DEEP EARTH PROCESSES SECTION|Software Institutes|Front in Earth Sys Dynamics|EarthCube,10/1/2013,7/2/2018,Matthew Jones,NY,SUNY at Buffalo,43.000809,-78.78897,Continuing grant,Micah Beck,9/30/2019,"$1,416,491.00 ",Marcus Bursik|Abani Patra|Matthew Jones|Matthew Jones|Greg Valentine|Tevfik Kosar,jonesm@ccr.buffalo.edu,520 Lee Entrance,Buffalo,NY,142282567,7166452634,CSE,1573|7571|8004|8016|8074,019Z|7433|8009|9102|9179,"This project is focused on creating and upgrading software infrastructure for a large community of scientists engaged in volcanology research and associated hazard analysis.  Specifically, the project will reengineer three widely used tools (TITAN2D - block and ash flows, TEPHRA and Puff - ash transport and dispersal) and develop support for workflows that use these tools to analyze risk from volcanic hazards. Reengineering will encompass modularization so researchers may easily experiment with different modeling approaches, incorporation of techniques to make the tools efficient on new computing architectures like GPUs and many-core chips. The workflows are intended to tackle the challenges of managing complex and often large data flows associated with these tools in validation processes and in probabilistic inference based on the outcomes of the modeling. The tools and workflows will be made available using the popular vhub.org platform. This project will help provide a standard well managed hardware/software platform and approaches to standardize the documentation associated with input data, source code, and output data. This will ensure that model calculations are reproducible.  The wider use of these high fidelity tools and their use in mitigating hazards is likely to have a significant effect on hazard analysis and management. The project will also engage in several major workshops and in training activities. Project personnel will also engage in the Earthcube initiative - popularizing computational methodologies, online access and dissemination mechanisms through the VHub platform.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339765,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339765
1440095,OTHER,OTHER,Collaborative Proposal: ATREX - integrated open source data analysis software for mineral and environmental sciences,Collaborative Proposal: ATREX - integrated open source data analysis software for mineral and environmental sciences,Collaborative,EAR,CI REUSE|EarthCube,9/1/2014,9/3/2014,Lars Ehm,NY,SUNY at Stony Brook,40.912376,-73.123389,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$128,804.00 ",,lars.ehm@stonybrook.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,GEO,6892|8074,7433,"Synchrotron radiation user facilities are critical resourcces which enable state-of-the-art research and training in mineralogy, mineral physics and environmental science. Access to these facilties is very competitive and time allocated for experiments is constrained. The most popular and fundamental type of experiment is X-ray diffraction, which produces information on crystal structure, symmetry, chemical bonding, composition and density of minerals and other crystalline solids. Modern synchrotron-based diffraction experiments are typically conducted with the use of area detectors, in which case the data is recorded as digital diffraction images. Technology used in synchrotron experiments evolves rapidly increasing the speed of the data collection and producing massive volumes of experimental data, posing new serious challenges for data analysis. The experiments are often decision-driven, and require at least partial real time data interpretation to guide the experimenter. Software offering such real time analysis capabilities is currently not available. This proposal is a collaborative effort to provide this scientific community with easily accessible tools and training opportunities for using these codes.  This project focuses on a combination of novel tools for diffraction-based synchrotron research in Earth and environmental sciences including: (IM1) New capabilities for structure determination of unknown phases and identification of known phases in natural and synthetic samples; (IM2) Opening new possibilities for real time analysis in studies of solid state dynamic processes; (IM3) Robust Bayesian analysis of outliers, uncertainties and missing data; and (IM4) Creation of new free advanced tools for utilizing the available mineralogical database in synchrotron research. Utilizing a combination of existing, well-tested and widely used software components developed in the Interactive Data Language , Python, the project  creates a  new integrated multiplatform, open-source Python software package ATREX (Advanced Tools for Research in Extreme Xtallography), with unique capabilities to process diffraction image data from samples in all forms from glasses and melts, bulk powders, though coarse multi grains, to single crystals, which will support new data types produced by novel ultrafast X-ray imaging detectors, offer extensive automated serial processing capabilities for massive data sets and will allow real time data analysis for time-constrained decision-driven synchrotron experiments. ATREX will include database access capabilities utilizing the free American Mineralogist Crystal Structure Database.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440095,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440095
1740595,IA,IA,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative,ICER,ANTARCTIC INSTRUM & SUPPORT|EarthCube,10/1/2017,9/14/2017,Heather Lynch,NY,SUNY at Stony Brook,40.912376,-73.123389,Standard Grant,Gregory J.  Anderson,9/30/2020,"$632,179.00 ",,heather.lynch@stonybrook.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,GEO,1647|8074,7433,"Satellite imagery is rapidly transforming the way we see the planet, including our ability to study the most remote parts of the Arctic and Antarctic. Satellite imagery can help us map networks of rivers, study changes in the flow and thickness of glaciers, identify rock and soil types, and even find animals like penguins and seals. Because the availability of imagery in polar areas has increased rapidly over the last decade, we are now faced with a challenge: To move from small pilot-studies to pan-Arctic or pan-Antarctic analyses of geological and biological processes requires new infrastructures that link scientists, satellite imagery, and fast computing. The project, called ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, aims to build the cyberinfrastructure required to make the most of satellite imagery for geosciences, starting with researchers working in polar areas, and then branching out to the larger community. The Broader Impacts of this proposal include the training of undergraduate and graduate students, as well as young investigators and female scientists. Moreover, the scientific findings enabled by this proposed cyberinfrastructure will have immediate benefits for our ability to predict the future dynamics of the polar regions, and critical to the management of Arctic and Antarctic resources.   Polar geosciences stands at the precipice of a revolution, one enabled by the confluence of cutting edge analytical tools, petabytes of high-resolution imagery, and an ever growing array of high performance computing resources. With these tools at hand, we can look beyond incremental improvements in our understanding of the polar regions. Near-real time datasets of geological and biological importance at the continental scale are within our reach if we create those critical cyberinfrastructure components that allow the geosciences community to exploit existing assets and establish a common workflow for reproducible imagery-enabled science. The research objective of this proposal is to understand the biological, geological, and hydrological functioning of the polar regions at spatial scales heretofore beyond the reach of individual PIs, and to develop tools for imagery-enabled science that can be applied globally. The resulting cyberinfrastructure, which we call ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, is an extensible system for coupling open-source image analysis tools with the use of high performance and distributed computing (HPDC) for imagery-enabled geoscience research. We propose a project to (1) develop open source image classification tools tailored to high-resolution satellite imagery of the Arctic and Antarctic to be used on HPDC resources, (2) create easy-to-use interfaces to facilitate the development and testing of algorithms for application specific geoscience requirements, (3) apply these tools through use cases that span the biological, hydrological, and geoscience needs of the polar community, (4) transfer these tools to the larger non-polar community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740595,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740595
1542058,RCN,RCN,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,Collaborative,ICER,EarthCube,9/1/2015,8/4/2015,Heather Lynch,NY,SUNY at Stony Brook,40.912376,-73.123389,Standard Grant,Eva Zanzerkia,8/31/2018,"$27,326.00 ",,heather.lynch@stonybrook.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,GEO,8074,7433,"One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs.  Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.  The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed.  This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training.  The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1542058,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1542058
1838230,"DIBBS, BIGDATA, III",DIBBS,BIGDATA: IA: Collaborative Research: Intelligent Solutions for Navigating Big Data from the Arctic and Antarctic,BIGDATA: IA: Collaborative Research: Intelligent Solutions for Navigating Big Data from the Arctic and Antarctic,Collaborative,IIS,POLAR CYBERINFRASTRUCTURE|EarthCube|Big Data Science &Engineering,9/1/2018,8/30/2018,Maryam Rahnemoonfar,TX,Texas A&M University Corpus Christi,30.618531,-96.336499,Standard Grant,Sylvia Spengler,8/31/2022,"$612,823.00 ",,maryam.rahnemoonfar@tamucc.edu,"6300 Ocean Drive, Unit 5844",Corpus Christi,TX,784125844,3618253882,CSE,5407|8074|8083,062Z|8083|9102,"The objective of this research is to investigate artificial intelligence (AI) solutions for data collected by the Center for Remote Sensing of Ice Sheets (CReSIS) in order to provide an intelligent data understanding to automatically mine and analyze the heterogeneous dataset collected by CReSIS. Significant resources have been and will be spent in collecting and storing large and heterogeneous datasets from expensive Arctic and Antarctic fieldwork (e.g. through NSF Big Idea: Navigating the New Arctic). While traditional analyses provide some insight, the complexity, scale, and multidisciplinary nature of the data necessitate advanced intelligent solutions. This project will allow domain scientists to automatically answer questions about the properties of the data, including ice thickness, ice surface, ice bottom, internal layers, ice thickness prediction, and bedrock visualization. The planned approach will advance the broader big data research community by improving the efficiency of deep learning methods and in the investigation of methods to merge data-driven AI approaches with application-specific domain knowledge. Special attention will be given to women and minority involvement in the research and the project will develop new course materials for several classes in AI at a Hispanic and minority serving institute.  In polar radar sounder imagery, the delineation of the ice top and ice bottom and layering within the ice is essential for monitoring and modeling the growth of ice sheets and sea ice. The optimal approach to this problem should merge the radar sounder data with physical ice models and related datasets such as ice coverage and concentration maps, spatiotemporal meteorological maps, and ice velocity. Rather than directly engineering specific relations into the image analysis that require many parameters to be defined and tuned, data-dependent approaches let the machine learn these relationships. To devise intelligent solutions for navigating the big data from the Arctic and Antarctic and to scale up the current and traditional techniques to big data, this project plans several approaches for detecting ice surface, bottom, internal layers, 3D modeling of bedrock and spatial-temporal monitoring of the ice surface: 1) Devise new methodologies based on hybrid networks combining machine learning with traditional domain specific knowledge and transforming the entire deep learning network to the time-frequency domain. 2) Equip the machine with information that is not visible to the human eye or that is hard for a human operator to consider simultaneously, to be able to detect internal layers and 3D basal topography on a large scale. Using the results of the feature tracking of the ice surface in radar altimetry, the research effort will also develop new data-dependent techniques for predicting the ice thickness for following years based on deep recurrent neural networks.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1838230,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1838230
1639749,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,Collaborative,ICER,EAR|EarthCube,9/1/2017,8/18/2017,Julie Newman,TX,Texas A&M University Main Campus,30.618531,-96.336499,Standard Grant,Eva E. Zanzerkia,8/31/2020,"$162,911.00 ",,Newman@geo.tamu.edu,400 Harvey Mitchell Pkwy South,College Station,TX,778454375,9798626777,GEO,6898|8074,026Z|7433,"When viewed at the micro-scale, rocks reveal structures that help to interpret the processes and forces responsible for their formation.  These microstructures help to explain phenomena that occur at the scale of mountains and tectonic plates.  Interpretation of microstructures formed in nature during deformation is aided by comparison with those formed during experiments, under known conditions of pressure, temperature, stress, strain and strain rate, and experimental rock deformation benefits from the ground truth offered through comparison with rocks deformed in nature.  However, the ability to search for relevant naturally or experimentally deformed microstructures is hindered by the lack of any database that contains these data.  The researchers collaborating on this project will develop a single digital data system for rock microstructures to facilitate the critical interaction between and among the communities that study naturally and experimentally deformed rocks.  To aid in the comparison of microstructures formed in nature and experiment, the researchers will link to commonly used analytical tools and develop a pilot project for automatic comparison of microstructures using machine learning.     Rock microstructures relate processes at the microscopic scale to phenomena at the outcrop, orogen, and plate scales and reveal the relationships among stress, strain, and strain rate.  Quantitative rheological information is obtained through linked studies of naturally formed microstructures with those created during rock deformation experiments under known conditions.  The project will develop a single digital data system for both naturally and experimentally deformed rock microstructure data to facilitate comparison of microstructures from different environments.  A linked data system will facilitate interaction between practitioners of experimental deformation, those studying natural deformation and the cyberscience community.  The data system will leverage the StraboSpot data system currently under development in Structural Geology and Tectonics.  To develop this system requires: 1) Modification of the StraboSpot data system to accept microstructural data from both naturally and experimentally deformed rocks; and 2) Linking the microstructural data to its geologic context ? either in nature, or its experimental data/parameters.  The researchers will engage the rock deformation community with the goal of establishing data standards and protocols for data collection, and integrate our work with ongoing efforts to establish protocols and techniques for automated metadata collection and digital data storage.  To analyze the microstructures studied and/or generated by these communities, we will ensure StraboSpot data output is compatible with commonly used microstructural tools.  They will develop a pilot project for comparing and analyzing microstructures from different environments using machine-learning.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639749,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639749
1450177,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,Brian Ancell,TX,Texas Tech University,33.584259,-101.878282,Standard Grant,Bogdan Mihaila,7/31/2019,"$166,428.00 ",,brian.ancell@ttu.edu,349 Administration Bldg,Lubbock,TX,794091035,8067423884,CSE,1525|8004|8074,4444|7433|8009,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450177,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450177
1443062,OTHER,OTHER,Beyond Data Discovery: Shared Services for Community Metadata Improvement,Beyond Data Discovery: Shared Services for Community Metadata Improvement,One organization,OAC,DATANET|EarthCube,5/1/2015,4/27/2015,Ray Habermann,IL,The HDF Group,40.093949,-88.239639,Standard Grant,Amy Walton,4/30/2019,"$1,498,604.00 ",Matthew Jones,thabermann@hdfgroup.org,410 E University Ave,Champaign,IL,618203871,2175316100,CSE,7726|8074,7433|8048,"Science data and results must be well documented in order to be reproducible and re-usable.  Metadata -- ancillary contextual information such as science objectives, data provenance, and uncertainty estimates at each step -- is a fundamental part of the research documentation, reuse, and collaboration process.  This project develops flexible tools for evaluating metadata, using consistent measurement systems that encourage community engagement, integrate guidance for improvement, and are a critical element in cross-community metadata improvement efforts.  Provision of these new metadata and data evaluation services across communities will improve the ability to integrate and reuse trustworthy data for crosscutting synthesis and analysis across science communities.  The focus on use metadata rather than discovery metadata is a significant shift in focus.  Use metadata is a fundamental building block needed to allow effective scientific analysis workflows.  The team builds a significant collaboration with several interdisciplinary partner organizations that provide guidance to this project.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443062,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443062
1450338,"SI2, CSSI",SI2,"Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics","Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics",Collaborative,OAC,GEOMORPHOLOGY & LAND USE DYNAM|Software Institutes|EarthCube,8/1/2015,7/14/2015,Nicole Gasparini,LA,Tulane University,29.940348,-90.120728,Standard Grant,Stefan Robila,7/31/2020,"$532,320.00 ",,ngaspari@tulane.edu,6823 ST CHARLES AVENUE,NEW ORLEANS,LA,701185698,5048654000,CSE,7458|8004|8074,7433|8009|9150,"Earth scientists discover and predict the behavior of the natural world in part through the use of computer models. Models are used to study a wide range of phenomena, such as soil erosion, flooding, plant growth, landslide occurrence, and many other processes. Models can be used to develop scientific understanding by comparing model calculations with the real world. They can also be used to make predictions about how nature will behave under certain conditions. In the areas of geosciences that deal with the earth's surface, one bottleneck in the development and use of models is the effort required to build, test, and debug the necessary software. This project contributes to scientific research and discovery by creating open source software tools that scientists can use to more efficiently create, modify, or combine computer models that represent portions of earth's surface and the processes occurring thereon. The project combines software development with user training and web-based resources, so that the products will be openly accessible, well documented, and widely disseminated within the relevant scientific communities. The project also contributes to K-12, undergraduate, and graduate-level education in computational modeling and earth-surface processes.  This project catalyzes research in earth-surface dynamics by developing a software framework that enables rapid creation, refinement, and reuse of two-dimensional (2D) numerical models. The phrase earth-surface dynamics refers to a remarkably diverse group of science and engineering fields that deal with our planet's surface and near-surface environment: its processes, its management, and its responses to natural and human-made perturbations. Scientists who want to use an earth-surface model often build their own unique model from the ground up, re-coding the basic building blocks of their model rather than taking advantage of codes that have already been written. Whereas the end result may be novel software programs, many person-hours are lost rewriting existing code, and the resulting software is often idiosyncratic, poorly documented, and unable to interact with other software programs in the same scientific community and beyond, leading to lost opportunities for exploring an even wider array of scientific questions than those that can be addressed using a single model. The Landlab model framework seeks to eliminate these redundancies and lost opportunities, and simultaneously lower the bar for entry into numerical modeling, by creating a user- and developer-friendly software library that provides scientists with the fundamental building blocks needed for modeling earth-surface dynamics. The framework takes advantage of the fact that nearly all surface-dynamics models share a set of common software elements, despite the wide range of processes and scales that they encompass. Providing these elements in the context of a popular scientific programming environment, with strong user support and community engagement, contributes to accelerating progress in the diverse sciences of the earth's surface.  The Landlab modeling framework is designed so that grid creation, data storage, and sharing of data among process components is done for the user. The framework is generic enough so that the coupling of two process components, whether they are squarely within a geoscience subdiscipline, or they cross subdisciplines, is the same. This architecture makes it easy to explore a wide range of questions in the geosciences without the need for much coding. Further, the model code is primarily written in Python, a language that is relatively easy for casual programmers to learn. Because of these attributes, the Landlab modeling framework has the potential to add computational modeling to the toolbox of a wide array of geoscientists, and to clear a path for trans-disciplinary earth-surface modeling that explores societally relevant topics, such as land-cover changes in response to climate change, as well as modeling of topics that currently require the coupling of sophisticated but harder-to-use models, such as sediment source-to-sink dynamics. The project will generate several proof-of-concept studies that are interesting in their own right, and demonstrate the capabilities of the modeling framework. Community engagement is fostered by presenting clinics and demonstrations at professional venues aimed at hydrologists, sedimentologists, critical zone scientists, and the broader earth and environmental sciences community. The team also supports visits by individual scientists for on-site training beyond these clinics. Input/output tools allow compatibility with data from relevant NSF-supported research. The project supports four graduate students and three postdoctoral researchers, and also includes modeling workshops for fifth to seventh grade girls in a community that has a greater than 50% minority population.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450338,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450338
1642620,RCN,RCN,Collaborative Proposal:  EarthCube RCN: Connecting the Earth Science and Cyberinfrastructure communities to advance the analysis of high resolution topography data,Collaborative Proposal:  EarthCube RCN: Connecting the Earth Science and Cyberinfrastructure communities to advance the analysis of high resolution topography data,Collaborative,EAR,EarthCube,8/15/2017,8/10/2017,Christopher Crosby,CO,"UNAVCO, Inc.",40.061137,-105.205904,Standard Grant,Dena Smith,7/31/2019,"$147,823.00 ",,crosby@unavco.org,6350 Nautilus Dr.,Boulder,CO,803015394,3033817500,GEO,8074,,"This EarthCube Research Coordination Network (RCN) will bring together communities that create and use high resolution map data, including those that conduct research on earth surface processes and those that create the technology to make these types of complex data usable. Members of this network will work to share currently available resources and best practices, and to develop new tools to make data more available to researchers. Training will focus on teaching graduate student and early career researchers to access and use high resolution map data to answer earth science research questions.   Vast quantities of High Resolution Terrain (HRT) data have been collected, with applications ranging from scientific research to commercial sector engineering. Full scientific utilization of these HRT data is still limited due to challenges associated with the storage, manipulation, processing, and analysis of these data. The cyberinfrastructure community, including computer vision, computer science, informatics, and related engineering fields are developing advanced tools for visualizing, cataloging, and classifying imagery data including point clouds. Yet, many of these tools are most applicable to engineered structures and small datasets, and not to heterogeneous landscapes. Together the earth science and cyberinfrastructure communities have the opportunity to test and validate emerging tools in challenging landscapes (e.g., heterogeneous and multiscale landforms, vegetation structures, urban footprints). In particular, this RCN will be focused on four themes: (1) coordination of the analysis of HRT data across the earth surface processes and hydrology communities to identify work-flows and best practices for data analysis; (2) identification of cyberinfrastructure tool development needs as new technologies for HRT data acquisition emerge; (3) use of HRT data for numerical models validation and integration of HRT data information in models; (4) training in HRT best practices, and data processing and analysis work-flows.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1642620,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1642620
1835791,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative,OAC,EarthCube,1/1/2019,8/27/2018,Charles Meertens,CO,"UNAVCO, Inc.",40.061137,-105.205904,Standard Grant,Amy Walton,12/31/2022,"$830,728.00 ",David Mencin|Scott Baker,meertens@unavco.org,6350 Nautilus Dr.,Boulder,CO,803015394,3033817500,CSE,8074,062Z|077Z|7925,"This project develops a real-time processing system capable of handling a large mix of sensor observations. The focus of this system is automation of the detection of natural hazard events using machine learning, as the events are occurring.  A four-organization collaboration (UNAVCO, University of Colorado, University of Oregon, and Rutgers University) develops a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  This work will support rapid analysis and understanding of data associated with hazardous events (earthquakes, volcanic eruptions, tsunamis).    This project uses a collaboration between computer scientists and geoscientists to develop a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  It focuses on the aggregation and integration of a large number of data streams into a coherent system that supports analysis of the data streams in real-time. The framework will offer machine-learning-based tools designed to detect signals of events, such as earthquakes and tsunamis, that might only be detectable when looking at a broad selection of observational inputs.  The architecture sets up a fast data pipeline by combining a group of open source components that make big data applications viable and easier to develop. Data sources for the project draw primarily upon the 1500+ sensors from the EarthScope networks currently managed by UNAVCO and the Incorporated Research Institutions for Seismology (IRIS), as well as the Ocean Observatories Initiative (OOI) cabled array data managed by Rutgers University.  Machine learning (ML) algorithms will be researched and applied to the tsunami and earthquake use cases.  Initially, the project plans to employ an advanced convolutional neural network method in a multi-data environment.  The method has only been applied to seismic waveforms, so the project will explore extending the method to a multi-data environment.  The approach is expected to be extensible beyond detection and characterization of earthquakes to include the onset of other geophysical signals such as slow-slip events or magmatic intrusion, expanding the potential for new scientific discoveries.  The framework is applied to use cases in the Cascadia subduction zone and Yellowstone: these locations combine the expertise of the science team with locations where EarthScope and OOI have the greatest concentration of instruments.  The architecture will be transportable and scalable, running in a Docker environment on laptops, local clusters and the cloud.  Integral to the project will be development, documentation and training using collaborative online resources such as GitLab and Jupyter Notebooks, and utilizing NSF XSEDE resources to make larger datasets and computational resources more widely available.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Program and Division of Earth Sciences within the NSF Directorate for Geosciences, the Big Data Science and Engineering Program within the Directorate for Computer and Information Science and Engineering, and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the Office of Advanced Cyberinfrastructure.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835791,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835791
1440213,BB,BB,EarthCube Building Blocks:  Collaborative Proposal:  Enabling Scientific Collaboration and Discovery through Semantic Connections,EarthCube Building Blocks:  Collaborative Proposal:  Enabling Scientific Collaboration and Discovery through Semantic Connections,Collaborative,ICER,EarthCube,9/1/2014,8/4/2014,Linda Rowan,CO,"UNAVCO, Inc.",40.061137,-105.205904,Standard Grant,Eva Zanzerkia,8/31/2018,"$386,875.00 ",,rowan@unavco.org,6350 Nautilus Dr.,Boulder,CO,803015394,3033817500,GEO,8074,7433,"Data, information, ideas, and technologies diffuse through social and organizational networks, if the impediments to their adoption are low and the benefits of new approaches are clear. This project brings together the National Center for Atmospheric Research (NCAR), UNAVCO, and Cornell University to understand how to improve the processes of collaboration and resource sharing in the geosciences by demonstrating and encouraging the adoption of structured information systems rooted in common standards. Using two large geoscience research programs as case studies, this effort will demonstrate how semantic web and linked data technology can play an essential role in the coordination and organization of scientific virtual organizations and their products, thereby accelerating the pace of scientific discovery and innovation.    The researchers will use a well-developed open source web application as an integrating data layer to expose the informational relationships and organizational collaborations within the case studies. This project will be an exemplar of using linked data to support virtual organizations in the geosciences. These efforts will feed into new tools that leverage linked data to support information and data exchange, and will produce recommendations on engaging user communities in linked data projects. This project will provide insight into how the geosciences can leverage linked data to produce more coherent methods of information and data discovery for large multi-disciplinary projects and virtual organizations. They will use the open source VIVO software application to illustrate how linked data can transform scientific project communication and dissemination via front end discovery based on rich networked metadata. The VIVO platform provides new capabilities for researchers and educators to use structured, interpretable data, permitting direct interlinking of information and data across platforms and projects. The project will structure data into an ontology-based, standard data format (RDF) for re-use, leveraging web identifier and vocabulary structures that have been well developed and widely adopted in the geoscience and cyberinfrastructure communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440213,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440213
1639709,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Deploying Multi-Facility Cyberinfrastructure in Commercial and Private Cloud-based Systems. (GeoSciCloud),EarthCube Building Blocks: Collaborative Proposal: Deploying Multi-Facility Cyberinfrastructure in Commercial and Private Cloud-based Systems. (GeoSciCloud),Collaborative,ICER,EarthCube,9/1/2016,9/15/2016,Charles Meertens,CO,"UNAVCO, Inc.",40.061137,-105.205904,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$605,204.00 ",Frances Boler,meertens@unavco.org,6350 Nautilus Dr.,Boulder,CO,803015394,3033817500,GEO,8074,7433,"It is common to hear that it is optimal to perform computations necessary for the operation of corporations in the ?cloud? and it is true that many commercial companies are moving their information technology into that environment. Scientific data centers funded by the NSF have unique constraints that they must accommodate.  Funding is limited and costs of managing data centers using cloud technology can be quite costly.  Additionally, government funded research organizations typically have much smaller IT staffs than do corporations. The impact of managing IT operations in the cloud is not identical between large corporations and NSF funded data centers.  In the GeoSciCloud project, two medium-size NSF funded data centers plan to deploy data collections along with cloud-based services in different environments in order to assess the feasibility and impact.  These environments include: - Commercial cloud environments such as those offered by Amazon, Google, and Microsoft and - NSF supported large computing facilities that are just beginning to offer services that have characteristics of cloud computing The operation of these infrastructures in these two cloud environments will be compared to current in-house environments and assessed. This project will thereby help NSF/EarthCube  identify the most suitable IT environment in which the EarthCube should deploy and support shared infrastructure.  The potential reliability and cost-savings are excellent motivating factors.  IRIS and UNAVCO operate data centers with several hundred terabytes of data and services that match our community's needs and requirements.  Each organization currently operates its own infrastructure. GeoSciCloud tasks will include moving subsets of our archives, as a test, into commercial cloud and XSEDE cloud environments where we will compare and contrast several aspects of working in different infrastructures. GeoSciCloud partners will also deploy key services developed under the GeoWS building block to enable access to data sets by domain scientists.   GeoSciCloud will help EarthCube compare and contrast the three environments (XSEDE, Commercial Cloud, and current infrastructure) in the following areas: - Gain an understanding of issues related to the ingestion of large data sets into the cloud and curating the data in a cloud environment. - Compare processing times for real world requests for data by practicing domain scientists - Test elasticity of the cloud for doing large amounts of digital signal processing of seismic data and reprocessing GPS solutions for long periods of time. - Compare the speed of data egress from multiple environments including tests of using higher access systems such as Grid-FTP. - Compare overall costs of operating in the three environments - Document what the best practices are that emerge from the GeoSciCloud test that should be promoted within EarthCube. - Perform conversion of data held in domain formats to more widely used formats such as HDF5 for improved interoperability. - Test the reliability of streaming real time data into the cloud. GeoSciCloud will also explore providing some infrastructure in support of other EarthCube partners so that multiple data centers can cohabitate within the GeoSciCloud.  IRIS and UNAVCO will commit to ultimately demonstrate the utility of shared infrastructure and how it can improve the efficiency and economics within EarthCube and specifically shared infrastructure in a cloud environment.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639709,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639709
1261833,OTHER,OTHER,2013-2018 UNAVCO Community Proposal Geodesy Advancing Geosciences and EarthScope:  The GAGE Facility,2013-2018 UNAVCO Community Proposal Geodesy Advancing Geosciences and EarthScope:  The GAGE Facility,One organization,EAR,EARTHSCOPE|EARTHSCOPE-OPERATIONS & MAINTE|GEOPHYSICS|EDUCATION AND HUMAN RESOURCES|INSTRUMENTATION & FACILITIES|CONTINENTAL DYNAMICS PROGRAM|ANTARCTIC INSTRUM & SUPPORT|ANTARCTIC OCEAN & ATMOSPH SCI|ARCTIC RESRCH SUPPRT & LOGISTI|ANTARCTIC INTEGRATED SYS SCI|GAGE|XC-Crosscutting Activities Pro|GEOMORPHOLOGY & LAND USE DYNAM|DEEP EARTH PROCESSES SECTION|ICER|EarthCube|GeoPRISMS|INTEGRATED EARTH SYSTEMS||||||||,10/1/2013,7/13/2018,Meghan Miller,CO,"UNAVCO, Inc.",40.061137,-105.205904,Cooperative Agreement,Russell C. Kelz,12/31/2018,"$71,588,238.00 ",Donna Charlevoix|Charles Meertens|Glen Mattioli,Meghan@unavco.org,6350 Nautilus Dr.,Boulder,CO,803015394,3033817500,GEO,007F|016F|1574|1575|1580|1581|1647|5113|5205|5292|7113|7222|7458|7571|7699|8074|8076|8212|M647|N551|O188|O224|O377|P181|Q138|R143,1079|1733|7433|9251,"The GAGE Facility:  Geodesy Advancing Geosciences and EarthScope Cooperative Agreement (CA) supports advancement of cutting-edge community geodetic research around the world.  Over the last two decades, space-based geodetic observations have enabled measurement of the motions of the Earth?s surface and crust at many different scales, with unprecedented spatial and temporal detail and increased precision, leading to fundamental discoveries in continental deformation, plate boundary processes, the earthquake cycle, the geometry and dynamics of magmatic systems, continental groundwater storage and hydrologic loading.  Space geodesy furthers research on earthquake and tsunami hazards, volcanic eruptions, coastal subsidence, wetlands health, soil moisture and groundwater distribution. Of particular importance are contributions to understanding of processes related to climate dynamics, including hurricane tracking and intensity, sea level rise, and changes in mountain glaciers and large polar ice sheets.  As global population disproportionately increases in hazards-prone coastal and tectonically active regions of the US and across the globe, the societal relevance of quantifying, understanding, and potentially mitigating natural hazards grows. Geoscientists using global geodetic infrastructure coupled with leading edge techniques are well poised to advance basic research that is in the U.S. and global public interest as the challenges of living on a dynamic planet escalate.  NSF-funded geodesy investigators are active on every continent, across a broad spectrum of the geosciences, and facilitated by data and engineering services that are now merged under the GAGE Facility.  GAGE continues operations of: 1) the EarthScope Plate Boundary Observatory (PBO), an integrated set of geodetic networks that includes 1100 continuous GPS sites (with ~350 high-rate, low-latency data streams and ~125 surface meteorological sensors), 78 borehole strainmeters and seismometers, and 6 long-baseline laser strainmeters, and tiltmeters on several volcanoes; 2) global engineering and data services primarily to NSF-funded investigators who use terrestrial and satellite geodetic technologies in their research and provision of network operations support to community GPS networks and NASA?s Global GNSS Network (GGN); and 3) Education and community outreach actvities.   NSF?s Division of Polar Programs (PLR) contributes to the GAGE Facility support of PI research and GPS networks in Greenland and Antarctica.  NASA contributes to the GAGE Facility to support the GGN and the activities of the IGS Central Bureau, which underlie the internationally coordinated reference frame products that make high-precision geodesy possible.  ***",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1261833,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1261833
1623751,"CC, GOVERNANCE",CC,EarthCube Science Support Office (ESSO),EarthCube Science Support Office (ESSO),One organization,ICER,EarthCube,5/1/2016,1/31/2019,Mohan Ramamurthy,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Cooperative Agreement,Eva Zanzerkia,4/30/2019,"$4,301,518.00 ",,mohan@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,062Z|7433,"EarthCube is a community-driven effort with the goal of transforming the conduct of geoscience research and education by creating a well-integrated and facile environment to share scientific data, information tools and services, and knowledge in an open, transparent, and inclusive manner. Under the leadership of University Corporation for Atmospheric Research (UCAR) and in partnership with the EarthCube community, its governance, and other stakeholders and collaborators, the EarthCube Science Support Office (ESSO) will support efforts to advance EarthCube's mission. ESSO's role will be to provide a logistical, organizational, and administrative foundation to facilitate the advancement of EarthCube goals to catalyze scientific breakthroughs in the geosciences by fostering advances in information and computational sciences. ESSO will endeavor to ensure a high quality of service to EarthCube stakeholders, delivered with professionalism, efficiency, transparency, and nimbleness.  ESSO will provide logistical support to the EarthCube community and its governance groups in order to stimulate and manage community dialog, strengthen efforts to define and resolve common challenges using a consensus-oriented approach, and help realize EarthCube's full potential and vision. ESSO will provide leadership to improve the coherence and impact of EarthCube's efforts, bringing a coordinated and well-integrated approach to managing and supporting governance, science, and technology activities. To accomplish this, UCAR will draw on the expertise of two of its community programs -- Unidata and the Joint Office for Science Support (JOSS) -- to provide the services requested of the ESSO. In addition, ESSO will collaborate with the Earth Science Information Partners (ESIP) Federation to leverage their long experience with the geoscience cyberinfrastructure community for the mutual benefit of both organizations and their communities. ESSO will also spearhead outreach and community engagement activities by participating in national and international scientific society meetings, scientific career fairs, and other events. ESSO will reach out to broader audiences through the EarthCube website, newsletters, and social media. It will leverage the presence of geoscientists and cyberinfrastructure professionals to offer in-person and virtual seminars, promoting the work of funded projects, data facilities, and providing backbone support for education, training, and workforce development activities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1623751,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1623751
1740641,IA,IA,Collaborative Proposal: EarthCube Integration: Accelerating Scientific workflowS using EarthCube Technologies (ASSET),Collaborative Proposal: EarthCube Integration: Accelerating Scientific workflowS using EarthCube Technologies (ASSET),Collaborative,ICER,EarthCube,9/1/2017,8/17/2017,Cindy Bruyere,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$275,000.00 ",James Done|Michael Daniels,bruyerec@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,7433,"A major need in the geosciences is to reduce the amount of time geoscientists spend on ""data wrangling"" tasks (finding, accessing, subsetting, gridding, processing, reformatting, visualizing) so that they can spend more time on complex scientific analysis. This project will develop a means for scientists to document and interact with all of the data management and analysis tools that they need to create a scientific result, and it will add tools to find common patterns in their work to help find tools that could reduce the time needed to produce the result. This work may also help to make moethods and analyses more transparent by providing the means to track the steps in creating a scientific result.  This project builds on relationships among cyberinfrastructure experts and geoscientists examine current scientific workflows and the integration of EarthCube tools.  The work will include a workflow sketching interface to specify the steps, dependencies, current tools, current duration, and other important aspects of a scientist's workflow.  As part of the proposed pilot project, the team will examine two geoscience use cases (hurricane risk and water resources) in detail and assign cyberinfrastructure experts to integrate EarthCube tools into these science workflows, to demonstrate the increases in productivity that are realized.  In addition, the team will conduct a workshop/clinic at a major geoscience conference to collect additional use cases from the community, where geoscientists will describe their workflows and receive personalized advice on the use of EarthCube tools.  If successful, the researchers may expand on this pilot project to conduct many more workshops at other venues and to map many more scientific workflows to corresponding EarthCube technologies.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740641,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740641
1740633,IA,IA,Collaborative Proposal: EarthCube Integration: Pangeo: An Open Source Big Data Climate Science Platform,Collaborative Proposal: EarthCube Integration: Pangeo: An Open Source Big Data Climate Science Platform,Collaborative,OCE,OCE|EarthCube,9/1/2017,8/21/2017,Kevin Paul,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Baris M. Uz,8/31/2020,"$466,882.00 ",Ryan May|Davide Del Vento|Joseph Hamman,kpaul@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,6899|8074,026Z|7433,"Climate, weather, and ocean simulations (Earth System Models; ESMs) are crucial tools for the study of the Earth system, providing both scientific insight into fundamental dynamics as well as valuable practical predictions about Earth's future. Continuous increases in ESM spatial resolution have led to more realistic, more detailed physical representations of Earth system processes, while the proliferation of statistical ensembles of simulations has greatly enhanced understanding of uncertainty and internal variability. Hand in hand with this progress has come the generation of Petabytes of simulation data, resulting in huge downstream challenges for geoscience researchers. The task of mining ESM output for scientific insights  has now itself become a serious Big Data problem. Existing Big Data tools cannot easily be applied to the analysis of ESM data, leading to a building crisis across a wide range of geoscience fields. This is exactly the sort of problem EarthCube was conceived to address. The project will integrate a suite of open-source software tools (the ""Pangeo Platform"") which together can tackle petabyte-scale ESM datasets. Additionally, training and educational materials for these tools will be developed, distributed widely online, and integrated into existing educational curricula at Columbia. A workshop at NCAR in the final year will help inform the broader community about Pangeo. Collaborators at other US climate modeling centers will encourage adoption and participation in the Pangeo project by their scientists. Beyond climate and related fields, multidimensional numeric arrays are common in many fields of science (e.g. astronomy, materials science, microscopy). However, the dominant Big Data software stack (Hadoop) is oriented towards tabular text-based data structures and cannot easily ingest petabyte scale multidimensional numeric arrays. The proposed work thus has potential to transform Data Science itself, enabling analysis of such datasets via a novel, highly scalable, highly flexible tool with a syntax familiar to disciplinary researchers.  The core technologies are the python packages Dask, a flexible parallel computing library which provides dynamic task scheduling, and XArray, a wrapper layer over Dask data structures which provides user-friendly metadata tracking, indexing, and visualization. These tools interface with netCDF datasets and understand CF conventions. They will be brought to bear on four high impact Geoscience Use Cases in atmospheric science, land-surface hydrology, and physical oceanography. Disciplinary scientists will define workflows for each use case and interact with computational scientists to demonstrate, benchmark, and optimize the software. The resulting software improvements will be contributed back to the upstream open source projects, ensuring long-term sustainability of the platform. The end result will be a robust new software toolkit for climate science and beyond. This toolkit will enhance the Data Science aspect of EarthCube. Implementation of these tools on the cloud will also be tested, taking advantage of agreement between commercial cloud service providers and NSF for the BIGDATA solicitation.      ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740633,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740633
1338425,WORKSHOP,WORKSHOP,"EarthCube Domain End-User Workshop: Integrating Real-time Data into the EarthCube Framework; Boulder, Colorado; June 17-19, 2013","EarthCube Domain End-User Workshop: Integrating Real-time Data into the EarthCube Framework; Boulder, Colorado; June 17-19, 2013",One organization,AGS,EarthCube,4/15/2013,4/5/2013,Michael Daniels,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Linnea M. Avallone,11/30/2014,"$95,634.00 ",,daniels@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,4444|7433|OTHR,"This grant supports a workshop entitled ""EarthCube Domain End-User Workshop: Integrating Real-time Data into the EarthCube Framework"" to be held in June 2013 in Boulder, Colorado.  The primary objective of this meeting is to bring together users and providers of real-time data across geosciences disciplines to address community needs for effectively and efficiently handling and applying this type of data. Through oral presentations and in breakout sessions, attendees from universities, federal agencies and industry will develop example cases and explore issues related to gathering and quality control of real-time data that can be used to inform the cyber-infrastructure development within EarthCube.    Real-time geoscientific data has the potential to revolutionize the application of scientific data in contexts of importance to a broader audience. Such data streams are key inputs, for example, to operational forecast models and warning systems that inform the general public of impending hazardous weather. This workshop will have a broader impact by helping to build capacity among the community of real-time technologists and researchers whose work affects a wide range of users, including water resource managers, energy planners, farmers, school districts, disaster mitigation and relief planners, urban managers, utilities, cities, etc.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338425,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338425
1238196,WORKSHOP,WORKSHOP,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,One organization,EAR,IIS SPECIAL PROJECTS|Software Institutes|EarthCube,4/1/2012,3/27/2012,Martyn Clark,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Barbara L. Ransom,3/31/2013,"$15,000.00 ",,mclark@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,7484|8004|8074,7433,"EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences.  They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238196,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238196
1266399,WORKSHOP,WORKSHOP,"Shaping the Development of EarthCube to Enable Advances in Data Assimilation and Ensemble Prediction Workshop; Boulder, Colorado; December 17-18, 2012","Shaping the Development of EarthCube to Enable Advances in Data Assimilation and Ensemble Prediction Workshop; Boulder, Colorado; December 17-18, 2012",One organization,AGS,EarthCube,12/15/2012,11/8/2012,Mohan Ramamurthy,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,A. Gannet Hallar,11/30/2013,"$41,225.00 ",,mohan@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,1525|4444|9145|OTHR,"Intellectual Merit:  Data intensive science has rapidly emerged as the Fourth Paradigm of scientific discovery after empirical, theoretical, and computational methods.  This is particularly true in the area of data assimilation and ensemble prediction. Yet, significant barriers exist in using the data efficiently or integrating them into data assimilation or ensemble prediction systems as the scientific community lacks easy-to-use common cyberinfrastructure frameworks.  By some estimates, researchers may spend 80 percent of their time dealing with data discovery, access, and processing, and only 20 percent ""doing science"" by way of interpretation, synthesis, and knowledge creation.  The goal of the National Science Foundation's EarthCube initiative is to transform the conduct of research by supporting the development of community-guided cyberinfrastructure. It is critical that EarthCube is both shaped by as well as benefits the different scientific communities to which it is targeted.  This project will fund a workshop to bring the research, education, and information technology communities together to discuss some of the science, technology and cyberinfrastructure issues related to distributed but shared mesoscale modeling, data assimilation, and ensemble prediction. The title of the workshop, which is planned to be held 17-18 December 2012 in Boulder, CO, is ""Shaping the Development of EarthCube to Enable Advances in Data Assimilation and Ensemble Prediction.""  One of the goals of the workshop is to shape the development of EarthCube and help in building a cyberinfrastructure and work toward a scientific ecosystem in which ""data friction"" is reduced, and data transparency and ease-of-use are significantly increased.  We believe achieving the workshop goals will help mesoscale ensemble prediction and data assimilation communities to work toward a transformation in the conduct of data-centric research and education.  To that end, we would like to assemble a team from across the country to develop a multi-institutional, multi-model, multi-data-assimilation regional scale ensemble prediction and analysis system that is capable of real-time forecasts, as well as historical reanalysis.  It is anticipated that workshop participants will come from U. S. universities, NCAR and UCAR, NOAA, NSF, and other research organizations.  Broad Impacts:  There is an urgent need for educating and training the next generation of students in mesoscale modeling, data assimilation, ensemble and probabilistic forecasting in the United States. The workshop will engage students pursuing careers in the aforementioned three areas of research. It is envisioned that the products from the planned data assimilation and ensemble prediction systems will be readily accessed by a broad community of university researchers, students and educators for exploring dynamics, physics of the atmosphere, as well as for educating the next generation of students to gain knowledge and expertise in advanced numerical weather prediction topics.  The real-time ensemble prediction system can be used as a complementary tool by operational forecasters, especially in terms of probabilistic forecasting of severe weather and tropical cyclones.  Finally, this workshop will help build capacity among the community of researchers and users of ensemble prediction and data assimilation and will foster further collaborative efforts to advance research in mesoscale meteorology.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1266399,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1266399
1835511,"SI2, CSSI",SI2,Cyberinfrastructure for Sustained Scientific Innovation - Software Elements: Cloud WRF for the Atmospheric Research and Education Communities,Cyberinfrastructure for Sustained Scientific Innovation - Software Elements: Cloud WRF for the Atmospheric Research and Education Communities,One organization,OAC,LARS SPECIAL PROGRAMS|Software Institutes|EarthCube,10/1/2018,7/31/2018,Jordan Powers,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Stefan Robila,9/30/2020,"$284,201.00 ",Yuh-Lang Lin|Russ Schumacher,powers@ncar.ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,CSE,7790|8004|8074,026Z|062Z|077Z|1525|4444|7923|8004,"This award supports the establishment of an officially-supported version of the Weather and Research Forecast (WRF) model in the cloud environment.  WRF is the world's most popular numerical weather prediction model and is supported by the National Center for Atmospheric Research (NCAR) for a community of users across universities, research labs, and operational weather centers.  This project will address fundamental issues such as modeling system accessibility, improvement of model support to the research and educational user communities, student and scientist training, and facilitation of model development. Given WRF's prominence in both atmospheric research and real-time weather forecasting, this work will not only promote the advancement of science, but also will contribute to the vigor of development and application of one of the nation's cyberinfrastucture (CI) assets, a key weather prediction model used at operational centers and for public purposes.  Furthermore, this project will contribute to education at minority-serving institutions and will yield tools to better the training of new generations of the nation's atmospheric scientists. Lastly, the project will leverage the resources and support of commercial cloud service providers to serve these national interests, in a collaboration of the principal researchers with industry.  The viability of running the WRF in the cloud has been previously demonstrated, and this project would advance the field by configuring and supporting the official version of the WRF in the cloud, with an up-to-date, cloud-configured version of the WRF system code synced to the WRF GitHub repository.  Other materials that will be available include the WRF tutorial materials and system documentation, WRF input and output datasets, and the WRF Testing Framework code analysis package.  The project will produce a configured and documented cloud WRF system that will open a new arena for model use and that will enhance the efficiency of both user support and the integration of contributed model improvements.  This cloud capability will exploit an emerging common cyber-ground to facilitate code development for the target model and allow for critical reproducibility in code analysis and testing.  It will advance the delivery of modeling system tutorials, and thus scientist training and education, through establishing globally-accessible modeling spaces, enhancing instruction portability and access, decreasing costs for host institutions, and improving usability of on-line materials.  These new cloud capabilities will be addressing bottlenecks in model support and development, and once developed, the CI can be adapted for other community models, thus benefiting other scientific disciplines and their tools via its reuse.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Program within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835511,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835511
1450180,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,Mohan Ramamurthy,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Bogdan Mihaila,7/31/2019,"$98,702.00 ",,mohan@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,CSE,1525|8004|8074,4444|7433|8009,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450180,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450180
1541031,IA,IA,EarthCube IA: Advancing netCDF-CF  for the Geoscience Community,EarthCube IA: Advancing netCDF-CF  for the Geoscience Community,One organization,ICER,EarthCube,9/1/2015,8/27/2015,Ethan Davis,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$1,091,266.00 ",Nicholas Bond|Charles Zender|David Arctur|Aleksandar Jelenak,edavis@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,7433,"For a collection of scientific data to be useful to multiple independent research groups, the collection must contain auxiliary information that describes where and how the data were collected, the units of measurement used, and other similar details. This auxiliary information, known as ""metadata,"" is crucial to allowing scientists to understand the physical and derived quantities captured by the data.  The Climate and Forecast (CF) metadata conventions for netCDF (netCDF-CF)  are currently used widely by weather forecasters, climate scientists, and remote-sensing researchers to include metadata along with scientific data, and numerous open source and commercial software tools have been developed to explore and analyze data sets that use the conventions. This project will work to extend the existing metadata conventions in ways that will broaden the range of  earth science domains whose data can be represented.  By broadening the applicability of an established convention, this effort seeks to extend its benefits to related earth science domains and reduce the amount of effort scientists must expend decoding and reformatting datasets created by other research groups. This, in turn, will leave researchers more time for analysis, leading to a better understanding of the physical processes the data describe.  NetCDF-CF is a community-developed standard first released in 2003. Originally designed to represent climate and forecast model output encoded in the netCDF binary format, with the specific goal of facilitating comparison of output from different models, the standard is now widely accepted in the climate, weather, and remote-sensing research communities, but less so in other earth science domains. This project will extend the standard to better represent a data set's spatial extents, and to encompass earth science data sets not currently covered by the conventions, including radar and more complex satellite data. Additionally, the project will work to make netCDF-CF compatible with data stored in modern data structures developed since the original creation of the conventions. Since netCDF-CF is a community-based standard, the approach will be to bring stakeholders from the existing CF community together with experts from domains into which CF can logically be extended so they can work together to design and prototype a series of enhancements, which will be submitted to the larger community for consideration. The envisioned improvements will help diverse research groups use the conventions to faithfully represent their data in formats accessible using standard, widely-available software tools.  This type of cross-domain data interoperability has the potential to give rise to more effective, integrated decisionmaking tools for a wide range of communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541031,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541031
1239746,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,Collaborative,EAR,EarthCube,4/1/2012,3/27/2012,David Gochis,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Barbara L. Ransom,3/31/2014,"$50,000.00 ",,gochis@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,7433|7916,"This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results.  Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239746,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239746
1440133,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2014,8/6/2014,Michael Daniels,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$284,673.00 ",,daniels@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,7433,"The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating  data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)  The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440133,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440133
1440293,BB,BB,EarthCube Building Blocks:  Collaborative Proposal:  Enabling Scientific Collaboration and Discovery through Semantic Connections,EarthCube Building Blocks:  Collaborative Proposal:  Enabling Scientific Collaboration and Discovery through Semantic Connections,Collaborative,ICER,EarthCube,9/1/2014,8/4/2014,Matthew Mayernik,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Eva Zanzerkia,7/31/2018,"$856,480.00 ",Michael Daniels,mayernik@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,7433,"Data, information, ideas, and technologies diffuse through social and organizational networks, if the impediments to their adoption are low and the benefits of new approaches are clear. This project brings together the National Center for Atmospheric Research (NCAR), UNAVCO, and Cornell University to understand how to improve the processes of collaboration and resource sharing in the geosciences by demonstrating and encouraging the adoption of structured information systems rooted in common standards. Using two large geoscience research programs as case studies, this effort will demonstrate how semantic web and linked data technology can play an essential role in the coordination and organization of scientific virtual organizations and their products, thereby accelerating the pace of scientific discovery and innovation.    The researchers will use a well-developed open source web application as an integrating data layer to expose the informational relationships and organizational collaborations within the case studies. This project will be an exemplar of using linked data to support virtual organizations in the geosciences. These efforts will feed into new tools that leverage linked data to support information and data exchange, and will produce recommendations on engaging user communities in linked data projects. This project will provide insight into how the geosciences can leverage linked data to produce more coherent methods of information and data discovery for large multi-disciplinary projects and virtual organizations. They will use the open source VIVO software application to illustrate how linked data can transform scientific project communication and dissemination via front end discovery based on rich networked metadata. The VIVO platform provides new capabilities for researchers and educators to use structured, interpretable data, permitting direct interlinking of information and data across platforms and projects. The project will structure data into an ontology-based, standard data format (RDF) for re-use, leveraging web identifier and vocabulary structures that have been well developed and widely adopted in the geoscience and cyberinfrastructure communities.  ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440293,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440293
1639750,BB,BB,EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2016,9/1/2016,Michael Daniels,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$742,673.00 ",,daniels@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,7433,"While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.  CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639750,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639750
1639648,BB,BB,EarthCube Building Blocks: Collaborative Proposal: That dot is a world! Drilling down from a statistics scatterplot to pre-populated case Notebooks,EarthCube Building Blocks: Collaborative Proposal: That dot is a world! Drilling down from a statistics scatterplot to pre-populated case Notebooks,Collaborative,ICER,EarthCube,9/1/2016,9/13/2016,Yuan Ho,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$545,496.00 ",,yuanho@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,8074,7433,"This project will develop and utilize capabilities for its scientists to ""drill down"" into abstract statistics about the flows of the atmosphere and ocean, to build a library of Notebooks with clear views of the actual weather systems (in the atmospheric part of the work) or Gulf of Mexico ocean eddies (in the ocean part of the work). The researchers will build this software, DRILSDOWN, using popular and powerful open-source software components that already exist, so it should be very generally applicable and have a long future. The power at the heart of the DRILSDOWN software will be the Integrated Data Viewer. The front end will consist of Jupyter Notebooks, a very popular new approach for literate computing and reproducibility of science. Literate computing allows a human-readable, meaningful, openly published document to have embedded computer-executable codes that can be repeated by anyone to replicate the results. The code can be adjusted if a user wants to see how analysis choices translate into outcomes. The involvement of scientists and a postdoc and and students will ensure the product development is useful to real research activities, while the collaboration with professional software developers (and the use of popular existing components) will ensure that it is robust and flexible enough to serve other ?use cases?, including researchers in other areas of geoscience.  The project will develop and utilize new software called DRILSDOWN to facilitate the linking of statistics to instances, a key step in the science of complex systems. In order to guide and stress test the software development, the team will perform novel atmospheric and oceanic science newly enabled by DRILSDOWN. In the atmosphere, they will study some distinct but related published measures of high-impact flow events variously classified as Rossby wave breaking (or potential vorticity filamentation) in the upper troposphere, or as poleward water vapor transports in the lower troposphere. Three-dimensional case studies will show the relationship between these low- and high-altitude descriptions, based on statistics of each measure which will allow us to select cases with high-low, low-high, and high-high measures. How do these different measures perform at characterizing these high impact events, and how might they be reconciled and perhaps optimized? In the ocean, similar activity will be to examine statistical characterizations of eddy shedding from the Loop Current in the Gulf of Mexico, an important current system for oil spills, hurricanes, fisheries, and other hazards and interests. Full-detail case studies of marginal cases (shedding/ non-shedding) will inform fundamental science understanding of the shedding process, as well as helping to improve the algorithms for objectively measuring it, so that large ensembles of possible ocean flow scenarios can be more effectively and rapidly screened, with realistic uncertainty quantification, for instance in the event of an incident requiring ocean forecasts.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639648,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639648
1449668,"EAGER, RAPID, INSPIRE",EAGER,EAGER:   Repository Cross-Linking for Open Archiving and Sharing of Scientific Data and Articles,EAGER:   Repository Cross-Linking for Open Archiving and Sharing of Scientific Data and Articles,One organization,ICER,NSF Public Access Initiative|EarthCube,12/1/2014,7/9/2014,Matthew Mayernik,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Eva E. Zanzerkia,2/29/2016,"$72,553.00 ",Don Middleton,mayernik@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,7414|8074,7433|7916,"The open availability and wide accessibility of scientific articles, data sets, and other digital resources is becoming the norm for 21st century science. Growing numbers of repositories of scientific resources enable researchers to discover, understand, and build upon previous work at greater scales than was previously possible. Many interrelationships exist between research articles, data, software, and other services used to produce scientific findings. Repositories for these resources, however, typically only supporting one particular kind of resource, or at most will support a couple of resource types, such as data and software. This has led to the siloing of information in a vast number of repositories. Producers and users of scientific resources would benefit from repositories with different specializations and user communities working together at a technical and process level to provide greater services than any one repository can provide. Through developing common workflows and information exchange protocols, this project will demonstrate how repository interconnections can be built in ways that establish connections between related resources (e.g. data, software, services, etc.).   This project will provide a model for how multiple repositories of diverse resources can exchange and connect related information via complementary workflows and metadata sharing. The project will consider two different cases: 1) connecting resources that are already hosted by repositories, and 2) connecting resources as they are newly deposited into repositories. These are common cases among data, articles, and software repositories. Case #1 looks backward in time, and case #2 looks forward in time. This project will produce a pilot implementation of repository cross-linking, using two repositories provided and managed by the University Corporation for Atmospheric Research (UCAR) / National Center for Atmospheric Research (NCAR) as the development bed: 1) the OpenSky repository, which hosts and provides access to the record of scholarship produced by UCAR and NCAR staff, and is the platform for publishing the NCAR Technical Notes series, and 2) is the Earth System Grid (ESG), which is a NCAR-hosted infrastructure for the distribution and access of climate models, data, and software. Building connections between repositories increases public access to geosciences information and data by increasing the visibility of data and information across previously unconnected systems, thereby increasing discoverability, and by increasing the utility of data through explicitly linking data to important documentation. Theproject outcomes will be shared and explored with the relevant stakeholders communities through a workshop, and with the communities brought together through EarthCube, namely, the geosciences, informatics experts, scientific publishers, and data repositories.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1449668,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1449668
856145,OTHER,OTHER,"Management and Operation of the National Center for Atmospheric Research, 2008-2018, and Supporting Activities","Management and Operation of the National Center for Atmospheric Research, 2008-2018, and Supporting Activities",One organization,AGS,"GVF - Global Venture Fund|AERONOMY|ATMOSPHERIC CHEMISTRY|PHYSICAL & DYNAMIC METEOROLOGY|LOWER ATMOSPHER OBSER FACILITI|PALEOCLIMATE PROGRAM|EDUCATION AND HUMAN RESOURCES|EDUCATION/HUMAN RESOURCES,OCE|NAT CENTER FOR ATMOSPHERIC RES|UPPER ATMOSPHERIC FACILITIES|CLIMATE SIMULATION LAB AT NCAR|ANTARCTIC EARTH SCIENCES|ANTARCTIC OCEAN & ATMOSPH SCI|Antarctic Astrophys&Geosp Sci|OPERATIONS SUPPORT PROGRAM|ARCTIC RESRCH SUPPRT & LOGISTI|ARCTIC SYSTEM SCIENCE PROGRAM|POLAR CYBERINFRASTRUCTURE|CLIMATE & LARGE-SCALE DYNAMICS|CI REUSE|AGS|COLLABORATIVE RESEARCH|EDUCATIONAL LINKAGES|UARS SPECIAL PROGRAMS|LARS SPECIAL PROGRAMS|ULAFOS SPECIAL PROGRAMS|CR|Earth System Models|EarthCube|SEES Hazards|Space Weather Research",10/1/2008,2/28/2019,Everette Joseph,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Cooperative Agreement,Sarah Ruth,9/30/2019,"$1,104,731,748.00 ",,ejoseph@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,054Y|1521|1524|1525|1529|1530|1575|1690|4200|4202|4203|5112|5113|5115|5140|5205|5219|5407|5740|6892|6897|7298|7700|7789|7790|7791|8012|8074|8087|8089,0000|026Z|1079|1303|1314|1324|1521|1524|1525|1529|1530|1575|1690|4200|4203|4444|5113|5140|5205|5219|5407|5740|5914|5978|5980|6892|6897|7386|7433|7700|7789|7790|7791|8012|8060|8092|9145|9196|EGCH|OTHR,,https://www.nsf.gov/awardsearch/showAward?AWD_ID=856145,https://www.nsf.gov/awardsearch/showAward?AWD_ID=856145
1651316,WORKSHOP,WORKSHOP,Workshop:   Modeling Research in the Cloud; Boulder Colorado; Spring 2017,Workshop:   Modeling Research in the Cloud; Boulder Colorado; Spring 2017,One organization,AGS,LARS SPECIAL PROGRAMS|EarthCube,9/1/2016,8/9/2016,Mohan Ramamurthy,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Nicholas Anderson,8/31/2018,"$49,824.00 ",Clifford Mass|David Bromwich|Brian Jewett|Wei Wang,mohan@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,GEO,7790|8074,1525|4444|7433|7556|7790,"This project is to plan, organize and host a community workshop to explore the potential for advancing ""Modeling Research in the Cloud."" The workshop, to be held in Spring 2017 at UCAR's facilities in Boulder, CO, will assemble researchers, educators, students, forecasters, and information technology (IT) professionals in academia, government and the private sector (including major cloud computing vendors). Specifically, the workshop participants will discuss the opportunities, challenges, and benefits of performing modeling research in a cloud computing environment and the means to and potential for enabling a paradigm shift in the conduct of weather and climate prediction and process studies. To achieve the workshop goals, about 30 participants from the aforementioned segments will be invited to the workshop.  Intellectual Merit: Cloud computing represents a fundamental change in the way IT services are developed, deployed, operated, and paid for, placing science communities in general and weather and climate prediction community in particular in the middle of a major paradigm shift. The cloud appears to be a potential avenue for researchers to gain access to significant computing resources beyond the traditional supercomputing center for end-to-end modeling studies, democratizing access to high performance computing resources, vast amounts of storage, and unprecedented access to large volumes of data.  Historically, the modeling community has relied mostly on high performance computing facilities (e.g., NCAR-Wyoming Supercomputing facility and XSEDE) and local computing clusters to perform their predictions. With the maturity of and significant advances in cloud computing, it has recently emerged as an alternative new paradigm for hosting and delivering a broad array of services over the Internet. The purpose of the workshop is to facilitate an in-depth discussion of the myriad aspects and formulate approaches for integrating cloud computing capabilities into the weather and climate prediction landscape, to identify atmospheric sciences communities, based on their usage patterns, needs, and resources, who would best benefit and utilize it, and discuss the significance of such integration for advancing discoveries.  Broader Impacts: The workshop will help the community to work toward a transformation in the conduct of atmospheric prediction studies, enabling researchers and educators to carry out their work in more innovative, efficient, and productive ways and push beyond the boundaries of their current knowledge and approaches.  In addition to democratizing access to computing, the workshop has the potential for transforming the conduct of atmospheric prediction studies. Cloud computing affords additional opportunities to advance data, cyber and geospatial literacy of students, and in the process the development of the next generation workforce, by enabling authentic data- and cyber-enabled inquiries.  There is a compelling need for students to understand and take advantage of rapidly developing and evolving cyberinfrastructure, data-related technologies, and data-enabled modes of scientific inquiry.  The workshop will engage graduate students, offering opportunities for enhancing their skills in data science, big data, cloud computing, and professional development. The results of the workshop will also be disseminated broadly through Unidata newsletters and presentations at scientific and computing conferences, including the AMS and AGU meetings.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1651316,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1651316
1740315,"SI2, CSSI",SI2,SI2-SSE: MetPy - A Python GEMPAK Replacement for Meteorological Data Analysis,SI2-SSE: MetPy - A Python GEMPAK Replacement for Meteorological Data Analysis,One organization,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,9/1/2017,8/29/2017,Ryan May,CO,University Corporation For Atmospheric Res,39.978318,-105.275031,Standard Grant,Stefan Robila,8/31/2020,"$499,693.00 ",Kevin Goebbert|John Leeman,rmay@ucar.edu,3090 Center Green Drive,Boulder,CO,803012252,3034971000,CSE,1525|8004|8074,4444|7433|8004|8005,"The MetPy project aims to make atmospheric science research and teaching easier and more reproducible by providing a set of well-tested and modern software tools. Meteorologists require many specialized calculations and maps in order to understand the weather and make reliable predictions. The tools they use must provide correct results, since lives and property depend on accurate forecasts and research. This project will port the bulk of the functionality from a widely used and trusted -- but aging and minimally supported -- software program called GEMPAK (the GEneral Meteorological PAcKage) into MetPy, developed using the Python programming language, and with a well-designed, new software architecture. Python has been selected as the language of choice because it has become very popular in many scientific communities. MetPy will be the meteorological community's entry into this growing scientific software ecosystem. In addition to making GEMPAK's functionality available in MetPy, this project will implement a better user-interface, which will help students and researchers get started more easily. The software team will use software development best practices in its development of MetPy, and ensure that it can work with all common meteorological data sources. Every relevant aspect of MetPy will be documented in an easy to digest way on the MetPy project webpage. The development team will work with university instructors to help revise their course materials to integrate MetPy. In addition, the team will teach MetPy and Python training workshops each year, allowing university professors, students, and professionals to get hands-on training on how to do their research in a faster and more robust way.   This project seeks to fill a need within the atmospheric science community by bringing key functional elements of a foundational software program, GEMPAK, to the innovation-rich Python ecosystem. By devoting software development resources to increasing the number of data types and file formats MetPy can work with, improving the underlying data model, and reaching feature parity with GEMPAK, MetPy can be positioned as a community-supported replacement for the older package. This effort leverages the entire Python ecosystem, and supports the movement (already well under way) of the atmospheric science community to Python-driven reproducible workflows. This transition will provide a number of community benefits. By bringing needed functionality from GEMPAK to the Python ecosystem, this project will allow atmospheric scientists to: simplify the process of exploratory analysis, have a cross-platform toolchain that can be carried from the classroom to the workforce, simplify the research workflow to make science easier and more reproducible, provide a tested library of domain-specific calculations with literature references, and create publication-quality data visualizations. Educators and researchers will be able to replace their use of legacy software, which is no longer being developed and is increasingly hard to maintain, with a modern toolkit that allows increased flexibility and reproducibility within atmospheric science research. Sustainability of the atmospheric science software workflow will be enhanced by the inclusion of modern automated software build-and-test tools, robust community-supported documentation and learning materials, and the ability to quickly incorporate new sources of environmental data. Finally, modernizing the atmospheric science toolchain opens the door to the use of innovations like web-based tools (Jupyter notebooks, for example) that would be difficult or impossible to take advantage of when using legacy software.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740315,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740315
1240394,WORKSHOP,WORKSHOP,"Workshops for Creating a Community Roadmap for EarthCube Services for Data Discovery, Mining and Access: Data Mining Services","Workshops for Creating a Community Roadmap for EarthCube Services for Data Discovery, Mining and Access: Data Mining Services",One organization,EAR,EarthCube,5/1/2012,4/17/2013,Rahul Ramachandran,AL,University of Alabama in Huntsville,34.725147,-86.639783,Standard Grant,Barbara Ransom,10/31/2013,"$99,394.00 ",Sara Graves,rahul.ramachandran@nasa.gov,301 Sparkman Drive,Huntsville,AL,358051911,2568242657,GEO,8074,7433|9150,"EarthCube, a major new NSF initiative, is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems.  This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (data mining and algorithm/data analytic techniques) that will enable the development of EarthCube. The focus of the community conversations include exploration of present data analysis approaches and possible new novel approaches; data filtering; pattern recognition and machine learning as applied to geoscience datasets; and search algorithm identification and development.  Intensive interaction will also take place with awardees and participants in the other EarthCube community groups and concept development awards.  Broader impacts of the work include: helping EarthCube realize its potential to dramatically improve the infrastructure for science, actively engaging early career geoscience researchers in the process, and supporting investigators at an institution in an EPSCoR state.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1240394,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1240394
1440081,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2014,8/6/2014,Sara Graves,AL,University of Alabama in Huntsville,34.725147,-86.639783,Standard Grant,Eva Zanzerkia,8/31/2016,"$120,000.00 ",,sgraves@itsc.uah.edu,301 Sparkman Drive,Huntsville,AL,358051911,2568242657,GEO,8074,7433|9150,"The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating  data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)  The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440081,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440081
1639720,BB,BB,EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2016,9/1/2016,Sara Graves,AL,University of Alabama in Huntsville,34.725147,-86.639783,Standard Grant,Eva Zanzerkia,8/31/2019,"$145,911.00 ",,sgraves@itsc.uah.edu,301 Sparkman Drive,Huntsville,AL,358051911,2568242657,GEO,8074,7433|9150,"While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.  CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639720,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639720
1541039,IA,IA,EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment,EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment,Collaborative,ICER,EarthCube,9/1/2015,9/9/2015,Sara Graves,AL,University of Alabama in Huntsville,34.725147,-86.639783,Standard Grant,Eva Zanzerkia,8/31/2018,"$211,104.00 ",Kenneth Keiser,sgraves@itsc.uah.edu,301 Sparkman Drive,Huntsville,AL,358051911,2568242657,GEO,8074,7433|9150,"EarthCube is supporting the creation of interoperable tools and services for Earth science research, but no environment currently exists for integration and testing of these components.  The EarthCube Integration and Test Environment (ECITE), an outgrowth of activities of the EarthCube Testbed Working Group. The ECITE approach focuses on integrating existing effective technologies and resources as well as capabilities being built by the EarthCube community to provide a federated and interoperable test environment. ECITE?s nationwide cyberinfrastructure for the geosciences will also advance the understanding of regional cyberinfrastructure and collaborative geosciences across geographic locations and disciplines by contributing relevant scheduling tools and a working integration and testing environment. A hallmark of the ECITE effort will be engagement of scientists and technologists from multiple disciplines and geographic regions across the geosciences community to develop requirements, prototype, design, build, and test an integration test-bed that will support cross-disciplinary research.  The multi-disciplinary ECITE team is led by Sara Graves of the University of Huntsville in Alabama (UAH) and includes participants from all areas of the United States. ECITE activities will enable EarthCube to further support other members and contribute leadership to the broader scientific community. The ECITE federated Integration and Test (I&T) environment has the potential to scale and extend to an NSF wide integration and test capability that can serve as a model and example for other agencies. The proposed ECITE functionality is vital to ensure that the broader goals of the EarthCube are achieved.  The ECITE team will actively engage EarthCube and the wider geosciences community in definition of requirements, design, and testing of the system. ECITE will consist of a seamless federated system of scalable and location independent distributed computational resources (nodes) across the US.  The hybrid federated system will provide a robust set of distributed resources to include both public and private cloud capabilities.  The nodes will provide compute and storage resources requiring minimal system administration.ECITE is an important step in ensuring that EarthCube components will be able to work together to provide a successful framework that can continue to evolve to meet the needs of the geosciences community.  This research addresses timely issues of integration, test and evaluation methodologies and best practices with a strong interoperability theme to advance disciplinary research through the integration of diverse and heterogeneous data, algorithms, systems and sciences. The results and findings will provide guidance for EarthCube evolution and future integration efforts. The ECITE team aims to make the Integration and Test (I&T) environment easy to use and readily available to the EarthCube community. Access to the resulting platform will enable and encourage the EarthCube community to develop prototypes, try out new technologies, and to share ideas, concepts and experiments",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541039,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541039
1639588,BB,BB,"Collaborative Proposal: EarthCube Building Blocks: Planet Microbe: Enabling the discovery and integration of oceanographic omics, environmental and physiochemical data layers","Collaborative Proposal: EarthCube Building Blocks: Planet Microbe: Enabling the discovery and integration of oceanographic omics, environmental and physiochemical data layers",Collaborative,OCE,EarthCube,9/1/2017,8/21/2017,Bonnie Hurwitz,AZ,University of Arizona,32.231885,-110.950109,Standard Grant,Michael Sieracki,8/31/2020,"$872,985.00 ",,bhurwitz@email.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,GEO,8074,1650|7433,"Oceanographic research expeditions provide a rich source of data comprised of next generation sequencing, microscopy, and physical/chemical environmental data to explore ocean biodiversity. As collection bottles and chemical sensors emerge from the depths of the ocean, research teams work through the night processing their key component of this oceanographic treasure. Despite careful efforts to share data among collaborators, the moment each sample emerges is often the last time these rich data sources are together. In this project the investigators will develop Planet Microbe, a federated resource of database connections to enable data discovery and open data sharing for historical and on-going oceanography and geobiology sequencing efforts.  Planet Microbe will provide the community with a platform that partners -omics data and analyses with any relevant contextual and environmental data available.  To promote the use of Planet Microbe, adoption by the community, and a collaborative research paradigm, the project will leverage and continue development of ECOGEO Research Coordination Network workshop on bioinformatics protocols using open-source web-based Protocols.io software. These protocols will contain multimedia training videos, screenshots, and example datasets in a stepwise format that are cross-linked to specific commands, tools, or outside websites. The investigators will refine and extend these use-cases and protocols in early career workshops. They will adapt the protocols for broader use in high school curriculum in ocean sciences and cyberinfrastructure through an existing collaboration with a technical librarian and science teacher in a high school comprised of 70% minority students. The project will offer undergraduate students research opportunities to design and develop Apps in the existing CyVerse Cyberinfrastructure to address bioinformatic needs from the oceanographic community and participate in protocol development and teaching.    Initially, the project will develop a prototype using data from Hawaii Ocean Time-series (HOT) and Bermuda Atlantic Time Series (BATS), both of which produce extensive ""-omics"" data sets (available via iMicrobe) and oceanographic data (available via the Biological and Chemical Oceanography Data Management Office (BCO-DMO)) and are of great value to the broader science community. Connections between data sets will be derived through automated distance-based algorithms, and refined through collaborative hand-curation. Once the prototype has been validated, additional -omics data sets from two NSF-funded Science and Technology Centers, the Centers for Dark Energy Biosphere Investigations (CDEBI)  and Microbial Oceanography Research and Education (CMORE), will be retrieved from disparate -omic repositories (e.g., JGI/IMG, MG-RAST, NCBI, EBI) and queryable through a recommendation algorithm fueled and refined by scientific queries from past users. Finally, data in Planet Microbe will leverage existing EarthCube funded projects to expand beyond BCO-DMO such as: GeoLink, which also includes Rolling Deck to Repository (R2R) and International Ocean Discovery Program (IODP), SeaView to share collected resources and create a ""microbe"" user scenario, and GeoDeepDive to discover dark data in historical publications. Through this concerted effort, Planet Microbe will become the go-to site for oceanographic data discovery and integration.By reconnecting -omics data with environmental data from oceanographic cruises, Planet Microbe will enable biological inquiry into environmental changes that affect the distribution and abundance of microbes in the sea. Further, algorithms for connecting disparate data types and a robust search interface developed by Planet Microbe will enable the creation of virtual datasets through user-defined oceanographic measurements, features, and thresholds that can be used to synthesize and analyze global datasets in novel ways by the community. In particular, virtual datasets can be used broadly by the geosciences community to refine global ecological models, to inform citizen science efforts, and derive critical information on temporal and spatial data associated with ocean microbes that re important in disaster analysis. Taken together, Planet Microbe will provide a much needed resource for the geosciences community to unite -omics and environmental data toward unforeseen discovery in the Earth system.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639588,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639588
1340233,"CC, GOVERNANCE",CC,EarthCube Test Enterprise Governance:   An Agile Approach,EarthCube Test Enterprise Governance:   An Agile Approach,One organization,ICER,DATANET|EarthCube,9/15/2013,9/21/2016,Tina Lee,AZ,University of Arizona,32.231885,-110.950109,Cooperative Agreement,Eva E. Zanzerkia,9/30/2016,"$3,599,687.00 ",Kimberly Patten|Ilya Zaslavsky|Erin Robinson|Christopher Keane,tinal@email.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,GEO,7726|8074,7433,"This project for Test Enterprise Governance outlines an agile model to identify, test and evaluate governance models to manage the development of Geosciences cyberinfrastructure. This model seeks broad engagement and participation of the EarthCube stakeholders to define and assess governance models while seeking evaluation and cross-checks from advisory committees and evaluation mechanisms.  This proposal employs an iterative deployment across the range of EarthCube stakeholders to encourage transparency, consensus, and inclusiveness. A broad coalition of stakeholder groups will comprise the ""Assembly? to serve as a preliminary venue for evaluating and testing governance models in Stage I, while a ""Secretariat"" will act as the coordinating body throughout the project, carrying out duties such as planning, organizing, communicating, and reporting and serve as an a priori governance test scenario itself. To ensure broader end-user participation in evaluating governance models, a ""Crowd-Source? approach will be used for members not involved in the Assembly.  In Stage II, a community selected test governance pilot will be deployed. The organizational structure will be demonstrated and evaluated. The structure and activities related to Stage II demonstration will depend heavily on the outcomes of Stage I. The role of the test governance demonstration is to facilitate community convergence on a reference architecture, procedures for standards, and coordination among emerging EarthCube elements.   The agile approach for Test Enterprise Governance has the potential to advance knowledge by providing community-guided solutions to the governance of cyberinfrastructure for the geosciences. It intends to incorporate multiple science disciplines and encourage broader participation of early career scientists. This proposal encourages cross-disciplinary research and discovery, not only across core science disciplines but also the computer and information sciences.  By building a collaborative, virtual community of practice, this proposal will enable distributed knowledge communities to cooperate, pool resources and work together across disciplines, geography, and cultures. Building upon existing NSF investments in cyberinfrastructure, this proposal allows for, and enables, a diverse set of end users previously unengaged in discussions within cyberinfrastructure - to define expectations, decision-making and leadership processes, leading to a sustainable and adaptable cyberinfrastructure for the geosciences that is extensible and scalable.  A significant responsibility of the Test Enterprise Governance is facilitation of geosciences community activities related to cyberinfrastructure, data policies and standards, and outreach related to these issues. The project will provide web services, forum and other engagement activities to facilitiate this outreach.   ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1340233,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1340233
1835794,"SI2, CSSI",SI2,Collaborative Research: Framework: Software: NSCI : Computational and data innovation implementing a national community hydrologic modeling framework for scientific discovery,Collaborative Research: Framework: Software: NSCI : Computational and data innovation implementing a national community hydrologic modeling framework for scientific discovery,Collaborative,OAC,Software Institutes|EarthCube,10/1/2018,9/12/2018,Laura Condon,AZ,University of Arizona,32.231885,-110.950109,Standard Grant,Stefan Robila,9/30/2022,"$699,587.00 ",Michelle Strout,lecondon@email.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,8004|8074,026Z|062Z|077Z|7925|8004,"This award supports the design and implementation of a software framework to simulate the movement of water at various scales. Understanding the movement and availability of water locally and across the country is of paramount importance to economic productivity and human health of our nation. Hydrologic scientists, are actively tackling these challenges using increasingly complex computational methods. However, modeling advances have not been easily translated to the broader community of scientists and professionals due to technical barriers to entry. This software platform draws from computer models and employs supercomputers capable of analyzing big data to provide unprecedented simulations of water movement over the continental US. Combining hydrologists and computer scientists the team behind the project envision a broad community of users who will have multiple ways to interact with the software framework. For the hydrologic scientist who is interested in generating their own scenarios the framework will facilitate direct interaction with the hydrologic models and the ability to generate simulations on the fly. Conversely, the framework will also provide a set of static output and a range of tools for a broader set of users who would like to evaluate hydrologic projections locally or extract model data for use in other analyses.  Continental scale simulation of water flow through rivers, streams and groundwater is an identified grand challenge in hydrology. Decades of model development, combined with advances in solver technology and software engineering have enabled large-scale, high-resolution simulations of the hydrologic cycle over the US, yet substantial technical and communication challenges remain. With support from this award, an interdisciplinary team of computer scientists and hydrologists is developing a framework to leverage advances in computer science transforming simulation and data-driven discovery in the Hydrologic Sciences and beyond. This project is advancing the science behind these national scale hydrologic models, accelerating their capabilities and building novel interfaces for user interaction. The framework brings computational and domain science (hydrology) communities together to move more quickly from tools (models, big data, high-performance computing) to discoveries. It facilitates decadal, national scale simulations, which are an unprecedented resource for both the hydrologic community and the much broader community of people working in water dependent systems (e.g., biological system, energy and food production). These simulations will enable the community to address scientific questions about water availability and dynamics from the watershed to the national scale. Additionally, this framework is designed to facilitate multiple modes of interaction and engage a broad spectrum of users outside the hydrologic community. We will provide easy-to-access pre-processed datasets that can be visualized and plotted using built-in tools that will require no computer science or hydrology background. Recognizing that most hydrology training does not generally include High Performance Computing and data analytics or software engineering, this framework will provide a gateway for computationally enhanced hydrologic discovery. Additionally, for educators we will develop packaged videos and educational modules on different hydrologic systems geared towards K-12 classrooms.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Activities Program of the Division of Earth Sciences within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835794,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835794
1265197,WORKSHOP,WORKSHOP,Operations Support For Continental Scientific Drilling Workshops,Operations Support For Continental Scientific Drilling Workshops,One organization,EAR,INSTRUMENTATION & FACILITIES,1/15/2013,10/20/2014,Andrew Cohen,AZ,University of Arizona,32.231885,-110.950109,Standard Grant,David Lambert,12/31/2014,"$54,031.00 ",,cohen@email.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,GEO,1580,,"This award will support the planning and assessment of future continental scientific drilling (CSD) opportunities for the Earth sciences community.  As a result of recent meetings (2011, 2012) of the Science Planning and Education and Outreach Committees of DOSECC a plan was put into place to provide NSF with broad community input concerning specific CSD science objectives in six broad areas for which the Science Planning and Education and Outreach Committees concluded that significant opportunities existed for CSD advances in the near future:  1) Scientific Drilling and the Evolution of the Earth System: Climate, Biota, Biogeochemistry, and Extreme Events. 2) Drilling, active tectonics and magmatism (volcanics, fault zones, Geoprisms, post-SAFOD). 3) Drilling into High-enthalpy Geothermal Systems: A Collaborative Initiative to Promote Scientific Opportunities. 4) Drilling, sampling, and imaging the depths of the critical zone. 5) EarthCube GEO Domain Workshop: Cyberinfrastructure for Paleogeoscience. 6) Broadening the Scope of Education and Outreach to Enhance the Scientific and Societal Impacts of Continental Scientific Drilling.  This award will support an on-campus IT support analyst and an off-campus workshop coordinator who will both assist the individual conveners with routine pre- and mid-workshop tasks and, most importantly, will help assemble a combined workshop report that documents and synthesizes the findings of all of these meetings, vis--vis the needs of the continental scientific drilling community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1265197,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1265197
1640775,"DIBBS, BIGDATA, III",DIBBS,CIF21 DIBBs: PD: Accelerating Comparative Metagenomics through an Ocean Cloud Commons,CIF21 DIBBs: PD: Accelerating Comparative Metagenomics through an Ocean Cloud Commons,One organization,OAC,ADVANCES IN BIO INFORMATICS|DATANET|EarthCube,1/1/2017,7/21/2016,Bonnie Hurwitz,AZ,University of Arizona,32.231885,-110.950109,Standard Grant,Amy Walton,12/31/2019,"$496,064.00 ",John Hartman,bhurwitz@email.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,1165|7726|8074,7433|8048|9102,"The Tara Oceans Expedition has provided the largest publicly available contiguous dataset available in genomics for any scientific project in the world.   Using the research schooner Tara and modern sequencing and state-of-the-art imaging technologies, a multinational team of scientists sampled microscopic plankton at hundreds of sites and depths in all the major oceanic regions.  The Tara Oceans Expedition data have been released, but it is a challenge for researchers to access, manipulate, and analyze such large-scale resources.  This project creates an Ocean Cloud Commons (OCC), a cloud-based resource and repository allowing researchers to query the Tara Oceans Expedition Data in the cloud; it also makes available comparative metagenomic tools through the Ocean Treasure Box (OTB).  The Ocean Cloud Commons and Ocean Treasure Box build upon established partnerships with organizations such as CyVerse Cyberinfrastructure, Agave Platform, OpenCloud, and computing facilities at the Texas Advanced Computing Center.  The Ocean Cloud Commons uses an algorithm based on MapReduce to create a comparative metagenomics data resource in a Hadoop big data framework.  The OCC can be widely accessed by researchers using tools developed in the Ocean Treasure Box and implemented as Apps in the CyVerse Cyberinfrastructure.  Specifically, OTB tools deploy and compute on OCC data in OpenCloud via the Agave Platform and Developer API from CyVerse.  Taken together, the OTB tools and OCC data resources enable researchers to address global-scale questions about the distribution of microbes across the sea that affect climate and ecosystem function.  This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and the NSF Directorate for Geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1640775,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1640775
1540977,IA,IA,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Jessica Blois,CA,University of California - Merced,37.364165,-120.425461,Standard Grant,Eva Zanzerkia,8/31/2017,"$68,118.00 ",,jblois@ucmerced.edu,5200 North Lake Road,Merced,CA,953435001,2092598670,GEO,8074,7433,"Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.  The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540977,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540977
1745675,"EAGER, RAPID, INSPIRE",EAGER,EAGER: DMP Roadmap: Making Data Management Plans Actionable,EAGER: DMP Roadmap: Making Data Management Plans Actionable,One organization,ICER,BIOLOGICAL OCEANOGRAPHY|EarthCube,9/1/2017,3/15/2019,Guenter Waibel,CA,"University of California, Office of the President, Oakland",37.802266,-122.271236,Standard Grant,Michael Sieracki,8/31/2020,"$275,178.00 ",,guenter.waibel@ucop.edu,1111 Franklin Street,Oakland,CA,946075200,5109879850,GEO,1650|8074,1650|7916,"The California Digital Library (CDL) will work with an extensive coalition of national and international collaborators to convert static data management plans (DMPs) into machine-actionable documents useful for structuring the course of research activities and communicating with other systems. Open data policies are proliferating worldwide and researchers are now required to submit DMPs with most grant proposals that describe the data they will produce and plans for sharing and preserving it. Researchers do not always know exactly what data they will produce at the beginning of a project, however. Furthermore, they have no incentives or easy methods for updating a DMP to keep things organized over the course of their research, which can lead to poor data practices and chaotic, unusable data shared at the end. DMPs in their current, static form pose similar challenges for other stakeholders across the research ecosystem, e.g., funders who must monitor compliance manually. This project will solve this problem by building out DMPRoadmap, a new, internationalized platform to reposition DMPs as true hubs of the networked research ecosystem. The principal impact of the proposed project is to transform one component of the increasingly digital research enterprise, the DMP, into an actively updated and machine-actionable hub to document and disseminate the products of research activity. Converting free-text responses to funder requirements into dynamic, verifiable data feeds will vastly improve the entire toolchain for all stakeholders and increase the velocity and availability of information across all disciplines. The software outputs of the pilot will be shared publicly with an open source license so that the community can continue to enhance and reuse the technology, extending the scholarly cyberinfrastructure in a scalable manner. All supporting data collected during the project will be made fully available for human and machine consumption. Since DMPs are rapidly becoming a global phenomenon, the outputs of the project will be of great interest to the entire research community. The breadth of the impact extends into the future of DMP policies worldwide, as machine-actionability makes change easier and continuous improvements possible. The project will provide insight into how to maximize investment in institutions and infrastructures in a manner that achieves policy goals by providing public access to government-funded research, and advances the overall public good.  By advancing best practices for data-intensive research across all disciplines the project will further the goals of the scientific endeavor.  The CDL will design, develop, and prototype machine-actionable DMPs based on community generated use cases; field research on DMP and data management practices; and pilot projects conducted with disciplinary and institutional partners. The work plan encompasses iterative phases of developing, implementing, and testing with various stakeholder groups using an agile methodology. Specific use cases include implementing a set of common standards and exchange protocols for DMPs to enable information to flow between DMPs and existing research information systems (e.g., offices of research, data repositories, faculty profile systems); leveraging persistent identifiers (e.g., DOIs for articles and datasets, ORCID iDs for people) to trigger push/pull notifications across systems that enable stakeholders to plan resources, connect research outputs, automate reporting and monitoring, get credit, and promote data discoverability, reuse, and reproducibility; among others.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1745675,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1745675
1917159,WORKSHOP,WORKSHOP,"Securing Legacy Seismic Data to Enable Future Discoveries: Albuquerque, NM - September 2019","Securing Legacy Seismic Data to Enable Future Discoveries: Albuquerque, NM - September 2019",One organization,ICER,EarthCube,3/1/2019,3/5/2019,Lorraine Hwang,CA,University of California-Davis,38.538232,-121.761712,Standard Grant,Eva Zanzerkia,2/29/2020,"$50,000.00 ",,ljhwang@ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,GEO,8074,7556,"This workshop will bring together stakeholders from federal agencies, national labs, and universities who are data, domain, and computational scientists to advance community goals for creating the framework for digital preservation and access to developing digital collections. Discussion will also include the tools necessary to make these data ready for research usage. Invited keynote speakers will frame the discussions and all participants will have a chance to contribute through breakout groups, interactive polling, and poster sessions.The writing group will summarize the discussions in a document addressing the two broad goals of the workshop: Goal 1: Work towards developing the framework for preservation of longitudinal seismic data. This includes recommendations for prioritizing scanning efforts, defining metadata and data imaging standards to improve discovery and (re)use, and identifying the associated technical and social challenges. Goal 2: Create an interdisciplinary network of data, domain, and computational scientists to facilitate management, access, and use of digitally imaged legacy data.  New seismological data mining methods are supporting discoveries and cross-disciplinary research across Earth system science. Such research is challenged by the relatively short time period of observation for which digital records are readily available. Historical data, recorded on paper and other physical media, potentially extend the time period of Earth observation to many decades. However, if such dark data are to be preserved and made available digitally to harness the data revolution, there are compelling challenges. The historical data are largely siloed; data are only available to scientists who can commit to traveling to specific archives or from archives capable of serving data requests. In addition, some of the physical media have been damaged or lost and/or at risk of losing stewardship. Hence, it is imperative that the community organize to preserve as well as make available these irreplaceable collections. The workshop will provide support for early-career and participants from under-represented groups.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1917159,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1917159
1440811,"SI2, CSSI",SI2,SI2-SSE: Development and Implementation of Software Elements using State-of-the-Art Computational Methodology to Advance Modeling Heterogeneities and Mixing in Earth's Mantle,SI2-SSE: Development and Implementation of Software Elements using State-of-the-Art Computational Methodology to Advance Modeling Heterogeneities and Mixing in Earth's Mantle,One organization,OAC,GEOPHYSICS|Software Institutes|EarthCube,8/1/2014,8/18/2016,Elbridge Puckett,CA,University of California-Davis,38.538232,-121.761712,Standard Grant,Alan Sussman,7/31/2018,"$502,715.00 ",Magali Billen,egpuckett@ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,CSE,1574|8004|8074,7433|8004|8005|9251,"This project involves the development and implementation of scientific software elements (SSEs), based on modern, high-resolution numerical methods for modeling steep gradients and sharp interfaces of material properties in viscous fluids in the presence of thermal convection. The goal of this project is to address a compelling need in geodynamics, in which continuum mechanics is applied to the study of geophysical processes, such as convection in the Earth?s mantle. A primary tool of geodynamics research is computational models of the flow of the extremely viscous interior of the Earth over hundreds of millions to billions of years. A long-standing challenge for these models is the need to accurately model sharp interfaces in temperature, viscosity, and other properties. These arise when, for example, modeling subduction (in which a cold tectonic plate plunges into the hot interior) or rising plumes (in which a hot boundary layer instability rises through the mantle and encounters the cold boundary layer of the tectonic plates). The project will foster interdisciplinary communication and the application of state-of-the-art applied and computational mathematics to fundamental problems in geophysics. It involves early-career mathematical scientists in the application of state-of-the-art numerical algorithms to geodynamics and, in particular, will provide an opportunity to increase the participation of women in mathematics and geodynamics research.  This project involves the design and implementation of state-of-the-art SSEs for computing the evolution of significant processes in the Earth's mantle in which an essential feature of the problem is the presence of one or more moving boundaries, interfaces, or steep gradients in temperature, composition, or viscosity. The SSEs will address two critical issues that currently limit modern mantle convection simulations. All computational models of mantle convection currently in use produce significant overshoot and undershoot in the neighborhood of sharp gradients in temperature and viscosity. The cause of these overshoots and undershoots is a numerical artifact, which is well-known and well-understood in other fields, such as the computational shock physics community. Over the past thirty years researchers in computational shock physics have developed a variety of high-order accurate, monotone numerical methods, which preserve the physically correct maximum and minimum values of the computed quantities, while producing a high-order accurate numerical approximation of these quantities. Another compelling need in computational geodynamics is the ability to track discontinuous jumps in quantities such as material composition. Here high-order accurate interface tracking algorithms are required, since these fields undergo large-scale deformation, yet quantities such as the viscosity must be accurately approximated at the interface between two materials.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440811,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440811
949446,OTHER,OTHER,Geoinformatics: Facility Support: Computational Infrastructure for Geodynamics,Geoinformatics: Facility Support: Computational Infrastructure for Geodynamics,One organization,EAR,GEOPHYSICS|CONTINENTAL DYNAMICS PROGRAM|CI REUSE|EAR|GEOINFORMATICS|EarthCube,7/1/2010,6/28/2016,Louise Kellogg,CA,University of California-Davis,38.538232,-121.761712,Cooperative Agreement,Robin Reichlin,6/30/2017,"$7,724,260.00 ",L. Ridgway Scott,kellogg@ucdavis.edu,OR/Sponsored Programs,Davis,CA,956186134,5307547700,GEO,1574|1581|6892|6898|7255|8074,1031|7433,"The Computational Infrastructure of Geodynamics (CIG) will develop, support and disseminate community-accessible software for the greater geodynamics community from model developers to the broad spectrum of end-users.  Software will support a tremendous variety of geodynamic research from mantle and core dynamics, to crustal and earthquake dynamics, to magma migration and seismology.  To be successful, the CIG will develop and maintain a high level of community participation across this research spectrum to ensure: ?  Reusable, well-documented  geodynamics software that can be demonstrated to be keeping pace with developments in hardware. ?  Basic software building blocks from which state-of-the-art modeling codes could be quickly assembled; ?  Extension of existing software frameworks to interlink multiple codes and data through a superstructure layer; ?  Strategic partnerships with the larger world of computational science and geoinformatics to ensure ?best practices? community-specific tool kits for scientific computations in solid-Earth sciences; ?  Specialized training and workshops for both the geodynamics and larger Earth Science communities; and ?  Hardware resources sufficient to support and facilitate software development and community use.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=949446,https://www.nsf.gov/awardsearch/showAward?AWD_ID=949446
1839336,"DIBBS, BIGDATA, III",DIBBS,TRIPODS+X:RES: Collaborative Research: Data Science Frontiers in Climate Science,TRIPODS+X:RES: Collaborative Research: Data Science Frontiers in Climate Science,Collaborative,DMS,TRIPODS Transdisciplinary Rese|OFFICE OF MULTIDISCIPLINARY AC|EarthCube,10/1/2018,9/10/2018,Efi Foufoula-Georgiou,CA,University of California-Irvine,33.640495,-117.844296,Standard Grant,Nandini Kannan,9/30/2021,"$300,000.00 ",Padhraic Smyth|James Randerson,efi@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,MPS,041Y|1253|8074,047Z|062Z,"Understanding the factors that determine regional climate variability and change is a challenge with important implications for the economy, security, and environmental sustainability of many regions around the globe. Our understanding and modeling of the large-scale dynamics of the Earth climate system and associated regional-scale climate variability significantly affects our ability to predict and mitigate climatic extremes and hazards. Earth observations and climate model outputs are witnessing an unprecedented increase in data volume, creating new opportunities to advance climate science but also leading to new data science challenges that must be addressed using tools from mathematics, statistics, and computer science. This project focuses on two central challenges at the heart of modern data-enabled climate science: (1) Increasing the predictive capacity of subseasonal forecasts by discovering and quantifying the sources of (un)predictability, including known and emergent climate modes and their interactions and non-stationarities; and (2) Understanding and quantifying the intricate space-time dynamics of the climate system to provide guidance for climate model assessment and regional forecasting.  This project brings together an interdisciplinary team that combines expertise in both hydroclimate science and statistical machine learning to create new platforms for climate diagnostics and prognostics.  The broader impacts of an enhanced knowledge of the climate system and robust and accurate seasonal forecasts have wide-ranging implications for society as a whole. For example, better seasonal forecasts will allow water resource managers to make sustainable decisions for water allocation.  This TRIPODS+CLIMATE project will develop novel machine learning and network estimation methodologies for analyzing the climate system over a range of space and time scales, to understand climate modes of variability and change and to explore their predictive ability for regional hydroclimatology. The two main objectives of this project are the following.  Objective 1: Develop novel classification and regression tools that account for highly-correlated features or covariates, nonlinear interaction terms in high-dimensional settings, and nonstationarity in climate observations. These tools will be used to improve seasonal-to-subseasonal forecasts of regional precipitation using multidimensional climate modes and feature vectors in the presence of evolving dynamics and nonstationarities. Objective 2: Develop network identification methods that leverage recent advances in machine learning and statistics and that can account for the nonstationarity and limited timeframe of climate data. The network representation will be used to analyze the structure and dynamics of the learned dependencies to contextualize and interpret them physically, and to quantify changing patterns in climate modes and their regional predictive capacity.  Emphasis will be placed on the western Pacific dynamics where an interhemispheric bi-directional connection has recently been discovered, promising earlier and more accurate seasonal-to-subseasonal forecasts in the southwestern US and other parts of the world.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1839336,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1839336
1239848,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,Collaborative,EAR,EarthCube,4/1/2012,3/27/2012,James Famiglietti,CA,University of California-Irvine,33.640495,-117.844296,Standard Grant,Barbara Ransom,3/31/2013,"$63,813.00 ",,jfamigli@uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,GEO,8074,7433|7916,"This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results.  Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239848,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239848
1550920,"EAGER, RAPID, INSPIRE",EAGER,EAGER-NEON: Collaborative Research: Formation of a NEON Microbial Metagenomics Data Synthesis Working Group,EAGER-NEON: Collaborative Research: Formation of a NEON Microbial Metagenomics Data Synthesis Working Group,Collaborative,DEB,MACROSYSTEM BIOLOGY,10/1/2015,8/3/2015,Emma Aronson,CA,University of California-Riverside,33.973706,-117.328064,Standard Grant,Elebeoba May,9/30/2019,"$92,730.00 ",,emma.aronson@ucr.edu,Research & Economic Development,RIVERSIDE,CA,925210217,9518275535,BIO,7959,7350|7916,"The goal of this collaborative project is to enhance the ability to analyze microbial metagenomics datasets of the National Ecological Observatory Network (NEON).  Microbial metagenomics, the characterization of microbial communities by the genes present in the sample, is important for fully understanding microbial processes. This project will enhance the comparative analytical capabilities available to the scientific community for describing properties of microbial communities, which will enable better integration of biological and geoscience data with other current earth-systems observing efforts. These improved analytic tools will facilitate developing better interconnections between environmental factors, biogeochemical processes, and microbial ecosystem structure and function in a more holistic fashion. The project will establish a Synthesis Working Group that will collect community input for guiding cyber-infrastructure and bioinformatics tool development and for answering fundamental questions with the NEON microbial metagenomics data sets.   This collaborative project will form and coordinate a Synthesis Working Group for analysis and integration of NEON metagenomics data, leveraging ongoing development of bioinformatics and cyber-infrastructure tools for metagenomic data in partnership with other concurrent earth-systems observing efforts EarthCube and Critical Zone Observatories. The Synthesis Working Group will enhance scientific advancement by 1) facilitating formation of a diverse team to inform and utilize NEON microbial metagenomic data, 2) exploring strategies for synthesis of NEON metagenomic data using existing and new bioinformatics and cyberinfrastructure tools, and 3) synthesizing NEON metagenomic datasets via integration with multiple existing and developing open data archives. This project will enable comparisons that cannot be adequately synthesized today, which is necessary for evaluating the sustainability and resilience of microbial ecosystems, as well as the function of these microbial communities in supporting key ecosystem services. The project will engender broad scientific dissemination, use, and intercomparison of NEON data products through targeted scientific outreach activities and engagement of the scientific community, including integration of NEON with other earth-systems observing efforts.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550920,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550920
1541047,IA,IA,EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science,EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science,Collaborative,ICER,EarthCube,9/1/2015,8/18/2015,Emma Aronson,CA,University of California-Riverside,33.973706,-117.328064,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$627,995.00 ",,emma.aronson@ucr.edu,Research & Economic Development,RIVERSIDE,CA,925210217,9518275535,GEO,8074,7433,"The Critical Zone (CZ) is the Earth's permeable near-surface layer from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. There has been a recent movement in the US Critical Zone Observatory (CZO) program to promote cross-CZO collaborations, with a major emphasis on biogeochemistry and related microbial ecology research. The project enable the CZ community to use software via training workshops, and better use CZ biogeochemistry and microbial ecology data. These objectives will be accomplished through a set of virtual and in-person workshops where CZ scientists have the opportunity to learn how to use the new cyberinfrastructure products, and use them to synthesize important biogeosciences and microbial ecology data from across numerous CZ sites. This effort will concurrently support the development of community-led standards for data collection and sharing. Direct involvement of software development teams as IA project personnel and collaborators will facilitate the training of members of the CZ community to use newly developed software. CZ scientists will then use these tools in a set of real-life use cases, in the form of synthesis of existing CZO data and analysis of collaboratively designed cross-CZO biogeochemical and metagenomic sample collection and analysis and ancillary measurements. This effort will not only train CZ scientists to use newly emerging EC CI tools, but also solicit community input on software improvements and identify remaining gaps and needs for further EarthCube CI development.  This project lays the groundwork for the whole-earth analysis and simulation capability envisioned through EarthCube, by bringing critical zone scientists together with hands-on training to test available cyberinfrastructure tools with comprehensive multiparameter datasets spanning a wide range of scales. The project will further improve access to the products of critical zone research by promoting the sharing, standardization, synthesis and analysis of biogeochemical and metagenomic data via EarthCube cyberinfrastructure, enabling a broader array of geosciences communities to shape future EarthCube activities and outcomes. This effort will support synthesis of broad swaths of data currently being collected at critical zone sites in the US and worldwide, as well as identify and fill key data gaps. The project will answer key biogeochemistry and microbial ecology questions, such as 1) measuring and modeling the fate of phosphorus during soil formation, and the relative role of bedrock vs. dust inputs to ecosystem phosphorus across diverse systems, and 2) evaluating nutrient availability and its impacts on microbial communities, growth rates and functions, across diverse systems. This project will also facilitate integrative scientific applications using critical zone data. The project will engender broad scientific dissemination of key EarthCube and Critical Zone Observatory products through targeted scientific outreach activities and engagement of diverse types of scientists, including a unique interaction between the computational science and geoscience communities. Key findings will be communicated through collaborative research and synthesis papers and presentations. This project will contribute extensive capacity-building in early-career researchers through targeted workshop participation. Finally, project findings and products will be used to inform future EarthCube development through the activity of the PIs and collaborators in the EarthCube Science Committee and Technology and Architecture Committee, as well as through the broader engagement of critical zone scientists into earthcube activities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541047,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541047
1343816,BB,BB,EarthCube Building Blocks: Community Inventory of EarthCube Resources for Geoscience Interoperability (CINERGI),EarthCube Building Blocks: Community Inventory of EarthCube Resources for Geoscience Interoperability (CINERGI),One organization,ICER,EarthCube,9/15/2013,8/21/2017,Ilya Zaslavsky,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Eva E. Zanzerkia,11/30/2017,"$900,000.00 ",,zaslavsk@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,8074,7433,"EarthCube Building Blocks: Community Inventory of EarthCube Resources for Geoscience Interoperability (CINERGI) Collaborating Institutions: University of California San Diego, Arizona Geological Survey, University of Chicago, Columbia University, The Open Geospatial Consortium This building block project focuses on constructing a community inventory and knowledgebase on geoscience information resources to extend work on interoperability-readiness and meet the challenge of finding resources across disciplines, assessing their fitness for use in specific research scenarios, and providing tools for integrating and re-using data from multiple domains. This capability is a key EarthCube mission mentioned in reports of several EarthCube domain workshops and roadmaps. We envision a comprehensive system linking geoscience resources, users, publications, usage information, and cyberinfrastructure (CI) components. It will supplement information included in existing data discovery catalogs by integrating feedback from users on their experience with resources, by providing characterization of resources in an interoperability assessment framework, and by supporting registration of mappings between information models and vocabularies to assist data integration. To assess interoperability among components an open source validation mechanism will be implemented. The system will enable community input and access by geoscientists via online user interfaces, and will provide documented web service APIs so that inventory information can be easily browsed, analyzed, and integrated within the emerging EarthCube CI. The project team will collaborate with related EarthCube efforts, including Building Blocks, RCNs, domain workshop and the Test Enterprise Governance. The PIs will work with researchers from selected geoscience domains (stratigraphy, hydrology, critical zone science) to validate and demonstrate advanced features of CINERGI in specific research context.  CINERGI is a direct response to the communitys need for easy discovery, assessment, and utilization of CI resources, expressed by many EarthCube stakeholders. It is a fundamental building block of an Earth Science CI and will serve geoscientists across all domains to efficiently and in more informed manner use existing and emerging resources for productive and transformative research. It will also help CI experts and computer scientists to align new developments better with existing resources such as vocabularies, ontologies, data exchange protocols, or metadata schemas.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343816,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343816
1226353,OTHER,OTHER,Collaborative Research: OpenTopography: A Cyberinfrastructure-Enabled Facility for High-Resolution Topographic Data and Tools,Collaborative Research: OpenTopography: A Cyberinfrastructure-Enabled Facility for High-Resolution Topographic Data and Tools,Collaborative,EAR,INSTRUMENTATION & FACILITIES|GEOINFORMATICS|EarthCube,4/1/2013,4/8/2016,Chaitanya Baru,CA,University of California-San Diego,32.88006,-117.234013,Continuing grant,Russell C. Kelz,3/31/2017,"$1,471,339.00 ",Viswanath Nandigam|Christopher Crosby,baru@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,1580|7255|8074,7433,"This Geoinformatics award to the University of California San Diego (PI: Baru) supports a three year development project that is collaborative with Arizona State University (PI: Arrowsmith).  The project plan will improve upon and refine the capabilities of the OpenTopography Light Detection and Ranging (LiDAR) data services web portal that was previously jointly supported by NSF/EAR, NSF/OCI and NSF/CISE (EAR-0930731/EAR-0930643).     OpenTopography (OT) was designed to allow users web-based access Lidar generated high resolution topographic data sets and analysis tools in support of surface Earth process research, research training and education.  This award will develop OT2, an extensible interface and platform that will allow scientists to develop and plug in functional modules, and a scalable system that will allow archive growth and computer services provided by cloud computing modalities.   OT2 will expand capabilities to handle full waveform LiDAR, TLS data and bathymetric data.  OT2 will continue to ingest extant airborne LiDAR and terrestrial laser scanning (TLS) data sets from numerous sources beyond airborne LiDAR and TLS data sets produced by continued and expanding use of the National Center for Airborne Laser Swath Mapping Facility (NCALM) and the UNVACO hosted TLS instrument pool.   Hosted data now at OT includes also airborne LiDAR data sets flown for EarthScope science projects, Critical Zone Observatories, NOAA, US Bureau of Reclamation, USGS, Bureau of Land Management, the US Forest Service and numerous state airborne LiDAR data sets.     Currently, OT hosts some 200 billion LiDAR returns and thousands of pre-computed digital elevation models (DEMs) and Google Earth readable kmz files.  OT management has documented high volume use of the web portal.  There are over 1,500 registered users, the site gets between 5,000 and 25,000 page view per month and more than 12,000 automated job runs have accessed over 250 billion LiDAR returns.  OT PIs also report that more than 35,000 pre-computed DEM tiles have been downloaded and over 70 Gb of Google Earth imagery is streamed per month.  The user base is approximately 22% students, 27% academic researchers, 24% government scientists and 15% commercial sector.    ***",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1226353,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1226353
1238420,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Readiness of Disciplinary Data Systems for Cross-Domain Interoperability within a Standards-Based EarthCube Reference Framework,EAGER: Readiness of Disciplinary Data Systems for Cross-Domain Interoperability within a Standards-Based EarthCube Reference Framework,One organization,EAR,Software Institutes|EarthCube,4/1/2012,3/22/2012,Ilya Zaslavsky,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Barbara L. Ransom,3/31/2014,"$217,932.00 ",,zaslavsk@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,8004|8074,7433|7916,"This EAGER award promotes a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of experts from across the fields of geoscience, cyberinfrastructure, engineering, and computer science this project focuses on using a collaborative, as opposed to competitive, method to create community consensus on the most appropriate means to realize interoperability of databases containing disparate data types that are widely distributed among many large and small data repositories. To achieve this goal, the project will create registries of interoperable infrastructure components for information-sharing of geoscience data; define user requirements for such a system; and carry out proof-of-concept, cross-domain interoperability workflows using federated catalogs, cross-linked vocabularies, common data services, and shared model semantics.  One of the unique aspects of this project is that the approach employed utilizes an inclusive, community-driven, collaborative approach.  It also engages individuals from most of the major NSF-funded geoscience data facilities, creating a much needed forum to exchange tools, services, and best practices allowing for a better return on research money investment. Broader impacts of the project include a focus on engaging students and young researchers in cross-domain data-intensive research, the likelihood that impacts of the project will crossover to other science domains, and the fact that some core project members were from under-represented groups in science and engineering.  An additional broader impact is an international component that engages UK scientists as members of the core project team.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238420,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238420
1339793,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: The Community-Driven Big-CZ Software System for Integration and Analysis of Bio- and Geoscience Data in the Critical Zone,Collaborative Research: SI2-SSI: The Community-Driven Big-CZ Software System for Integration and Analysis of Bio- and Geoscience Data in the Critical Zone,Collaborative,OAC,Software Institutes,12/1/2013,8/9/2016,Ilya Zaslavsky,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Rajiv Ramnath,11/30/2017,"$433,911.00 ",David Valentine,zaslavsk@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,8004,7433|8009,"The Critical Zone (CZ) science community takes as its charge the effort to integrate theory, models and data from the multitude of disciplines collectively studying processes on the Earth's surface. The Critical Zone is Earth's permeable near-surface layer - from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. The Critical Zone was a term coined by the National Research Council's Basic Research Opportunities in the Earth Sciences (BROES) Report (2001) to highlight the imperative for a new approach to thoroughly multi-disciplinary research on the zone of the Earth?s surface that is critical to sustaining terrestrial life on our planet. In January 2013, 103 members of the CZ community met for the CZ-EarthCube Domain Workshop (NSF Award #1252238) to prioritize the CZ community's key science drivers, key computational and information technology (""cyber"") challenges and key cyber needs. They identified that the central scientific challenge of the critical zone science community is to develop a ""grand unifying theory"" of the critical zone through a theory-model-data fusion approach.  Work participants unanimously described that the key missing need of this approach was a future cyberinfrastructure for seamless 4D visual exploration of the integrated knowledge (data, model outputs and interpolations) from all the bio and geoscience disciplines relevant to critical zone structure and function, similar to today?s ability to easily explore historical satellite imagery and photographs of the earth's surface using Google Earth.  This project takes the first ""BiG"" steps toward answering that need.  The overall goal of this project is to co-develop with the CZ science and broader community, including natural resource managers and stakeholders, a web-based integration and visualization environment for joint analysis of cross-scale bio and geoscience processes in the critical zone (BiG CZ), spanning experimental and observational designs. Our Project Objectives are to: (1) Engage the CZ and broader community to co-develop and deploy the BiG CZ software stack; (2) Develop the BiG CZ Portal web application for intuitive, high-performance map-based discovery, visualization, access and publication of data by scientists, resource managers, educators and the general public; (3) Develop the BiG CZ Toolbox to enable cyber-savvy CZ scientists to access BiG CZ Application Programming Interfaces (APIs); and (4) Develop the BiG CZ Central software stack to bridge data systems developed for multiple critical zone domains into a single metadata catalog. The entire BiG CZ Software system will be developed on public repositories as a modular suite of fully open source software projects.  It will be built around a new Observations Data Model Version 2.0 (ODM2) that is being developed by members of the BiG CZ project team, with community input, under separate funding (NSF Award #1224638).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339793,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339793
1440301,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Digital Crust: An Exploratory Environment for Earth Science Research and Learning,EarthCube Building Blocks: Collaborative Proposal: Digital Crust: An Exploratory Environment for Earth Science Research and Learning,Collaborative,ICER,EarthCube,9/1/2014,9/29/2014,Ilya Zaslavsky,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$502,497.00 ",Charles Kennel,zaslavsk@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,8074,7433,"This project develops the Digital Crust, an online workspace where the geosciences community can contribute data and knowledge, visualize, explore, synthesize and test multiple hypotheses across space-time and themes, and derive 4D data product from multiple data.The platform can serve as a resource to bring together geoscientists working on separate aspects of the Earth system, by bringing their data/ideas together and by providing an environment to view the Earth from different perspectives. It will also be a ""one-stop shop"" for Earth science educators to expose the growing minds to the multi-faceted nature of Earth science problems and to see data and knowledge gaps which are powerful motivators for the young (not all problems have been solved ? there is a place for me to contribute).   The Digital Crust platform prototype will demonstrate technology that has the potential to transform the way geoscientists  conduct research and learning, by (1) linking existing data repositories on all aspects of the Earth?s crust created by all disciplines of geosciences, communities as well as individuals, (2) creating a multi-context environment (e.g., tectonics, structural geology, stratigraphy, sedimentology, geomorphology, paleontology, archeology, mineralogy, geochemistry, soil science, hydrology, terrestrial ecology) at any given space (xyz) and time (t) for synthesis-type explorations, hypothesis-testing or learning, (3) allowing for multi-scale (e.g., outcrop to continent) data extractions and downloads for all research and learning applications, and (4) exposing data-knowledge gaps to identify the most rewarding future investments. Hosting multiple data types and sometimes conflicting interpretations and hypotheses of Earth processes will promote community discussion and debate on Earth processes that will foster interaction, collaboration, and data/idea sharing among scientists who might otherwise never have met. From the CI perspective, Digital Crust leverages and links with existing Building Blocks, explores the application of ""loose-schema"", noSQL databases to allow the flexibility necessary in a geoscience research database, and utilizes a modular software design to facilitate long-term maintenance and evolution of the platform.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440301,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440301
1639764,BB,BB,EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub,EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub,Collaborative,ICER,EarthCube,9/1/2016,9/14/2016,Ilya Zaslavsky,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$1,104,750.00 ",Amarnath Gupta|Karen Stocks|Jeffrey Grethe,zaslavsk@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,8074,7433,"Making data discovery more efficient, comprehensive and user-friendly is a critical challenge articulated by geoscientists as well as researchers in other fields. While information discovery portals and search engines have been developed for many data repositories, and systems that simultaneously search multiple resources have been created, cross-disciplinary data discovery remains a serious issue. It becomes especially acute with rapid increases in the volume and diversity of observations, reflecting different components of the Earth System and collected by multiple research groups, government organizations and commercial companies. The main goal of the EarthCube Data Discovery Hub project is to greatly reduce the time and effort necessary to locate and evaluate geoscience information resources across disciplines, and increase the value of investment in data generation by promoting data reuse and reducing duplication of effort. Project outcomes will benefit a wide group of scientists by providing them a user-friendly and powerful gateway to information resources across multiple data facilities and community contributions, and mechanisms for improving the system to answer their research queries in a consistent manner. The project will also benefit geoscience research in several ecosystems that are being used as examples to test the data tools being developed, including rivers, coral reefs and other marine ecosystems, and the critical zone where rock, soil, water, air and living organisms interact. The EarthCube Data Discovery Hub will be developed as a comprehensive data discovery and content enhancement system, which will leverage improved and community-curated metadata descriptions and integrate previously unregistered information sources. The project will further extend, improve and operationalize the inventory catalog developed in an earlier CINERGI (Community Inventory of EarthCube Resources for Geoscience Interoperability) project, which currently includes over 2 million metadata documents from multiple sources. The key technological innovations include: pioneering the development of an automated cross-domain metadata augmentation and curation pipeline enabled by a large integrated geoscience ontology; mechanisms for ?deep registration? of geoscience data from different sources based on a novel data type registry; an online use case management system; and a methodology for processing several types of complex geoscience queries that cannot be answered by existing systems. In addition, the project will support scientific progress in several representative cross-disciplinary research scenarios, using the contexts of river geochemistry, coral reef and other marine ecosystem analysis, and critical zone science. The project will implement innovative community engagement mechanisms, including community annotation of automatically curated metadata, iterative improvement of geoscience ontology based on community feedback, and joint development of cross-disciplinary use cases semantically aligned with data descriptions. ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639764,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639764
1343813,"CC, GOVERNANCE",CC,EarthCube Conceptual Design:  Enterprise Architecture for Transformative Research and Collaboration Across the Geosciences,EarthCube Conceptual Design:  Enterprise Architecture for Transformative Research and Collaboration Across the Geosciences,One organization,ICER,EarthCube,9/15/2013,9/3/2015,Ilya Zaslavsky,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Eva E. Zanzerkia,8/31/2016,"$313,640.00 ",Amarnath Gupta,zaslavsk@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,8074,7433,"EarthCube design is a complex socio-technical systemof systems, in which communication between various domain subsystems and previously disconnected CI components,people and organizations enables more comprehensive, data-intensive research designs and knowledge sharing. The main features of project include an approach that:(1) follows and enhances existing patterns of data, information and knowledge exchange within and between geoscience domains, (2) integrates ?traditional? layered cyberinfrastructure components (e.g.information sources, catalogs, vocabularies, services, analysis and modeling tools) with CI components supporting scholarly communication, self-organization and social networking (e.g.research profiles, Q&A systems, annotations) and (3) supports continuous EarthCube architectural evolution. The proposed work will be done in close collaboration with other EarthCube activities,taking input from a wide group of geoscientists and CI experts engaged in EarthCube, as well as information system architects from a range of academic and commercial projects.Design parameters include system abilities to: a) evolve by factoring in the impact of maturing movements like linked data, ?big data?, and social collaborations; b) handle the volume, complexity and diversity of geoscience information; (b) incorporate new informational and analytical requirements, tools, and techniques,(c)accommodate different ideas and approaches to research and data stewardship;(d)make best use of NSFs current investment in the geoscience CI.  The innovative aspect of this architecture planning will include three component. It will be designed as a system of systems,i.e., the basic information objects and infrastructure of any community will be re-used, but will be modeled in a manner that higher-level operations(e.g., vocabulary mashup) can be performed on them. It will be based on emerging interchange practices and protocols for scholarly objects, a paradigm that will be designed to foster inter-community research collaboration and exchange. It will be centered on a social network of communicating scientists who will use the interchange protocols. The social network will consist of both people and the information objects they choose to share as they conduct research.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343813,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343813
1239623,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,One organization,EAR,EarthCube,4/1/2012,3/28/2012,Ilkay Altintas,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Barbara L. Ransom,3/31/2013,"$18,000.00 ",,altintas@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,8074,7433|7916,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239623,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239623
1540945,IA,IA,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Collaborative,ICER,EarthCube,9/1/2015,8/19/2015,Ilya Zaslavsky,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Eva Zanzerkia,8/31/2018,"$286,000.00 ",Amarnath Gupta,zaslavsk@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,8074,7433,"A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services.   Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540945,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540945
1440412,"SI2, CSSI",SI2,SI2-SSE: Wavelet Enabled Progressive Data Access and Storage Protocol (WASP),SI2-SSE: Wavelet Enabled Progressive Data Access and Storage Protocol (WASP),One organization,OAC,ADVANCES IN BIO INFORMATICS|PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,10/1/2014,4/10/2017,Lawrence Frank,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Rajiv Ramnath,4/30/2018,"$599,999.00 ",,lfrank@ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,1165|1525|8004|8074,4444|7433|8004|8005|8009,"Advances in digital imaging methods are revolutionizing a wide range of scientific disciplines by facilitating the acquisition of huge amounts of data that allow the visualization and analysis of complex, multidimensional images. Concurrently, modern computing technologies enable numerical modeling of a broad gamut of scientific phenomena, resulting in vast quantities of numerical data, which are just the starting point for the scientific exploration that modern computational and visualization methods enable. This is particularly true in the biological and geosciences, two seemingly very different disciplines. These capabilities come with a cost: increasing data size and complexity require more sophisticated methods for data analysis and visualization. This project will conduct research that will lead to a common software framework for supporting a multi scale progressive data refinement method based upon the representation of the data as a wavelet expansion, and enabling interactive exploration of large data sets for the bio  and geoscience communities.  The development of a general toolkit for wavelet based representations of data will have broad impact, allowing the multi scale analysis, storage, and visualization for data collected in a wide range of fields and on a multitude of platforms, from high end computing facilities to laptop computers used by students, field biologists, and others.  Analysis and visualization of large data sets play an important role in scientific discovery. Efficient, and broadly available tools to accomplish these tasks are crucial for a wide range of scientific and educational fields. However, efficient analysis and visualization is a non trivial problem as the size and complexity of data increases. This research addresses this challenge through a general progressive access, multi scale data representation for efficient handling of structured data sets across a range of science domains. The development is based upon a wavelet enabled data representation developed by NCAR for geoscience applications. The tools will utilize the very flexible and open source standard NetCDF format, and the methods will be documented as a set of conventions and a toolkit developed that incorporates and integrates these components for dissemination. In addition to an open source toolkit, these tools will be integrated into the VAPOR (NCAR) and STK (CSCI) platforms, thus expanding the capabilities and efficiencies of these platforms for the geo  and bio sciences communities, respectively.  Advancements generated by this project will be openly disseminated to the user community through an open source toolkit.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440412,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440412
1747490,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Building the Community for the Open Storage Network,Collaborative Research: Building the Community for the Open Storage Network,Collaborative,IIS,EarthCube,6/15/2018,6/7/2018,Michael Norman,CA,University of California-San Diego,32.88006,-117.234013,Standard Grant,Alejandro Suarez,5/31/2020,"$432,400.00 ",Christine Kirkpatrick,mlnorman@ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,8074,062Z,"The scientific community is facing a major challenge dealing with the increasing amount of open scientific data emerging from research projects on all scales-- from large facilities to small research labs. Over the last five years the NSF has funded more than 200 high-speed connections to the Internet-2 backbone operating at 10-100Gbps speeds. The goal of this project is to develop a prototype module for a high performance distributed storage system that extends the usability of the existing high-speed interconnects. This project is a pilot for a potential national-scale storage infrastructure for open scientific data, which at full scale could serve hundred sites and many hundreds of Petabytes.  Many of the technologies associated with such a distributed system already exist; the key challenge in this project is social engineering: how can one design a simple enough yet robust storage node that can be easily replicated, is attractive for universities and research projects to adopt, is easy to manage and can support the various patterns for large scale scientific analyses?  Many universities have several of the necessary pieces for Data Intensive Science in place-- reasonably sized computing clusters, a few PB of storage and even a high-speed connection-- yet performing the analyses of data intensive science is very painful and slow. Data is never there when needed, large storage systems often fail despite having massive RAID configurations, and moving data from disk-to-disk at the full network speed still requires complex skills. The project offers a broad community buy-in through the Big Data Hubs, a unique combination of skills, facilities and science challenges to test, evaluate and deploy different hardware and software combinations that can be used in the design of a much larger, national-scale system. The goal is to design and run detailed benchmarks for various test science projects requiring different combinations of data transfer, data processing and massive compute, and use the results to design and build a low-cost, scalable petascale appliance including inexpensive hardware nodes and a simple software stack that can be replicated across many universities, supercomputer centers and large NSF facilities. The proposed system could become an enormous multiplier on the existing NSF investments in high end computing and fast networks. It could also accelerate the pace of standardization of data storage across the nation. The public, open data products, often discussed in the Data Management Plans at the end of NSF proposals could find an easy-to-use home. Various educational projects could simply rely upon a robust storage infrastructure with a simple API, and build a variety of delivery services for the educational community.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747490,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747490
930731,OTHER,OTHER,"Facility Support:  OpenTopography - A National Hub for High Resolution Topographic Data, Tools, and Knowledge","Facility Support:  OpenTopography - A National Hub for High Resolution Topographic Data, Tools, and Knowledge",One organization,EAR,INSTRUMENTATION & FACILITIES|CI REUSE|INFO INTEGRATION & INFORMATICS|EarthCube,9/15/2009,8/8/2014,Chaitanya Baru,CA,University of California-San Diego,32.88006,-117.234013,Continuing grant,Russell C. Kelz,8/31/2014,"$1,517,073.00 ",,baru@sdsc.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,GEO,1580|6892|7364|8074,0000|7433|OTHR,"This collaborative grant to the San Diego Supercomputer Center and Arizona State University (PI:  Arrowsmith/EAR-0930643) will support a three year Facility project to further develop and scale up the OpenTopography Portal (http://www.opentopography.org) for provision of high-performance, internet-based access to large volumes of high-resolution airborne and ground-based LIDAR topographic data sets and generation of derived data products.  The proof-of-concept OpenTopography Portal (OpenTopo) was developed through NSF/Information Technology Research and EAR/Geoinformatics support to the San Diego Supercomputer Center as part of the GEON Project.  That portal currently hosts and distributes a limited number of data sets acquired through the NSF/EAR supported National Center for Airborne Laser Swath Mapping (NCALM) at the University of Florida and from USGS and NASA-funded research.  This support will enable significant upgrades and assimilation of large volumes of extant and future LIDAR data through: 1) provision of internet-based access to LIDAR topography data in multiple formats, including ?raw? point cloud data, standard LIDAR-derived DEMs, and easily accessible Google Earth products; and 2) development of additional collaborations with existing LIDAR topography data providers and hosts (e.g.,  NCALM, USGS, regional consortia, states, etc.) to link to their data archives and/or to host and distribute their data and processing software algorithms through a freely accessible web-interface.  High-resolution digital elevation models derived from LIDAR (Light Distance And Ranging) methods (both airborne and ground-based) have been revolutionary for Earth science, environmental, and engineering applications. These data are among the most powerful tools available for study of the bare Earth surface, vegetative cover, and civil structures.  Capable of generating digital elevation models (DEMs) more than an order of magnitude better resolved than those currently available from digitized USGS topo maps or from Shuttle Radar Topography Mission products, airborne LIDAR (or airborne laser swath mapping - ALSM) provides the ability to acquire meter-scale resolution, decimeter accuracy elevation data sets over large areas at relatively low expense.  Ground-based or terrestrial laser scanners (TLS) offers even finer resolution mapping for specific targets.  These data enable research on surface processes at fine scales and extents not previously possible yet essential for understanding processes (e.g., erosion, hillslope creep) at the scales at which they operate.  OpenTopo will address the challenge of making massive LIDAR data sets and products readily accessible to end users through a freely accessible web-portal.   ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=930731,https://www.nsf.gov/awardsearch/showAward?AWD_ID=930731
1546351,"DIBBS, BIGDATA, III",DIBBS,BIGDATA: Collaborative Research: IA: Quantifying Plankton Diversity with Taxonomy and Attribute Based Classifiers of Underwater Microscope Images,BIGDATA: Collaborative Research: IA: Quantifying Plankton Diversity with Taxonomy and Attribute Based Classifiers of Underwater Microscope Images,Collaborative,IIS,ADVANCES IN BIO INFORMATICS|BIOLOGICAL OCEANOGRAPHY|EarthCube|Big Data Science &Engineering,10/1/2016,9/14/2016,Jules Jaffe,CA,University of California-San Diego Scripps Inst of Oceanography,32.86814,-117.250323,Standard Grant,Elizabeth Blood,9/30/2019,"$916,113.00 ",Peter Franks,jjaffe@ucsd.edu,8602 La Jolla Shores Dr,LA JOLLA,CA,920930210,8585341293,CSE,1165|1650|8074|8083,7433|8083,"Plankton play an essential role in the global ecosystem, forming the base of marine food webs, linking the atmosphere to the deep ocean, and regulating a myriad of ecologically and climatologically important processes. Despite their importance, however, the technology to assess abundances and distributions of plankton has been limited. Changes in abundances of individual species are particularly poorly resolved; this includes the harmful algal blooms that have profound economic, societal, and ecosystem effects in many coastal systems. Traditional tools such as nets and bottles can destroy fragile organisms during sampling. Underwater microscopes, on the other hand, allow observation of the organisms undisturbed, and in their natural setting. New underwater microscopes are generating many thousands of high-resolution images of individual plankton each day. Before these images can be used for scientific analyses, the imaged organisms must be identified and classified. However, the vast number of images generated by such microscopes has led to a serious bottleneck: identification and classification of the images takes an impossibly long time for individuals to accomplish. Fortunately, advances in computer vision science have shown great promise in accurately performing such classification tasks. The main goal of this award is to explore and develop computer vision approaches for plankton image classification. A team of instrumentation specialists, an ocean ecologist, and a computer scientist, including two graduate students and one post doctoral student, will formulate, implement, and test methods to advance the goal of efficient and accurate automated plankton image classification. The advances made in this award will enable both improved classification algorithms in computer science, and vast new data streams for plankton ecology.  Plankton form the base of marine food webs, link the atmosphere to the deep ocean, and regulate  global biogeochemical cycles. Plankton are often studied either through bulk measures, or by manual enumeration of individual taxa. Novel underwater microscope systems such as the Scripps Plankton Camera System (SPCS) are generating tens of thousands of images of individual plankton daily. However, without accurate annotation of the images, the potential science is limited. This project will explore the use of many-layer, deep Convolutional Neural Nets (CNN) as automated computer recognition methods; these techniques hold promise for classifying the nearly one trillion underwater microscope images that have been collected by a variety of research groups around the globe. The primary source of images will be a pair of microscopes that have been operating for 2 years from the Scripps Inst. of Oceanography's pier, yielding 200 million regions of interest. The project will build a large data base of training sets using a novel approach: a bench-top imaging system that is capable of rapidly producing thousands of annotated images showing organisms in all orientations and configurations identical to that in the field. Based on these automatically collected training sets, and hand annotation of in situ images from experts, a deep  (many layer) CNN will embed taxonomic and attribute constraints, and will be used to classify the organisms imaged. With success, this massive, growing, taxonomically classified dataset will enable unprecedented, transformative, taxon-specific explorations of the dynamics of the planktonic ecosystem on time scales from hours to decades.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1546351,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1546351
1540966,IA,IA,EarthCube IA: Oceans of Data: Bringing EarthCube to the Science User,EarthCube IA: Oceans of Data: Bringing EarthCube to the Science User,One organization,ICER,EarthCube,9/1/2015,8/18/2015,Karen Stocks,CA,University of California-San Diego Scripps Inst of Oceanography,32.86814,-117.250323,Standard Grant,Eva Zanzerkia,8/31/2019,"$436,815.00 ",Stephen Diggs,kstocks@ucsd.edu,8602 La Jolla Shores Dr,LA JOLLA,CA,920930210,8585341293,GEO,8074,7433,"The ability to find, access, and visualize data is critical to many kinds of oceanographic research, as well as to teaching oceanography. Yet ocean data is held in multiple data facilities, in different formats, and is accessible through different pathways. This creates practical problems with integrating and working across different data sets. The SeaView project is building connections between the rich data resources in five major oceanographic data facilities - R2R, BCO-DMO, CCHDO, OBIS and OOI* - and an ocean data visualization and exploration tool, the Ocean Data View (ODV), having over 40,000 registered users. To do so, it is leveraging from NSF investments into two previous EarthCube projects: CINERGI, as the registry where users will find and access data they wish to use, and GeoLink, which is providing interconnections between existing data resources, allowing users to explore a knowledge base of related information. SeaView leverages existing resources to provide improved tools and data access in support of fundamental research in two areas of ocean sciences: deep water hydrography and marine community-environment interactions. Both feed directly into research identified by the 2015 Decadal Survey of Ocean Sciences as of the highest priority. It will also engage scientists from currently underrepresented communities in EarthCube.  The specific oceanographic communities targeted are deep water hydrographers and marine ecologists, particularly those studying species interactions with the environment. Near the start of the project, a set of three focus groups and a Science Drivers workshop composed of end-user scientists from these communities will prioritize the specific datasets and develop science scenarios (use cases). They will meet again mid-stream for hands-on testing of the tool and feedback.  The CINERGI registry will be used to expose ODV-supported formats from these repositories to ODV. The EarthCube GeoLink knowledge base will provide links to additional content (investigators, publications, etc.) for cruise-related datasets loaded in ODV.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540966,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540966
1313870,WORKSHOP,WORKSHOP,Collaborative Project: EarthCube Education End-User Workshop,Collaborative Project: EarthCube Education End-User Workshop,Collaborative,ICER,EarthCube,2/1/2013,1/17/2013,Cheryl Peach,CA,University of California-San Diego Scripps Inst of Oceanography,32.86814,-117.250323,Standard Grant,Jill L. Karsten,1/31/2014,"$52,998.00 ",,cpeach@ucsd.edu,8602 La Jolla Shores Dr,LA JOLLA,CA,920930210,8585341293,GEO,8074,,"This award is being used to convene a workshop of ~40 participants to define end-user needs related to geoscience education within the EarthCube initiative.  The workshop brings together disciplinary faculty in the geosciences, educators experienced in teaching with geoscience data and developing associated curricula, representatives of NSF-sponsored research programs involved with generation of large data sets, as well as technologists, STEM education researchers, and learning scientists.  The workshop is being held at the Scripps Forum (Scripps Institution of Oceanography) during the Spring of 2013.  The workshop seeks to explore both the educational opportunities offered through the cyberinfrastructure capabilities of the EarthCube program and identify the educational needs for preparing undergraduate students and faculty to be the future contributors to the scientific research enabled by EarthCube.  A major goal of this workshop is to establish an initial roadmap for educational activities that should be associated with or enabled by EarthCube.  The workshop will consider the educational and instructional strategies not only to prepare students in undergraduate programs to be technologically-savvy users of EarthCube data and models, but also to build the future scientific capacity to advance Earth systems scientific research.  Consideration will also be given to how EarthCube may serve as a platform for advancing STEM education research.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1313870,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1313870
1440084,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2014,8/6/2014,Frank Vernon,CA,University of California-San Diego Scripps Inst of Oceanography,32.86814,-117.250323,Standard Grant,Eva Zanzerkia,8/31/2016,"$20,000.00 ",,flvernon@ucsd.edu,8602 La Jolla Shores Dr,LA JOLLA,CA,920930210,8585341293,GEO,8074,7433,"The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating  data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)  The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440084,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440084
1743687,RCN,RCN,EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network,EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network,Collaborative,ICER,EarthCube,5/1/2017,6/15/2017,Fiammetta Straneo,CA,University of California-San Diego Scripps Inst of Oceanography,32.86814,-117.250323,Standard Grant,Eva Zanzerkia,7/31/2019,"$253,349.00 ",,fstraneo@ucsd.edu,8602 La Jolla Shores Dr,LA JOLLA,CA,920930210,8585341293,GEO,8074,7433,"Greenland ice loss quadrupled over the last two decades and presently accounts for one quarter of global sea level rise. The ice loss is due to changes in surface mass balance and ice sheet dynamics associated with rising air and ocean temperatures. The associated increasing freshwater discharge is impacting the regional ocean, including its ecosystems, and has the potential to impact the large-scale North Atlantic circulation. Thus, Greenland's changes are having far-reaching consequences for global societies, yet the mechanisms responsible for these changes are not well understood. Dynamic ice loss, in particular, was likely triggered by changes at the margins of marine-terminating glaciers, through ice/ocean/atmosphere processes that are either absent or poorly represented in climate, ice sheet and ocean models. The interaction of the ocean, the glaciers and atmosphere at Greenland?s margins is a new research frontier. The complex processes involved include the coupling of multiple components of the Earth system, the challenges of obtaining and integrating diverse data from this region, and of modeling such a complex system. These challenges make this a problem that can only be addressed by bringing together multiple disciplines, including data management, collaboratively exploring diverse approaches and working across national borders. This project establishes a network to help scientists working in this area to share their data and work collaboratively.  The goal of this project is to substantially enhance multi-disciplinary activities and collaboration through the establishment of the GRISO (Greenland Ice Sheet Ocean) Science Network - an international, multidisciplinary, open network of scientists and cyberinfrastructure experts. Participants have a shared interested in advancing collective understanding of problems related to Greenland Ice Sheet change and its impact on regional and global climate. GRISO RCN activities will bring together scientists focused on all aspects of ice/ocean/atmosphere/climate data in Greenland and provide a framework for productive collaborative interaction. Specific objectives include two workshops, and a series of synthesis efforts. Additionally, a virtual data portal, leveraging existing infrastructure, will make interdisciplinary data submission and data availability easier and promote uniform and appropriate data management practices. The RCN builds on activities initiated by the former GRISO US CLIVAR Working Group and explicitly addresses priorities identified in a report from an international workshop held in 2013.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1743687,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1743687
1834807,"SI2, CSSI",SI2,Elements:  Software - Harnessing the InSAR Data Revolution: GMTSAR,Elements:  Software - Harnessing the InSAR Data Revolution: GMTSAR,One organization,OAC,XC-Crosscutting Activities Pro|EarthCube,10/1/2018,8/15/2018,David Sandwell,CA,University of California-San Diego Scripps Inst of Oceanography,32.86814,-117.250323,Standard Grant,Stefan Robila,9/30/2021,"$281,747.00 ",,dsandwell@ucsd.edu,8602 La Jolla Shores Dr,LA JOLLA,CA,920930210,8585341293,CSE,7222|8074,026Z|062Z|072Z|077Z|7923|8004,"The award supports the development of a software tool aimed at lowering the barriers for the use of Interferometric Synthetics Aperture Radar (InSAR) data. Natural processes such as earthquakes, volcanoes, landslides, and glaciers cause deformation of the surface of the earth that can now be monitored to 10 mm precision globally.  These surface measurements provide a new tool for investigating processes in the interior of the Earth. InSAR is a powerful and low-cost way to monitor subsurface magma movement and is especially useful when combined with other tools such as GPS and seismic data.  InSAR is also used to understand subsurface fluid movement, such as caused by groundwater withdrawal, geothermal production, or in oil and gas fields. A wide variety of new SAR satellites are currently operating and the US will have an even more capable mission in the near future.  These massive data sets need to be transformed into information to promote the progress of science, mitigate natural  hazards, and enhance use of underground resources. The software, named GMTSAR will develop robust and sustainable software to take full advantage of the satellite generated data for both science and applications.  The main innovation of this project is to develop open and robust software to simplify the InSAR data processing and enable routine processing of thousands of SAR images on state-of-the-art computer facilities.  Open distribution of software, and the GMTSAR theoretical basis document provide a foundation for education in the field of space geodesy and ensures availability to a diverse audience.  This proposed investigation will use standard software engineering practices to harden the GMTSAR code, improve the geodesy, and make it more accessible to novice and advanced users on a wide array of UNIX platforms.  This will be achieved through improved and automated testing, partial redesign and simplification of the work flows, UNAVCO short courses, user feedback, and eventual migration of the code distribution and maintenance to a national facility. Work will be performed by a postdoctoral researcher in collaboration with the GMTSAR and GMT development teams and with assistance from the XSEDE program. The expected outcome is to provide sustainable, open, geodetically-accurate software to move InSAR time series analysis from the intermediate-scale methods published today to large spatial and time scale analyses that are becoming possible using the new data streams.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Activities Program of the Division of Earth Sciences within the NSF Directorate for Geosciences, and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the Office of Advanced Cyberinfrastructure.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1834807,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1834807
1829814,OTHER,OTHER,"Operation of a Hydrographic Data Office at UCSD/SIO, 2019-2023","Operation of a Hydrographic Data Office at UCSD/SIO, 2019-2023",One organization,OCE,PHYSICAL OCEANOGRAPHY|EarthCube,9/1/2018,8/27/2018,Karen Stocks,CA,University of California-San Diego Scripps Inst of Oceanography,32.86814,-117.250323,Continuing grant,Baris Uz,8/31/2023,"$593,238.00 ",James Swift|Bruce Appelgate|Sarah Purkey,kstocks@ucsd.edu,8602 La Jolla Shores Dr,LA JOLLA,CA,920930210,8585341293,GEO,1610|8074,062Z|1324,"The project is to continue to operate the CLIVAR and Carbon Hydrographic Data Office (CCHDO) at the UCSD Scripps Institution of Oceanography funded by NSF previously. The CCHDO's primary mission is to deliver the highest possible quality global Conductivity-Temperature- Depth (CTD) and hydrographic data to users. These data are a product of decades of observations from multiple programs, past and present, around the world. The project will enhance research infrastructure, disseminate results broadly, and integrate research and education. While the CCHDO does not generate new data, it improves data quality, usability, and accessibility, thus widening the reach of the data and its scientific and social relevance. CTD, routine hydrography, ocean carbon, and tracer ocean profile data are gathered, quality controlled, and put in a standardized format all located on one website so that the data is usable to a much wider audience in the research, educational, and broader communities who do not employ data specialists. The CCHDO puts into play the fundamental concept that ocean data belongs to the community, and should be available to the community. The CCHDO directly contributes to research of high societal importance, such as the ocean's response to and role in climate change. The CCHDO contributes to education and STEM activities, including training of undergraduate research assistants and enhancing the oceanographic aspects of their experience, and participation of the CCHDO leadership in STEM and Career Day events in the San Diego area. Commitment to broadening the participation of underrepresented groups extends to every aspect of the CCHDO.  The CCHDO performs meticulous curation and dissemination of the highest quality CTD, hydrographic, carbon and tracer water column data. The CCHDO supports climate and ocean carbon science programs, and is a critical component of a global observing system for the physical climate/CO2 system. It is the official international GO-SHIP data center for CTD and water sample profile data and related documentation. In addition, the CCHDO is responsible for data from WOCE, CLIVAR, the International Ocean Carbon Coordination Project, and other oceanographic research programs. The CCHDO's user-oriented data management structure and functions were developed to pull together and verify data and information from diverse, disparate sources, placing the data into near lock-step agreement with community-agreed standards, and organize the documentation to make information about the data complete and easy to locate. The users of CCHDO data benefit from the CCHDO's activities, saving them from performing these time-consuming, expertise needing tasks. This ""data assembly center"" structure thus facilitates gaining broader scientific understanding well beyond the collection and interpretation that can be gained from individual data sets. The CCHDO assures that these data and their associated documentation are readily available for immediate research and education uses, easily accessible through an intuitive and well known online search and download site, can be used in a variety of applications, and are promptly provided to NOAA's NCEI for long-term archive. This ensures that these data have maximum utility to the scientific community and a long service life.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1829814,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1829814
1344385,WORKSHOP,WORKSHOP,Collaborative Project:  EarthCube Domain End-User Workshop:  Developing a Community Vision of Cyberinfrastructure Needs for Coral Reef Systems Science,Collaborative Project:  EarthCube Domain End-User Workshop:  Developing a Community Vision of Cyberinfrastructure Needs for Coral Reef Systems Science,Collaborative,OCE,EarthCube,8/1/2013,7/10/2013,Mark Schildhauer,CA,University of California-Santa Barbara,34.413963,-119.848947,Standard Grant,Michael Sieracki,7/31/2015,"$65,760.00 ",,schild@nceas.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,GEO,8074,7433,"The Geosciences EarthCube program recognizes the importance of aligning cyber-infrastructure activities with the needs of end user research communities. To that end we propose to convene 50-70 members of the coral reef community in two workshops, one held at the University of Hawaii (HIMB) and the other at the University of California Santa Barbara National Center for Ecological Analysis and Synthesis (NCEAS). The specific objectives of the workshop are to:   1. Define current and future (5-15 years) scientific challenges in the field  2. Summarize data and cyber-infrastructure constraints that prevent these challenges being realized  3. Collate current community data and modeling resources and their locations  4. Identify and recommend data infrastructure that could facilitate rapidly addressing the scientific challenges in the field  The coral reef research community is multidisciplinary and the data on reefs is diverse and complex, crossing biological scales from genes to ecosystems, temporal scales from nanoseconds to millennia, and spatial scales from nanometers to kilometers. The challenge is to integrate across these data sources to identify patterns and relationships that rapidly improve our understanding of coral reefs systems. This effort has been hindered to date by the lack of tools to accomplish this and ineffective means of sharing data or collaborating. This project will support workshops that engage the coral reef community to 1) develop a common vision of the grand science challenges in the field 2) highlight how data cyber-infrastructure needs will integrate the complex datasets and potentially facilitate rapid progress in key areas of coral reefs ecosystem science and 3) emphasize the value of collaboration and data sharing as a first step to changing and improving the way coral reef scientists support each other and advance the field.  As ecosystem engineers, corals provide the nutritional, economic, and structural basis of an ecosystem worth billions of dollars annually. This workshop proposal convenes the coral reef community and will address how cyber-infrastructure can inform coral reef systems science. The latter will ultimately accelerate understanding of reef ecosystems, broaden the scope of the questions that can be asked and build capacity to predict how these societally relevant and fragile ecosystems will face the challenges of climate change and human development. The workshops will also be attended by at least 4 postdocs and represents a significant professional development opportunity for these individuals. Results will be disseminated on the EarthCube website, the NCEAS website, and the HIMB website making them broadly accessible to the science, education and the public. The product from the proposed endeavor will be a report to NSF EarthCube summarizing the discussion for each of these objectives that will serve to define and align the needs across the Geosciences and help prioritize EarthCube activities. There is also an opportunity to use the results to develop a manuscript that articulates how cyber-infrastructure can address the science challenges facing the coral reef community and facilitate a systems level science agenda. Such a product could have high value in both the science funding and policy realm.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1344385,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1344385
1740581,IA,IA,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative,ICER,EarthCube,10/1/2017,9/14/2017,Vena Chu,CA,University of California-Santa Barbara,34.413963,-119.848947,Standard Grant,Gregory J.  Anderson,9/30/2020,"$181,266.00 ",,venachu@ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,GEO,8074,7433,"Satellite imagery is rapidly transforming the way we see the planet, including our ability to study the most remote parts of the Arctic and Antarctic. Satellite imagery can help us map networks of rivers, study changes in the flow and thickness of glaciers, identify rock and soil types, and even find animals like penguins and seals. Because the availability of imagery in polar areas has increased rapidly over the last decade, we are now faced with a challenge: To move from small pilot-studies to pan-Arctic or pan-Antarctic analyses of geological and biological processes requires new infrastructures that link scientists, satellite imagery, and fast computing. The project, called ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, aims to build the cyberinfrastructure required to make the most of satellite imagery for geosciences, starting with researchers working in polar areas, and then branching out to the larger community. The Broader Impacts of this proposal include the training of undergraduate and graduate students, as well as young investigators and female scientists. Moreover, the scientific findings enabled by this proposed cyberinfrastructure will have immediate benefits for our ability to predict the future dynamics of the polar regions, and critical to the management of Arctic and Antarctic resources.   Polar geosciences stands at the precipice of a revolution, one enabled by the confluence of cutting edge analytical tools, petabytes of high-resolution imagery, and an ever growing array of high performance computing resources. With these tools at hand, we can look beyond incremental improvements in our understanding of the polar regions. Near-real time datasets of geological and biological importance at the continental scale are within our reach if we create those critical cyberinfrastructure components that allow the geosciences community to exploit existing assets and establish a common workflow for reproducible imagery-enabled science. The research objective of this proposal is to understand the biological, geological, and hydrological functioning of the polar regions at spatial scales heretofore beyond the reach of individual PIs, and to develop tools for imagery-enabled science that can be applied globally. The resulting cyberinfrastructure, which we call ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, is an extensible system for coupling open-source image analysis tools with the use of high performance and distributed computing (HPDC) for imagery-enabled geoscience research. We propose a project to (1) develop open source image classification tools tailored to high-resolution satellite imagery of the Arctic and Antarctic to be used on HPDC resources, (2) create easy-to-use interfaces to facilitate the development and testing of algorithms for application specific geoscience requirements, (3) apply these tools through use cases that span the biological, hydrological, and geoscience needs of the polar community, (4) transfer these tools to the larger non-polar community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740581,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740581
1440139,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,Collaborative,ICER,EarthCube,9/1/2014,8/19/2014,Mark Schildhauer,CA,University of California-Santa Barbara,34.413963,-119.848947,Standard Grant,Eva Zanzerkia,8/31/2018,"$481,214.00 ",Matthew Jones|Krzysztof Janowicz,schild@nceas.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,GEO,8074,7433,"The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.  A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440139,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440139
1540849,IA,IA,EarthCube IA: Collaborative Proposal: Cross-Domain Observational Metadata Environmental Sensing Network (X-DOMES),EarthCube IA: Collaborative Proposal: Cross-Domain Observational Metadata Environmental Sensing Network (X-DOMES),Collaborative,ICER,EarthCube,9/1/2015,8/18/2015,Krzysztof Janowicz,CA,University of California-Santa Barbara,34.413963,-119.848947,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$55,288.00 ",,jano@geog.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,GEO,8074,7433,"Across-domains, agencies and political boundaries, our environment is being continuously observed and studied.  The researchers in this project are looking for short-term, near-term and long-term changes while researching new and evolving methods to observe properties and to process the collected observations.  Emerging technologies enable us to provide and discover the data openly and freely.  But, if we do not understand the newly discovered data, with its inherent limitations and biases, it cannot be responsibly utilized for new or collaborative research efforts.  Working with environmental sensor manufacturers and researchers, the X-DOMES project will develop tools and social and technical infrastructure to facilitate the creation of data about data (metadata).   Metadata describes not only who, when and where the observations were made, but also it must document how an observation came to be (provenance).  By taking this knowledge out of manuals and human-readable documents, the X-DOMES model creates metadata that can be treated like data ? discoverable and searchable, making it ready to be incorporated into automated archival and processing for quality assurance and validation methods.   Leveraging existing relationships with large NSF-funded data management programs, EarthCube building blocks and working groups, and environmental sensor manufacturers and consortia, we will establish a community of sensor manufacturers and other stakeholders to provide a unifying approach to describing sensors and observations across geo-science domains.  Built on an existing sensor metadata model that references registered, standards-based vocabularies, the X-DOMES pilot project will provide a suite of tools, built upon community-adopted standards of the Open Geospatial Consortium (OGC) and World Wide Web Consortium (W3C) to demonstrate and facilitate the generation of documents that are discoverable and accessible on-line and/or directly from onboard sensor descriptions.  The project will also demonstrate mechanisms to associate the data with the metadata through standards-based web services.  With vendor-ready tools implemented throughout a broad-based community, the X-DOMES Network will lay the foundation for the development of and adoption of interoperable access to much needed content-rich sensor metadata.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540849,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540849
1216894,OTHER,OTHER,Conceptualizing an Institute for Sustainable Earth and Environmental Software (ISEES),Conceptualizing an Institute for Sustainable Earth and Environmental Software (ISEES),One organization,OAC,ADVANCES IN BIO INFORMATICS|CYBERINFRASTRUCTURE|ICER|Software Institutes,10/1/2012,9/10/2012,Matthew Jones,CA,University of California-Santa Barbara,34.413963,-119.848947,Standard Grant,Daniel Katz,9/30/2014,"$582,660.00 ",Mark Schildhauer|Carol Meyer|William Michener|Peter Fox,jones@nceas.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,CSE,1165|7231|7699|8004,7433|8060|8211,"The University of California Santa Barbara is awarded a grant for a one-year community-driven process to develop a strategic plan for the creation and operation of an Institute for Sustainable Earth and Environmental Software (ISEES) that would provide development and sustainable support of innovative and interoperable scientific software tools that can transform science at the intersection of earth, environmental, and life sciences. Software is critical to advances in environmental science, but is in crisis due to issues that are prevalent in scientific software, such as code complexity and opacity, lack of scalability, lack of openness and interoperability, and lack of formal versioning and management of software evolution for sustainability. The vision for ISEES is to advance the state of science software by engaging earth and environmental research communities to address the software barriers that most impede grand challenge earth science. This project will work with community efforts such as EarthCube to develop a strategic plan that improves capabilities for scientific discovery within overlapping disciplines within the geological and biological sciences, such as ecology, oceanography, and atmospheric science. ISEES would engage a large swath of the science community in projects that will create and mature software that facilitates bold new science advances. For each science topic identified as a community priority, participants in this planning effort will collaboratively address the entire software lifecycle, from product conceptualization, to requirements analysis, design, development, testing, deployment, long-term support, and decommissioning. A robust workforce development program will be specified to sustain software advances made through ISEES.   The planning process will be diverse, including earth, life, and environmental scientists and experts from software engineering, computer science, informatics, and library sciences. A series of design workshops that use proven, formal planning and assessment methods will meet in three topical clusters to conceptualize and articulate a grand vision and strategy for how ISEES will transform the software lifecycle and galvanize the research community. A Science Cluster collates and articulates grand challenges within earth observational sciences that focus and drive ISEES' software activities and define exemplary collaborative science activities that support detailed requirements analysis. A Software Cluster analyzes requirements for scientific software and proposes approaches for ISEES to address these via improvements across the full science software lifecycle. And, a Sustainability and Adoption Cluster examines sustainability and governance challenges, and proposes models for engaging the research community, governing ISEES, and developing an effective workforce that can sustain the portfolio of science software curated through ISEES. Community experts lead each working group and collectively comprise a Steering Committee that synthesizes recommendations, presents these results and gathers feedback at a Town Hall co-located at a major science conference, and combines this with recommendations from an open call for comments on the Internet to create the final Strategic Plan describing the mission, design, and impact of ISEES.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1216894,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1216894
743429,OTHER,OTHER,Semantic Enhancements for Ecological Data Management,Semantic Enhancements for Ecological Data Management,One organization,DBI,ADVANCES IN BIO INFORMATICS,8/1/2008,8/28/2013,Matthew Jones,CA,University of California-Santa Barbara,34.413963,-119.848947,Standard Grant,Peter H. McCartney,7/31/2014,"$599,999.00 ",Joshua Madin|Mark Schildhauer|Margaret O'Brien|Shawn Bowers,jones@nceas.ucsb.edu,Office of Research,Santa Barbara,CA,931062050,8058934188,BIO,1165,1165|9183|9184|BIOT,"The University of California at Santa Barbara is awarded a grant to address semantic data heterogeneity in ecology by developing and deploying innovative software services that use ontologies and automated reasoning. Ontology-based searches will allow scientists to find data using familiar and meaningful scientific terms, but with better precision and recall than is possible with text-based searches available today. The Morpho and Metacat data-management tools, initially developed by the Knowledge Network for Biocomplexity, will be extended to support semantic annotations, semantic queries, and sensible data summarization.  These tools will provide an open, interoperable semantic software framework. The broader ecological and informatics community will contribute use cases, usability requirements, and feedback on the proposed additions through workshops at the National Center for Ecological Analysis and Synthesis and the Long Term Ecological Research Network. Improving and extending the Morpho and Metacat software systems will benefit the hundreds of ecological field stations in the US and abroad that currently utilize this software for data archiving and discovery. These new semantic software capabilities and improved usability of existing tools will result in more scalable and efficient data synthesis, thereby allowing scientists, students, and educators to better understand and manage complex systems and human-induced global problems. The project will be a collaborative effort with the University of California at Davis.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=743429,https://www.nsf.gov/awardsearch/showAward?AWD_ID=743429
1450488,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,10/4/2017,Carl Maltzahn,CA,University of California-Santa Cruz,36.991474,-122.058297,Standard Grant,Bogdan Mihaila,7/31/2019,"$695,525.00 ",,carlosm@ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,1525|8004|8074,7433|8009,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450488,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450488
1550852,"EAGER, RAPID, INSPIRE",EAGER,EAGER-NEON: Collaborative Research: Formation of a NEON Microbial Metagenomics Data Synthesis Working Group,EAGER-NEON: Collaborative Research: Formation of a NEON Microbial Metagenomics Data Synthesis Working Group,Collaborative,EF,MACROSYSTEM BIOLOGY,10/1/2015,8/3/2015,Folker Meyer,IL,University of Chicago,41.788608,-87.598713,Standard Grant,Elebeoba May,9/30/2018,"$173,451.00 ",,folker@mcs.anl.gov,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,BIO,7959,7350|7916,"The goal of this collaborative project is to enhance the ability to analyze microbial metagenomics datasets of the National Ecological Observatory Network (NEON).  Microbial metagenomics, the characterization of microbial communities by the genes present in the sample, is important for fully understanding microbial processes. This project will enhance the comparative analytical capabilities available to the scientific community for describing properties of microbial communities, which will enable better integration of biological and geoscience data with other current earth-systems observing efforts. These improved analytic tools will facilitate developing better interconnections between environmental factors, biogeochemical processes, and microbial ecosystem structure and function in a more holistic fashion. The project will establish a Synthesis Working Group that will collect community input for guiding cyber-infrastructure and bioinformatics tool development and for answering fundamental questions with the NEON microbial metagenomics data sets.   This collaborative project will form and coordinate a Synthesis Working Group for analysis and integration of NEON metagenomics data, leveraging ongoing development of bioinformatics and cyber-infrastructure tools for metagenomic data in partnership with other concurrent earth-systems observing efforts EarthCube and Critical Zone Observatories. The Synthesis Working Group will enhance scientific advancement by 1) facilitating formation of a diverse team to inform and utilize NEON microbial metagenomic data, 2) exploring strategies for synthesis of NEON metagenomic data using existing and new bioinformatics and cyberinfrastructure tools, and 3) synthesizing NEON metagenomic datasets via integration with multiple existing and developing open data archives. This project will enable comparisons that cannot be adequately synthesized today, which is necessary for evaluating the sustainability and resilience of microbial ecosystems, as well as the function of these microbial communities in supporting key ecosystem services. The project will engender broad scientific dissemination, use, and intercomparison of NEON data products through targeted scientific outreach activities and engagement of the scientific community, including integration of NEON with other earth-systems observing efforts.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550852,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550852
1440327,BB,BB,EarthCube Building Block:   GeoDataspace:   Simplifying Data Management for Geoscience Models,EarthCube Building Block:   GeoDataspace:   Simplifying Data Management for Geoscience Models,One organization,ICER,EarthCube,9/1/2014,8/8/2014,Tanu Malik,IL,University of Chicago,41.788608,-87.598713,Standard Grant,Eva E. Zanzerkia,2/28/2017,"$519,440.00 ",Ian Foster,tanu@cdm.depaul.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,GEO,8074,7433,"A big obstacle to such sharing is the inordinate amount of time and effort that must be spent in creating, communicating, receiving, and interpreting specifications of data, models, and associated knowledge. This inability to quickly and conveniently share is particularly a problem in computational geoscience, wherein scientists spend significant portions of their time managing the many input and output files that are typically associated with a model. When developing, testing, validating, and comparing models, particularly coupled models, the number of such data elements and the complexity associated with their management soon outgrows human memory capacity. The unfortunate consequence is that researchers often narrow the scope of a model analysis, compromise research quality, or conduct analysis within restricted teams. This pilot project will demonstrate a mechanism to overcome this challenge in the scientific community.  The GeoDataspace pilot will develop a new data-centric approach to describing models and associated data resources for computational geoscience. This new approach will both simplify model use and enhance the shareability, reusability, and reproducibility of models, data, and computations?properties widely sought by computational geoscientists. Specifically, the project will develop methods for defining, sharing, and accessing geounits, collections of descriptive metadata that define a m the entire collection of files needed to run a computational model, including details about the model run. In the case of files, processing and manipulation scripts, manifests, spreadsheets, or one-off databases, the encapsulation may consist simplify of the elements location and specification of each element.  The GeoDataspace team includes (a) experts in cyberinfrastructure, data management systems, and SaaS at UChicago; (b) experienced and leading geoscientists in four domains of solid earth, climate, hydrology, and space science, and a leading expert, as well as, geoscientist on model coupling frameworks. Together the team has identified a cross-cutting data management barrier that must be critically addressed in a domain-independent manner so as to extend capabilities to a broader set of geoscientists.All participating geoscientists are initiators, leaders, working-group chairs, and/or representatives of the five modeling communities we represent, including Computational Infrastructure for Geodynamics (CIG), Community Earth System Models (CESM), Consortium of Universities for the Advancement of Hydrological Science, Inc. (CUAHSI), and Community Coordinated Modeling Center (CCMC) at NASA, and finally Earth Systems Bridge (ESB), a community invested in developing model coupling frameworks. In total, the number of geoscientists either directly or indirectly involved in GeoDataspace is in the hundreds, if not thousands.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440327,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440327
1540901,IA,IA,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,Collaborative,ICER,EarthCube,9/1/2015,7/28/2015,Tanu Malik,IL,University of Chicago,41.788608,-87.598713,Standard Grant,Eva E. Zanzerkia,2/28/2017,"$89,990.00 ",,tanu@cdm.depaul.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,GEO,8074,7433,"The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.  EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540901,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540901
1450468,"SI2, CSSI",SI2,SI2-SSI Integration of Synchrotron X-Ray Analysis Software Methods into the Larch Framework,SI2-SSI Integration of Synchrotron X-Ray Analysis Software Methods into the Larch Framework,One organization,OAC,OFFICE OF MULTIDISCIPLINARY AC|GEOPHYSICS|DMR SHORT TERM SUPPORT|Software Institutes|EarthCube,10/1/2015,9/16/2015,Matthew Newville,IL,University of Chicago,41.788608,-87.598713,Standard Grant,Stefan Robila,9/30/2019,"$540,969.00 ",,newville@cars.uchicago.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,CSE,1253|1574|1712|8004|8074,7433|7574|8004|8009|9216,"The solutions to many of the outstanding problems in geology, environmental science, material science, and biology require understanding the chemical state and detailed atomic structure of the molecules and solids that make up our world.  Such problems range from understanding the molecular forms of arsenic in rice, determining the chemical composition of the earths interior, and improving the performance and reducing the environmental impact of batteries that are in our laptops, cellphones, and cars.  The nation's synchrotron facilities provide powerful X-ray facilities that allow researchers to study these questions by investigating the chemical makeup and crystal structure of complex, real-world materials such as plant seeds, contaminated soils, human and animal tissue, minerals and meteorites, and working batteries and catalysts.  Synchrotron measurement techniques have developed very rapidly over the past few decades, and are being used by many more researchers.  The ability to handle and interpret the large and complex datasets now being routinely generated at these facilities is often a significant challenge, even for experts.  The work here will develop the Larch X-ray analysis framework to provide open-source software that is easy to use and specific enough to correctly interpret several categories of synchrotron X-ray data.  The approach will provide tools that are flexible enough to enable researchers to explore and interpret new combinations of data easily enough to make new connections and discoveries in a wide variety of scientific areas.   This project will integrate visualization and analysis software for multiple synchrotron X-ray techniques into the open source and extensible Larch X-ray Analysis framework.  The immediate focus of the work is to support visualization and quantitative analysis of the rich and complex data from X-ray microprobes, including X-ray fluorescence imaging, fluorescence and absorption spectroscopies, and X-ray diffraction.  The Larch framework already provides a suite of analysis procedures for X-ray absorption spectroscopy and fluorescence imaging, and has been designed to be readily extensible by adding plug-ins in Python, widely used in scientific computing and being embraced in the synchrotron user communities.  Existing state-of-the-art analysis procedures for X-ray fluorescence, X-ray absorption, and X-ray diffraction have been identified to be integrated into the Larch framework, adapting and translating the software as needed to be compatible with the open-source Python framework.  With the combination of state-of-the-art analysis methods for multiple data types, Larch will provide a single well-supported and -documented analysis package with robust, easy to use analytic methods for a range of synchrotron X-ray data. By being easily extensible, the Larch package can also accommodate methods for other synchrotron X-ray techniques.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450468,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450468
951576,OTHER,OTHER,DMUU: Center for Robust Decision Making on Climate and Energy Policy,DMUU: Center for Robust Decision Making on Climate and Energy Policy,One organization,SES,CROSS-DIRECTORATE  ACTIV PROGR|CCRI-DEC MAKING UNDER UNCERTAI|EarthCube,9/15/2010,8/25/2014,Ian Foster,IL,University of Chicago,41.788608,-87.598713,Cooperative Agreement,Cheryl L. Eavey,8/31/2016,"$6,054,994.00 ",Kenneth Judd|Lars Hansen|Todd Munson|Elisabeth Moyer,foster@uchicago.edu,6054 South Drexel Avenue,Chicago,IL,606372612,7737028669,SBE,1397|7264|8074,7264|7322|7433|7979|9278|EGCH,"As additional governments are acknowledging the existence of climate change, many are systematically evaluating policy actions to reduce greenhouse gas emissions.  Simultaneously, various groups like utilities, private-sector firms, and state and local governments are estimating the potential costs related to mitigation, adaption, or damage and the potential benefits of climate change and alternative policies. All of these decisions collectively will have economic impacts measuring into the trillions of dollars.  Decisions of such magnitude should be based on the best possible analysis tools.  Such tools inevitably must be based on computational models because of the complexity of the system of systems that need to be analyzed to project possible future states, identify potential unexpected consequences, and understand sensitivity to uncertainty.  This interdisciplinary collaborative group will develop and disseminate tools to help individuals and organizations make more informed decisions relating both to short-term economic dislocations induced by climate policies and to long-term consequences of climate change.  The group's primary product will be CIM-EARTH, a powerful and flexible framework of model components that can be used to help answer questions across a wide range of policy analyses.  At the core of the CIM-EARTH framework will be an open-source, dynamic, general equilibrium model.  The architecture of this framework will leverage high-performance computing and numerical methods that enable the evaluation of far more detailed models than existing code.  The group will focus on enhanced representation of key energy producing and consuming sectors and on dynamic processes, such as capital investment and technology development.  Another key component of the group's work will be the characterization of multiple types of uncertainty inherent in any complex system. CIM-EARTH will be developed in the newly created Center for Robust Decision Making on Climate and Energy Policy (DMCEP), which will be staffed by experts in economics, energy technologies, energy systems, climate modeling, and computational science who represent multiple institutions and countries.  Robust decision-making research is critical if policymakers are to fully understand the factors to be weighed in policy design and choice.  While there are existing models that provide some guidance, they have shortcomings that limit their practical utility.  This group will produce next-generation computational models for analyzing complex system of systems, with specific emphasis placed on advances in model components that represent economic systems.  CIM-EARTH is expected to create a new standard for open-source modeling that encourages the participation of a community users and contributors.  In addition, by incorporating recent advances in computer architecture, numerical methods, and economic modeling, CIM-EARTH will enhance methodologies that will be of tremendous value to other computational models with similar complexity.  This collaborative group project is supported by the NSF Directorate for Social, Behavioral, and Economic Sciences through its Decision Making Under Uncertainty (DMUU) competition.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=951576,https://www.nsf.gov/awardsearch/showAward?AWD_ID=951576
1740719,IA,IA,Collaborative Proposal: EarthCube Integration: Accelerating Scientific workflowS using EarthCube Technologies (ASSET),Collaborative Proposal: EarthCube Integration: Accelerating Scientific workflowS using EarthCube Technologies (ASSET),Collaborative,ICER,EarthCube,9/1/2017,8/17/2017,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$165,000.00 ",,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"A major need in the geosciences is to reduce the amount of time geoscientists spend on ""data wrangling"" tasks (finding, accessing, subsetting, gridding, processing, reformatting, visualizing) so that they can spend more time on complex scientific analysis. This project will develop a means for scientists to document and interact with all of the data management and analysis tools that they need to create a scientific result, and it will add tools to find common patterns in their work to help find tools that could reduce the time needed to produce the result. This work may also help to make moethods and analyses more transparent by providing the means to track the steps in creating a scientific result.  This project builds on relationships among cyberinfrastructure experts and geoscientists examine current scientific workflows and the integration of EarthCube tools.  The work will include a workflow sketching interface to specify the steps, dependencies, current tools, current duration, and other important aspects of a scientist's workflow.  As part of the proposed pilot project, the team will examine two geoscience use cases (hurricane risk and water resources) in detail and assign cyberinfrastructure experts to integrate EarthCube tools into these science workflows, to demonstrate the increases in productivity that are realized.  In addition, the team will conduct a workshop/clinic at a major geoscience conference to collect additional use cases from the community, where geoscientists will describe their workflows and receive personalized advice on the use of EarthCube tools.  If successful, the researchers may expand on this pilot project to conduct many more workshops at other venues and to map many more scientific workflows to corresponding EarthCube technologies.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740719,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740719
1740575,IA,IA,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences,Collaborative,ICER,EarthCube,10/1/2017,9/14/2017,Michael Willis,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Gregory J.  Anderson,9/30/2020,"$212,395.00 ",,mike.willis@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"Satellite imagery is rapidly transforming the way we see the planet, including our ability to study the most remote parts of the Arctic and Antarctic. Satellite imagery can help us map networks of rivers, study changes in the flow and thickness of glaciers, identify rock and soil types, and even find animals like penguins and seals. Because the availability of imagery in polar areas has increased rapidly over the last decade, we are now faced with a challenge: To move from small pilot-studies to pan-Arctic or pan-Antarctic analyses of geological and biological processes requires new infrastructures that link scientists, satellite imagery, and fast computing. The project, called ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, aims to build the cyberinfrastructure required to make the most of satellite imagery for geosciences, starting with researchers working in polar areas, and then branching out to the larger community. The Broader Impacts of this proposal include the training of undergraduate and graduate students, as well as young investigators and female scientists. Moreover, the scientific findings enabled by this proposed cyberinfrastructure will have immediate benefits for our ability to predict the future dynamics of the polar regions, and critical to the management of Arctic and Antarctic resources.   Polar geosciences stands at the precipice of a revolution, one enabled by the confluence of cutting edge analytical tools, petabytes of high-resolution imagery, and an ever growing array of high performance computing resources. With these tools at hand, we can look beyond incremental improvements in our understanding of the polar regions. Near-real time datasets of geological and biological importance at the continental scale are within our reach if we create those critical cyberinfrastructure components that allow the geosciences community to exploit existing assets and establish a common workflow for reproducible imagery-enabled science. The research objective of this proposal is to understand the biological, geological, and hydrological functioning of the polar regions at spatial scales heretofore beyond the reach of individual PIs, and to develop tools for imagery-enabled science that can be applied globally. The resulting cyberinfrastructure, which we call ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, is an extensible system for coupling open-source image analysis tools with the use of high performance and distributed computing (HPDC) for imagery-enabled geoscience research. We propose a project to (1) develop open source image classification tools tailored to high-resolution satellite imagery of the Arctic and Antarctic to be used on HPDC resources, (2) create easy-to-use interfaces to facilitate the development and testing of algorithms for application specific geoscience requirements, (3) apply these tools through use cases that span the biological, hydrological, and geoscience needs of the polar community, (4) transfer these tools to the larger non-polar community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740575,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740575
1252574,WORKSHOP,WORKSHOP,Furthering EarthCube:  A Roadmap Coordination Workshop,Furthering EarthCube:  A Roadmap Coordination Workshop,One organization,OAC,EarthCube,9/1/2012,8/24/2012,Siri Jodha Khalsa,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Amy Walton,8/31/2013,"$49,999.00 ",,khalsa@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,8074,7433,"EarthCube is a joint venture between the Directorate of Geosciences and the Office of Cyberinfrastructure at the National Science Foundation.  It is a community-driven effort to design and implement an effective data and knowledge management system for the geosciences that will integrates disparate data sets and web services and serves all members of the geoscience community.  This 2-day workshop at the University of Colorado brings together investigators and other interested parties who have been tasked with developing cyberinfrastructure components that are potential candidates for inclusion in the final architecture and design of EarthCube. Participants at the workshop will be tasked to synthesize community input from the June EarthCube meeting and sequence the series of proposed milestones and events included in community-created road maps of key cyberinfrastructure capabilities that were generated over the course of the last six months.  The overarching goals of the workshop will be to propose a workable cyberinfrastructure framework for EarthCube and work out a provisional timeline for its implementation.  Participants will consist of key individuals already working on potential EarthCube architecture components, as well as those from newly formed special interest groups such as those interesting in having EarthCube link to and incorporate biological datasets; those seeking to serve the needs of geoscientists who work with unique sample-based data, as opposed to large homogeneous datasets coming from sensor arrays; and those trying to develop software to allow direct ingestion of data from laboratory instruments.  Broader impacts of the workshop lie in the area of building infrastructure for science and engineering.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252574,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252574
1239841,OTHER,OTHER,Toward Cyber-Infrastructure 2025:  Addressing Critical Milestones for EarthCube,Toward Cyber-Infrastructure 2025:  Addressing Critical Milestones for EarthCube,One organization,EAR,EarthCube,4/1/2012,3/28/2012,Siri Jodha Khalsa,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Barbara L. Ransom,3/31/2013,"$218,524.00 ",Ruth Duerr|Mark Parsons|Jay Pearlman|Francoise Pearlman,khalsa@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433|7916,"This EAGER award promotes a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of experts from academia and the private section, the funded work is focused on developing the key EarthCube cyberinfrastructure capability of brokering, which among other things enables sharing of very diverse data across disciplinary and technological boundaries.  It also allows data repositories to easily expose and make discoverable their data to potential users via multiple standards and services. The approach employed utilizes an inclusive, community-driven, collaborative approach to the problem and emphasizes the testing and evaluation of different brokering technologies using community-agreed upon standard datasets and applications, such as water sustainability, geohazards, biodiversity loss, and climate change. The work substantially and positively impacts our ability to carry out quantitative data-enabled research in the geo- and environmental sciences.  The project includes technical assessments of existing technologies, the development of a brokering roadmap that will mature ideas and technology over the next few years, and will engage a broad and diverse community of geoscientists, cyberinfrastructure developers, and computer scientists. Broader impacts of the work include maturation of a key capability that is required for the realization of EarthCube, a new NSF initiative in geoscience knowledge and data management, the engagement of a broad spectrum of individuals from the geoscience, cyberinfrastructure, and computer science communities, the inclusion of members of under-represented groups in the leadership team, and international collaboration with partners in France, Germany, and Canada.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239841,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239841
1310644,WORKSHOP,WORKSHOP,"Collaborative Research: An EarthCube Domain Workshop integrating the inland-waters biogeochemistry and fluvial sedimentology communities, April 22-24.","Collaborative Research: An EarthCube Domain Workshop integrating the inland-waters biogeochemistry and fluvial sedimentology communities, April 22-24.",Collaborative,EAR,EarthCube,4/1/2013,3/29/2013,Albert Kettner,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Hailiang Dong,3/31/2015,"$88,622.00 ",,kettner@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"Continental surface waters represent distinct environments that are hot spots of biogeochemical storage and transformation, as well as conduits for large-scale material transport to the oceans and atmosphere. These systems are integral components of global geochemical cycles, are intertwined with human health and economic activity, and are highly sensitive to anthropogenic impacts. Without data from a wide variety of disciplines, such as organic and physical chemistry, ecosystem science, sedimentology, landscape evolution, water-rock interaction, and element and material cycles (weathering products, trace elements, carbon burial, nutrient fluxes, mineral particles, etc.), it is not possible to realistically model these important surface water systems and understand the complex interactions between their various physical and biological components. Data necessary to populate such models comes from field-based, experimental, laboratory, and theoretical work, involving short research projects, long-term research observatories, and water quality monitoring systems. The goal of this workshop is to surface requirements in the fields of river and fresh water biogeochemical studies for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~60 geoscientists from across the US who come from relevant disciplines, including cyber/computer science experts, this coallition of parties will have a job to collectively define future science goals in this important arena. It will also be used to identify the most critical, widespread needs shared by those working on surface water and fresh water biogeochemical problems and to guide the development of NSF EarthCube cyberinfrastructure for this community. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers. Discussions will encompass all aspects of experimental, in-situ, geospatial, and modeling data as well as address issues related to quantitative analytical and scaling approaches that enable the integration of observations. Workshop participants will also address topics such as process rates along flow paths ranging from short scales such as sediment-water interfaces, to continental-scale basins. Progress addressing these needs in a coordinated fashion across sub-disciplines has the potential to lead to transformative advancements in this dispersed but critical intersection of research communities. Broader impacts of the work center primarily on building infrastructure for science.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1310644,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1310644
1740696,IA,IA,Collaborative Research: EarthCube Integration--Brokered Alignment of Long-Tail Observations (BALTO),Collaborative Research: EarthCube Integration--Brokered Alignment of Long-Tail Observations (BALTO),Collaborative,AGS,EarthCube,9/15/2017,9/15/2017,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Subhashree (Shree) Mishra,8/31/2020,"$501,223.00 ",Anne Sheehan,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"This project, Brokered Alignment for Long-Tail Observations (BALTO), is supported under the EarthCube program.  The development team seeks to build a tool and infrastructure to allow the community to easily submit long-tail observational data that cannot easily fit into existing data repositories.  A data brokering technique will be developed to accomplish the goals of the study.  Graduate students, including from underrepresented minority groups, will receive training opportunities via this project.   To facilitate access to long-tail observations this work seeks to develop a core capability for the future EarthCube (EC) architecture in the Architecture and Implementation Plan - Brokered Alignment for Long-Tail Observations (BALTO). BALTO entails an open-source interface to discover, access and transform geoscience data sources through a brokering solution implemented by user-developed accessors. BALTO integrates core attributes of successful prior EC Building Blocks, BCube and ODSIP, to create a next generation EC capability. Leveraging its large installed base and its open-source flexibility, BALTO will extend Hyrax OPeNDAP's data server for ODSIP with capabilities for distributed brokering. Results from this project will demonstrate improved access and its impacts on scientific discovery via three NSF funded interdisciplinary use-cases that span geodesy, seismology, hydrology, oceanography, and geodynamics.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740696,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740696
1343811,BB,BB,EarthCube Building Blocks:  Earth System Bridge:  Spanning Scientific Communities with Interoperable Modeling Frameworks,EarthCube Building Blocks:  Earth System Bridge:  Spanning Scientific Communities with Interoperable Modeling Frameworks,One organization,ICER,EarthCube,9/15/2013,3/9/2015,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva Zanzerkia,8/31/2017,"$1,699,997.00 ",Richard Hooper|Gary Egbert|Cecelia Deluca|David Gochis|Jennifer Arrigo|Anna Kelbert,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"This EarthCube project possesses deep, disciplinary and interdisciplinary expertise in the development, implementation and support of geoscientific modeling architectures and in the promotion and utilization of community standards in model development and in data management. Combined, this team will integrate existing model architectures, model coupling standards and data standards into a set of open source Earth System Bridge building blocks that will transform the process of Earth system model coupling and bridge the present technological gap. In collaboration with the community of framework developers, the team will create a Framework Definition Language (FDL) which characterizes Earth system coupling technologies in terms of their metadata usage, architecture, protocols for interaction, and implementation, and use this as a basis for understanding potential framework inter-connections. They will use the FDL to develop a set of ?bridges? that connect leading software frameworks from the federal modeling enterprise and from the academic geoscientific modeling enterprise, for the sake of creating seamless environmental and impacts prediction tools, and develop new services to improve the integration of inter-agency, four-dimensional databases with more heterogeneous academic databases for use in earth system models and by modeling groups. Demonstration of the  new modeling and data integration architecture will be in two case studies: the first, prediction of the local impacts of the Hurricane Sandy landfall; and the second, the integration of deep Earth process with surface dynamics. These problems span disciplines, agencies, and research and operational communities, and require addressing scientific, technical, and cultural issues.  The overarching goal is to bridge this present technological gap in Earth System modeling, thereby illustrating how a common cyberinfrastructure can be used in different Earth science disciplines and communities, and how improved cyberinfrastructure can directly address pressing cross-disciplinary science questions.  The tools developed by the Earth System Bridge have the potential to serve many different disciplinary communities. A more interconnected and capable modeling community will significantly increase the speed at which knowledge is currently transferred between the research and operational communities, Connecting the academic and operational infrastructure will reduce inefficiencies and gaps that exists in the system today. The technology developed will place increased capabilities in the hands of a broader set of geoscientists, lowering the barriers to more scientists participating in multi-disciplinary research that is needed to address today?s policy issues and increase our national resilience to a wide variety of natural hazards.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343811,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343811
1450409,"SI2, CSSI",SI2,"Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics","Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics",Collaborative,OAC,GEOMORPHOLOGY & LAND USE DYNAM|Software Institutes|EarthCube,8/1/2015,7/14/2015,Gregory Tucker,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Stefan Robila,7/31/2020,"$789,777.00 ",Daniel Hobley,gtucker@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,7458|8004|8074,7433|8009,"Earth scientists discover and predict the behavior of the natural world in part through the use of computer models. Models are used to study a wide range of phenomena, such as soil erosion, flooding, plant growth, landslide occurrence, and many other processes. Models can be used to develop scientific understanding by comparing model calculations with the real world. They can also be used to make predictions about how nature will behave under certain conditions. In the areas of geosciences that deal with the earth's surface, one bottleneck in the development and use of models is the effort required to build, test, and debug the necessary software. This project contributes to scientific research and discovery by creating open source software tools that scientists can use to more efficiently create, modify, or combine computer models that represent portions of earth's surface and the processes occurring thereon. The project combines software development with user training and web-based resources, so that the products will be openly accessible, well documented, and widely disseminated within the relevant scientific communities. The project also contributes to K-12, undergraduate, and graduate-level education in computational modeling and earth-surface processes.  This project catalyzes research in earth-surface dynamics by developing a software framework that enables rapid creation, refinement, and reuse of two-dimensional (2D) numerical models. The phrase earth-surface dynamics refers to a remarkably diverse group of science and engineering fields that deal with our planet's surface and near-surface environment: its processes, its management, and its responses to natural and human-made perturbations. Scientists who want to use an earth-surface model often build their own unique model from the ground up, re-coding the basic building blocks of their model rather than taking advantage of codes that have already been written. Whereas the end result may be novel software programs, many person-hours are lost rewriting existing code, and the resulting software is often idiosyncratic, poorly documented, and unable to interact with other software programs in the same scientific community and beyond, leading to lost opportunities for exploring an even wider array of scientific questions than those that can be addressed using a single model. The Landlab model framework seeks to eliminate these redundancies and lost opportunities, and simultaneously lower the bar for entry into numerical modeling, by creating a user- and developer-friendly software library that provides scientists with the fundamental building blocks needed for modeling earth-surface dynamics. The framework takes advantage of the fact that nearly all surface-dynamics models share a set of common software elements, despite the wide range of processes and scales that they encompass. Providing these elements in the context of a popular scientific programming environment, with strong user support and community engagement, contributes to accelerating progress in the diverse sciences of the earth's surface.  The Landlab modeling framework is designed so that grid creation, data storage, and sharing of data among process components is done for the user. The framework is generic enough so that the coupling of two process components, whether they are squarely within a geoscience subdiscipline, or they cross subdisciplines, is the same. This architecture makes it easy to explore a wide range of questions in the geosciences without the need for much coding. Further, the model code is primarily written in Python, a language that is relatively easy for casual programmers to learn. Because of these attributes, the Landlab modeling framework has the potential to add computational modeling to the toolbox of a wide array of geoscientists, and to clear a path for trans-disciplinary earth-surface modeling that explores societally relevant topics, such as land-cover changes in response to climate change, as well as modeling of topics that currently require the coupling of sophisticated but harder-to-use models, such as sediment source-to-sink dynamics. The project will generate several proof-of-concept studies that are interesting in their own right, and demonstrate the capabilities of the modeling framework. Community engagement is fostered by presenting clinics and demonstrations at professional venues aimed at hydrologists, sedimentologists, critical zone scientists, and the broader earth and environmental sciences community. The team also supports visits by individual scientists for on-site training beyond these clinics. Input/output tools allow compatibility with data from relevant NSF-supported research. The project supports four graduate students and three postdoctoral researchers, and also includes modeling workshops for fifth to seventh grade girls in a community that has a greater than 50% minority population.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450409,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450409
1242909,"EAGER, RAPID, INSPIRE",EAGER,EAGER Collaborative Research: Bringing Together Computational and Linguistic Methods to Extract 'Dark' Geosciences Data for the EarthCube Framework,EAGER Collaborative Research: Bringing Together Computational and Linguistic Methods to Extract 'Dark' Geosciences Data for the EarthCube Framework,Collaborative,EAR,EarthCube,7/15/2012,7/3/2012,Christopher Jenkins,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Barbara L. Ransom,6/30/2013,"$69,452.00 ",,chris.jenkins@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433|0000|7916|OTHR,"A large percentage of vaulable geoscience data is based on the analysis of discrete samples and is collected manually (e.g., paleontological collections, structural/tectonic data, petrographic/mineralogic data, economic data, geochemical measurements, rock mechanics, etc.) Often, these data are reported only in tables in the published literature or in .pdf or spreadsheets on individual investigator websites. Commonly these data are not registerd on or entered into standardized, publicly accessible databases. As a result, for this data to be discovered and used/reused, researchers or other interested parties must manually comb through the text, figures, and appendices of journal articles or websites of individual investigators, sometimes having to sift through raw experimental data. This process is extremely time intensive and slows down the time needed to make scientific discoveries or allow verification of research results. As a result the vast amount of surface earth geoscience data is currently inaccessible. This inaccessible data is termed ""Dark Data"". This EAGER combines the expertise of top-notch computer scientists and geoscientists whose goal is to create a search algorithm to bring this dark data to light in a way that will enable the next generation of integrative geoscience research. The approach will involved development of an innovative search engine ""crawler"" that will comb the geoscience literature and bring dark data to light from the text and figures in this corpus. The cyberinfrastructure tool being developed will be able to interpret the semantics of English text and the concepts of geoscience. The tool will be piloted by examining entries on the Macrostrat database, a structured spatial database of lithologic and geochronologic information, and then employing a geoscience ontology by means of the Hazy framework for information extraction. Questions to be addressed will be to find out to what extent dark data is presently accessible and if it can be extracted and placed into an accessible format and repository where it can be discovered by web services or other search engines. Broader impacts of the work include training of graduate students and increasing the infrastructure for science through the development of a new and much needed data search tool.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1242909,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1242909
1239718,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications,Collaborative,EAR,EarthCube,4/1/2012,3/27/2012,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Barbara L. Ransom,3/31/2013,"$60,000.00 ",,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433|7916,"This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results. Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239718,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239718
1239697,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,Collaborative,EAR,EarthCube,4/1/2012,3/28/2012,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Barbara L. Ransom,3/31/2013,"$18,000.00 ",,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433|7916,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239697,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239697
1440333,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models,EarthCube Building Blocks:  Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models,Collaborative,ICER,EarthCube,9/1/2014,8/13/2014,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva Zanzerkia,8/31/2017,"$262,299.00 ",,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"The project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. Many challenges hinder the seamless integration of models with data. These challenges compel scientists to perform the integration process manually. The primary challenges are a consequence of the knowledge latency between model and data resources and others are derived from inadequate adoption and exploitation of information technologies. Knowledge latency challenges increase exponentially when a user aims to integrate long-tail data (data collected by individual researchers or small research groups) and long-tail models (models developed by individuals or small modeling communities).The goal of this research is to develop a framework rooted in semantic techniques and approaches to support ?long-tail? models and data integration. The vision is to develop a decentralized knowledge-based platform that can be easily adopted across geoscience communities comprising of individual and small group researchers.    This project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. The project will develop a knowledge framework to close the loop from models? queries back to data sources by first investigating the required concepts architecture for integrating two leading examples of long-tail resources in geoscience: Community Surface Dynamic Modeling System (CSDMS) and Sustainable Environment Actionable Data (SEAD). The project will also develop a context-based data model that provides an explicit interpretation of a metadata attribute. The researchers will capture the metadata concepts and semantic from various geo-informatics systems and provide tools for ensuring conceptual integration between the resources. Next, the project will develop a knowledge discovery tool that allows automated coupling of a model and data coming from different contributors. Finally, the project will provide a prototype physical implementation of the knowledge framework in CSDMS modeling framework to demonstrate how it can advance the seamless discovery, selection, and integration between models and data, and how to achieve dynamic reusability of resources across multiple Earth Science long-tail resources.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440333,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440333
1639675,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web,EarthCube Building Blocks:  Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web,Collaborative,ICER,POLAR CYBERINFRASTRUCTURE|EarthCube,9/1/2016,9/16/2016,Siri Jodha Khalsa,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Gregory J.  Anderson,8/31/2019,"$294,999.00 ",,khalsa@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,5407|8074,1079|7433,"This project develops an NSF EarthCube Building Block focused on Polar Data Science. The system will build upon work in Information Retrieval and Data Science and upon existing investment from NSF Polar, EarthCube, and from DARPA and NASA in this area. The system will collect, analyze, and make interactive the wealth of textual and scientific Polar data collected to date across the Deep web of scientific information -- scientific journals, multimedia information, scientific data, web pages, etc. The system builds upon fundamental research in text analysis, search, and visualization. Its primary goal is to unlock unstructured scientific data from 90+ data formats and to scale to 10s-100s of millions of records using the NSF XSEDE supercomputing resources. The system will perform information retrieval and machine learning on data crawled from the Polar Deep and Scientific web. Crawling will be informed by science questions crowdsourced through the EarthCube and Polar communities. The project is a collaboration with NSIDC, Ronin Institute, and the broader community including the newly funded Arctic Data Center led by NCEAS, to build our proposed system.  The result of periodic and regular crawling will be a Crawl Data Repository (CDR) of raw textual data e.g., web pages containing richly curated dataset abstract descriptions, news stories tied to datasets, ASCII note files and dataset descriptions, and other textual data available on or pointed to by Polar repositories as well as scientific data (HDF, Grib, NetCDF, Matlab, etc.). The CDR will be made available for historical and future analysis by the broader EarthCube and Polar communities. In addition, an extraction pipeline will generate an Extraction Data Repository (EDR) of machine learning features not previously present (geospatial, temporal, people, places, scientific publications and topics, etc.) that will be the basis of interactive, visual analytics over the Polar data resources. Information collected will assist in answering scientific questions such as these derived from the President?s National Strategy for the Arctic Region. To date, the team has also crowd sourced 30+ questions from the Polar community represented on CRYOLIST https://goo.gl/4dDyIS and will continue to solicit this feedback and use the information collected to aid science as prioritized by the community. They will also engage the community to assist in validating our system. This is not a predictive tool per-se ? though it can help to enable such predictions. Its focus is on building an operational and core capability for textual scientific data analysis, both retrospective, and prospective.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639675,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639675
1440332,BB,BB,EarthCube Building Blocks: Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences,EarthCube Building Blocks: Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences,Collaborative,ICER,EarthCube,9/1/2014,8/14/2014,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva Zanzerkia,8/31/2018,"$330,000.00 ",,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"Geosciences software embodies crucial scientific knowledge, and as such it should be explicitly captured, curated, managed, and disseminated. The goal of this project is to create a system for software stewardship in geosciences that will empower scientists to manage their software as valuable scientific assets. Scientific software stewardship requires a combination of cyberinfrastructure, social infrastructure, and professional development infrastructure. The  framework will result in an open transparent and broader access to scientific software to other scientists, software professionals, students, and decision makers. It will significantly improve the adoption of open data and open software initiatives, improve reproducibility, and advance scientific scholarship.  The proposed research will advance knowledge and understanding of scientific software as a valuable community asset that is worth sharing, curating, cataloging, validating, reusing, and maintaining.  1) Facilitating software publication through TurboSoft, a personal assistant (analogous to TurboTax) that guides a user through best practices. Users will choose the degree of investment they are willing to make in componentizing, describing, licensing, and maintaining their software. The system will encourage open source publication, the formation of communities around the software, and set up mechanisms for software citation and credit.  2) Enabling broad software dissemination through GeoSoft, a ""software commons"" for geosciences that will support software contributions (prepared through TurboSoft or otherwise), software discovery through multi-faceted search, and foster social interactions through dynamic formation of communities of interest. GeoSoft will interoperate with existing software repositories and modeling frameworks in geosciences.  3) Providing just-in-time training materials through GeoCamp, an annotated collection of educational units ranging from basic education to professional training on all aspects of software stewardship. GeoCamp will be seamlessly integrated with TurboSoft and GeoSoft, and present a wide range of options for learning in the context of a user?s context of interaction with the framework or independently.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440332,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440332
1639547,BB,BB,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Scott Peckham,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva Zanzerkia,8/31/2018,"$99,837.00 ",,Scott.Peckham@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility.   GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639547,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639547
1343802,BB,BB,EarthCube Building Blocks: A Broker Framework for Next Generation Geoscience (BCube),EarthCube Building Blocks: A Broker Framework for Next Generation Geoscience (BCube),One organization,ICER,EarthCube,9/15/2013,7/24/2015,Siri Jodha Khalsa,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva E. Zanzerkia,8/31/2016,"$1,529,918.00 ",Stefano Nativi|Ruth Duerr|Francoise Pearlman|Jay Pearlman,khalsa@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"The grand challenges of geoscience require working across traditional disciplinary boundaries. Scientists are being called upon to find, access, and use diverse and voluminous data types that are described with semantics. The BCube project has put together a strong team of geoscientists, cyberinfrastructure experts and social scientists to address these interoperability challenges using a maturing Brokering Framework for discovery, access, semantics, web crawling, workflows and enhanced user services. The first three have been explored for geoscience and are mature enough to provide near term engagement of geoscientists in a test bed environment. Crawling, workflow and services will be developed during the project. The geoscientists, (including early career scientists) from the domains of hydrology, oceans, polar,  weather, will compile community needs and assess broker capabilities in an increasing complex series of user scenarios. To address the cultural barriers, BCube includes social science and education in the project team. BCube engages five major repositories (DataOne, OOI, USGS, NCAR/RAL, NSIDC) to test and demonstrate interconnections with the Broker Framework, with extension to international repositories in the second year.  The broker discovery and access modules have two important and unique characteristics: a design that builds interoperability without putting a burden upon either users or providers and an interfaced web crawling capability to find new data, models and services. New capabilities also come as the Broker translates cyberinfrastructure research in areas such as semantics and workflow into a user-oriented capability for cross-discipline geoscience research. An agile development process will support rapid adaptations to changing user needs. Since not all needs can be anticipated, the Broker will also have APIs for scientists to write modules for their own applications. BCube will look at the cultural issues in cross-discipline research to improve acceptance and use of the broker. Both the technical and cultural broker attributes will be exercised through user scenarios that start with individual geoscience research issues and move to more complex cross-discipline research studies. This will develop reference cases for metrics, monitoring and validating progress as the Broker Framework evolves and matures.  To address the grand challenges facing society, geoscientists need a sustainable and evolvable cyberinfrastructure supporting cross-discipline research with powerful interoperability. Success in addressing the project?s six diverse domains will demonstrate this and engender advancements in the broader geosciences. The Broker module for web 2.0 will support use of crowd sourcing and citizen science. BCube?s education analyses and early career scientists will consider the best way to reach a new generation. Expansion to international data access will be demonstrated through collaboration with the BCube?s international repository partners and a special interest group of the international Research Data Alliance.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343802,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343802
1153164,OTHER,OTHER,Integrated Data Management System for Critical Zone Observatories,Integrated Data Management System for Critical Zone Observatories,One organization,EAR,GLOBAL CHANGE|GEOBIOLOGY & LOW TEMP GEOCHEM|CZO: CRITICAL ZONE OBSER SOLIC,4/15/2012,11/6/2012,Anthony Aufdenkampe,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Enriqueta Barrera,4/30/2013,"$1,503,590.00 ",Anthony Aufdenkampe,aaufdenkampe@limno.com,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,1577|7295|7693,,"The objective of the project is to develop a comprehensive, integrated data management system for the NSF-funded Critical Zone Observatory (CZO) program, called CZOData. The overall goal for CZOData is to support, empower, and broaden the impact of CZO science and maximize the return on investment of the CZO program by transforming capabilities to easily share, integrate, analyze and preserve the wide range of multi-disciplinary data generated within and across CZOs.   The CZOData design is based on the experience of the collaborative project team in building the current CZOData prototype and on other foundational cyber-infrastructure systems.  The principal investigators at the University of Boulder and the Stroud Water Research Center are Earth surface scientists who provided high-level oversight of the CZOData prototype and provide a direct link to the scientific community collecting and using CZO data.  Team members at San Diego Supercomputing Center (SDSC) and Utah State University (USU) are primary developers of the Hydrological Information System (HIS) developed by the Consortium for the Advancement of Hydrological Sciences, Inc. (CUAHSI).  Team members at Columbia University developed and lead the Integrated Earth Data Applications (IEDA), Geoinformatics for Geochemistry (GfG), EarthChem and the System for Earth Sample Registration (SESAR) projects.  Team members at the Applied Physics Laboratory at the University of Washington developed and maintain the Northwest Association for Ocean Observing Systems (NANOOS) Visualization System (NVS).    This project combines state-of-the-art computer science and cyber-infrastructure technologies and international metadata standards with a strong effort to engage the science community in the process of developing and testing the CZOData system.  This collaborative, community-based approach to developing scientific cyber-infrastructure has been actively encouraged by the NSF-supported EarthCube initiative and thus complements those goals (http://www.nsf.gov/geo/earthcube/). The approach with CZOData is based on integrating site-based data with system capabilities' such as consistent data publication, cataloguing, discovery and access infrastructure. These new capabilities will strongly leverage other CI efforts described above. The resulting system will support new CZO research that was not possible before while easing the data management burden on CZO scientists.  The vision is that the proposed CZOData will serve as a model for the greater Earth surface science community. The CZOData project is a collaborative, community-guided cyber-infrastructure project for integrating multi-disciplinary data and providing interoperability with other systems. Thus, CZOData will inform the development of other large geoinformatics initiatives, such a the Open Geospatial Consortium (OGC), Long-Term Environmental Research (LTER) observatories, DataOne, OpenTopography, the Implementing Organization of the International Geosample Number (IGSN e.v.), and the Integrated Ocean Observing System (IOOS). Also, by incorporating system research and development with graduate education, we will move towards cultivating a new generation of researchers skilled in both different facets of environmental research and in advanced information management and computing.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1153164,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1153164
1735890,OTHER,OTHER,"Building a continent: Integration of surface geology, rock physics, and seismic observations to investigate the tectonic history of the contiguous United States","Building a continent: Integration of surface geology, rock physics, and seismic observations to investigate the tectonic history of the contiguous United States",One organization,EAR,EARTHSCOPE|EAR,9/1/2017,7/14/2017,Vera Schulte-Pelkum,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Margaret Benoit,8/31/2020,"$284,196.00 ",Kevin Mahan,vera.schulte-pelkum@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,007F|6898,026Z,"The North American continent formed over billions of years via the collision of continental fragments and the rifting apart of larger continents. Geologists can read some of this history by looking at rocks exposed at the Earth's surface that were deformed in the past. The aim of this project is to extend this ability below the Earth's surface. While buried rocks cannot be seen and mapped directly, they are constantly traversed by seismic waves from earthquakes around the world. These waves are imprinted with information on the rocks they travel through before reaching the Earth's surface. We combine mapped rock deformation at the surface with seismic information from the subsurface in order to find out how to extract the imprinted information from the seismic data. The information can then be used to map how the Earth's crust was deformed.  The project advances knowledge of Earth science by allowing us to read the record of past geological processes beneath the surface. Because current geological processes also deform rocks, the method can also be used to map the roots of earthquake-generating faults, which is useful for estimates of seismic hazard. The rock characteristics investigated in this process are also relevant to mapping geological resources. Additionally, accurate knowledge of the imprint of rock fabrics on the seismic signal enables us to avoid biases in other uses of the seismic data, such as for location and characterization of natural and human-made seismic sources.  A stated goal of the EarthScope program is to derive constraints on the deformation history of the continent. This project aims to bridge the scales from microstructural rock fabrics measured in the laboratory, to deformation structures mapped on outcrop exposures, and to rock fabrics causing seismic anisotropy at km-scale seismic wavelengths. Project components are 1) integration of seismic anisotropy observations from multiple techniques and seismic networks, 2) contribution of existing digital structural data sets containing foliations, lineations, and mapped major ductile and brittle faults to existing EarthCube-funded and U. S. Geological Survey-held databases as well as calculation of bulk elasticity tensors from ~1:100,000 scale maps to hand samples and 3) synthesis and joint interpretation of seismic observations and structural data extracted from EarthCube-funded databases using straightforward correlations as well as an explicit scaling from elastic tensors representative of rock types to geological foliation maps to seismic wavelength-scale anisotropy.  The ability to relate crustal seismic anisotropy to the strain history of the crust requires 1) a representative catalog of elastic properties of crustal rocks and how they average at scales of seismic wavelengths and 2) a compilation of major structural parameters such as orientations of dominant rock fabrics (foliation and lineation) in metamorphic and igneous rocks and their internal coherence in unique domains, as well as orientations of more discrete features such as fault zones, in order to enable quantitative comparisons to anisotropy measured seismically. The proposed work will centralize existing compilations and make them widely available online.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1735890,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1735890
1817295,OTHER,OTHER,PREEVENTS Track 1: A transdisciplinary approach to next-gen natural hazard modeling: Improving accuracy and usability of earth surface process models for pre-event risk assessment,PREEVENTS Track 1: A transdisciplinary approach to next-gen natural hazard modeling: Improving accuracy and usability of earth surface process models for pre-event risk assessment,One organization,ICER,PREEVENTS - Prediction of and|EarthCube,2/15/2018,2/8/2018,Albert Kettner,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Justin Lawrence,1/31/2019,"$49,839.00 ",Gregory Tucker|Irina Overeem,kettner@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,034Y|8074,,"Natural hazards impact thousands of people every year; floods, droughts, extreme storms, landslides, wildfires, and permafrost erosion all change the Earth's surface and inflict tremendous damage to human infrastructure. Most often, humans respond to disasters ""after the fact"" and a paradigm shift is needed to a strategy of resilience that would provide a way to reduce vulnerability to disasters and their impacts before they occur. This workshop will focus disparate efforts in natural hazard modeling in the earth surface processes towards a common goal of modeling for risk assessment. A resulting white paper will provide policy makers, funding agencies, and the science community with a clear agenda and timeline on needs for improving modeling fundamentals, and needs for modeling cyberinfrastructure and model-data couplings and high performance computing capability as needed to inform natural hazard occurrence.   This workshop aims at bringing in a diverse group of scientists and students across career stages to work towards the problem of natural hazard modeling. The workshop will build on the momentum of several existing modeling and data communities; Community Surface Dynamics Modeling System, EarthCube, and Natural Hazards Engineering Research Infrastructure DesignSafe. The organizers will bring together leading representatives of these initiatives for keynotes, clinics and extensive break-out discussions. Explicitly, they will aim for inclusivity by striving for gender balance in keynotes and clinic leaders, and make a dedicated effort to bring students from underrepresented groups through a Student Modeler Award competition and several diversity stipends.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1817295,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1817295
1541010,IA,IA,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,Collaborative,ICER,EarthCube,9/1/2015,7/28/2015,Tomoko Matsuo,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva Zanzerkia,8/31/2018,"$100,000.00 ",,tomoko.matsuo@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.  EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541010,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541010
1443085,"DIBBS, BIGDATA, III",DIBBS,"C1F21 DIBBS: Porting Practical Natural Language Processing (NLP) and Machine Learning (ML) Semantics from Biomedicine to the Earth, Ice and Life Sciences","C1F21 DIBBS: Porting Practical Natural Language Processing (NLP) and Machine Learning (ML) Semantics from Biomedicine to the Earth, Ice and Life Sciences",One organization,OAC,ADVANCES IN BIO INFORMATICS|POLAR CYBERINFRASTRUCTURE|DATANET|EarthCube,11/1/2014,7/17/2015,Christopher Jenkins,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Amy Walton,10/31/2018,"$1,497,785.00 ",James Martin|Martha Palmer|Ruth Duerr,chris.jenkins@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,1165|5407|7726|8074,7433|8048,"Semantics is the study of word-based information. The sciences are filled with word-based descriptive data: field observations, materials and habitat identifications, parameter names and units, events and processes. Semantics are also important in medicine, where the human body and illnesses have to be described.  To enhance interoperability among these word-based (semantic) systems, and to more readily explore the rapidly growing quantities of semantic data, there has been a movement towards organizing word-based data in ways that allow machine-assisted, automated analysis.  Biomedicine has made great progress in organizing and using semantic information because of substantial funding investments. This project builds upon extensive investments in the biomedical field, providing an opportunity to rapidly develop the organization of semantic concepts for other domain sciences.   A toolkit developed by the Center for Computational Language and Education Research (CLEAR TK) will be used to build semantic resources (taxonomies, ontologies, and semantic networks) for three science domains (geology, cryology, and biology).  CLEAR TK is a state-of-the-art natural language processing (NLP) and machine learning (ML) system that also has essential tools for machine-assisted annotation, validation, document tagging, and event extraction.  The CLEAR TK system has been used operationally for biomedical semantic applications, including in high-profile hospitals.  In this project, developments are focused upon the science fields of geology, ice and snow, and biology.  In these fields, accurate extraction of semantic information from the word-based data is required so users can quickly find the data they really need. This project provides a valuable opportunity to expand and evaluate semantic capabilities in conjunction with several scientific domain experts.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443085,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443085
1541620,RCN,RCN,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,Collaborative,ICER,EarthCube,9/1/2015,5/25/2016,Allen Pope,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Eva Zanzerkia,8/31/2018,"$44,472.00 ",,allen.pope@nsidc.org,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,GEO,8074,7433,"One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs.  Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.  The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed.  This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training.  The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541620,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541620
1835566,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative,OAC,EarthCube,1/1/2019,8/27/2018,Kristy Tiampo,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Amy Walton,12/31/2022,"$432,326.00 ",,kristy.tiampo@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,8074,062Z|077Z|7925,"This project develops a real-time processing system capable of handling a large mix of sensor observations. The focus of this system is automation of the detection of natural hazard events using machine learning, as the events are occurring.  A four-organization collaboration (UNAVCO, University of Colorado, University of Oregon, and Rutgers University) develops a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  This work will support rapid analysis and understanding of data associated with hazardous events (earthquakes, volcanic eruptions, tsunamis).    This project uses a collaboration between computer scientists and geoscientists to develop a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  It focuses on the aggregation and integration of a large number of data streams into a coherent system that supports analysis of the data streams in real-time. The framework will offer machine-learning-based tools designed to detect signals of events, such as earthquakes and tsunamis, that might only be detectable when looking at a broad selection of observational inputs.  The architecture sets up a fast data pipeline by combining a group of open source components that make big data applications viable and easier to develop. Data sources for the project draw primarily upon the 1500+ sensors from the EarthScope networks currently managed by UNAVCO and the Incorporated Research Institutions for Seismology (IRIS), as well as the Ocean Observatories Initiative (OOI) cabled array data managed by Rutgers University.  Machine learning (ML) algorithms will be researched and applied to the tsunami and earthquake use cases.  Initially, the project plans to employ an advanced convolutional neural network method in a multi-data environment.  The method has only been applied to seismic waveforms, so the project will explore extending the method to a multi-data environment.  The approach is expected to be extensible beyond detection and characterization of earthquakes to include the onset of other geophysical signals such as slow-slip events or magmatic intrusion, expanding the potential for new scientific discoveries.  The framework is applied to use cases in the Cascadia subduction zone and Yellowstone: these locations combine the expertise of the science team with locations where EarthScope and OOI have the greatest concentration of instruments.  The architecture will be transportable and scalable, running in a Docker environment on laptops, local clusters and the cloud.  Integral to the project will be development, documentation and training using collaborative online resources such as GitLab and Jupyter Notebooks, and utilizing NSF XSEDE resources to make larger datasets and computational resources more widely available.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Program within the NSF Directorate for Geosciences, the Big Data Science and Engineering Program within the Directorate for Computer and Information Science and Engineering, and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the Office of Advanced Cyberinfrastructure.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835566,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835566
1835864,"SI2, CSSI",SI2,Collaborative Research: Framework: Software: NSCI : Computational and data innovation implementing a national community hydrologic modeling framework for scientific discovery,Collaborative Research: Framework: Software: NSCI : Computational and data innovation implementing a national community hydrologic modeling framework for scientific discovery,Collaborative,OAC,EarthCube,10/1/2018,9/12/2018,Paul Constantine,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Stefan Robila,9/30/2022,"$350,000.00 ",,paul.constantine@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,8074,026Z|062Z|077Z|7925|8004,"This award supports the design and implementation of a software framework to simulate the movement of water at various scales. Understanding the movement and availability of water locally and across the country is of paramount importance to economic productivity and human health of our nation. Hydrologic scientists, are actively tackling these challenges using increasingly complex computational methods. However, modeling advances have not been easily translated to the broader community of scientists and professionals due to technical barriers to entry. This software platform draws from computer models and employs supercomputers capable of analyzing big data to provide unprecedented simulations of water movement over the continental US. Combining hydrologists and computer scientists the team behind the project envision a broad community of users who will have multiple ways to interact with the software framework. For the hydrologic scientist who is interested in generating their own scenarios the framework will facilitate direct interaction with the hydrologic models and the ability to generate simulations on the fly. Conversely, the framework will also provide a set of static output and a range of tools for a broader set of users who would like to evaluate hydrologic projections locally or extract model data for use in other analyses.  Continental scale simulation of water flow through rivers, streams and groundwater is an identified grand challenge in hydrology. Decades of model development, combined with advances in solver technology and software engineering have enabled large-scale, high-resolution simulations of the hydrologic cycle over the US, yet substantial technical and communication challenges remain. With support from this award, an interdisciplinary team of computer scientists and hydrologists is developing a framework to leverage advances in computer science transforming simulation and data-driven discovery in the Hydrologic Sciences and beyond. This project is advancing the science behind these national scale hydrologic models, accelerating their capabilities and building novel interfaces for user interaction. The framework brings computational and domain science (hydrology) communities together to move more quickly from tools (models, big data, high-performance computing) to discoveries. It facilitates decadal, national scale simulations, which are an unprecedented resource for both the hydrologic community and the much broader community of people working in water dependent systems (e.g., biological system, energy and food production). These simulations will enable the community to address scientific questions about water availability and dynamics from the watershed to the national scale. Additionally, this framework is designed to facilitate multiple modes of interaction and engage a broad spectrum of users outside the hydrologic community. We will provide easy-to-access pre-processed datasets that can be visualized and plotted using built-in tools that will require no computer science or hydrology background. Recognizing that most hydrology training does not generally include High Performance Computing and data analytics or software engineering, this framework will provide a gateway for computationally enhanced hydrologic discovery. Additionally, for educators we will develop packaged videos and educational modules on different hydrologic systems geared towards K-12 classrooms.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Activities Program of the Division of Earth Sciences within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835864,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835864
1835256,"SI2, CSSI",SI2,Element: Software: Data-Driven Auto-Adaptive Classification of Cryospheric Signatures as Informants for Ice-Dynamic Models,Element: Software: Data-Driven Auto-Adaptive Classification of Cryospheric Signatures as Informants for Ice-Dynamic Models,One organization,OAC,POLAR CYBERINFRASTRUCTURE|CESER-Cyberinfrastructure for|EarthCube,1/1/2019,9/6/2018,Ute Herzfeld,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Stefan Robila,12/31/2021,"$593,624.00 ",,uch5678@gmail.com,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,5407|7684|8074,026Z|062Z|072Z|077Z|1079|7923|8004,"The objective of this project is to develop and automatize a connection between Earth observation data and numerical models of Earth system processes. Both collection of Earth observation data from satellites and modeling of physical processes have seen unprecedented advances in recent years. However, data-derived information is not used to inform modeling in a systematic and automated fashion. This creates a bottleneck that is growing with the data revolution. The award supports the development of a software cyberinfrastructure aimed at reducing this bottleneck by automating classification and parameterization. The proposed cyberinfrastructure will be implemented in a general and transportable way, but its functionality will be demonstrated by addressing a concrete open problem in glaciology: the acceleration during a glacier surge, which is characterized by an increase to 100-200 times the flow normal velocity. Glacial accelerations are important, because they constitute the largest uncertainty in sea-level-rise assessment. The team, from University of Colorado will combine their expertise of field work and data collection with their background in software development to generate a high-quality application that will be made available under an open source license to the broader scientific community. The project will engage graduate and undergraduate students in the software development, thus contributing to the development of future generations of scientists and cyberinfrastructure professionals.  The results will also be used to inform activities in K-12 schools and other outreach efforts.  The proposed data-driven auto-adaptive classification system is expected to provide a tool to the Earth Sciences community that allows it to employ the unprecedented detail in satellite image and SAR data (WordView, Sentinel-1 and Sentinel-2) necessary to extract information on surface properties and processes that were previously indiscernible. In that the classification will automatically adapt to changing conditions in time and space, it will provide a consistent parameterization of spatial processes that can be used to drive numerical simulations of Earth system processes. Thus, a direct connection will be established between data analysis and modeling. In a pilot study, the data-modeling connection will be demonstrated through classification of crevasse patterns, which result from deformation, and optimization of the basal sliding parameter in a three-dimensional model of a glacier surge. Hence the pilot study will advance understanding of ice dynamics. A second application is a sea-ice classification system, aimed to aid in mapping and understanding the changing Arctic sea-ice cover. The planned automated connection between data-driven automated classification and optimization of model parameters is expected to lay the foundation for a transformation of the data-modeling world in Earth sciences, atmospheric and polar sciences. The project will also advance machine learning and spatial statistics through realization of a science-driven approach to computer science and cyberinfrastructure.  This award by the NSF Office of Advanced Cyberinfrastructure (OAC) is jointly supported by the Cross-Cutting Program within the NSF Directorate for Geosciences, The OAC Cyberinfrastructure for Emerging Science and Engineering Research (CESER) program and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the OAC.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835256,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835256
1532236,OTHER,OTHER,MRI Collaborative Consortium: Acquisition of a Shared Supercomputer by the Rocky Mountain Advanced Computing Consortium,MRI Collaborative Consortium: Acquisition of a Shared Supercomputer by the Rocky Mountain Advanced Computing Consortium,One organization,OAC,MAJOR RESEARCH INSTRUMENTATION|CYBERINFRASTRUCTURE|EarthCube,9/1/2015,8/19/2015,Thomas Hauser,CO,University of Colorado at Boulder,40.007581,-105.265942,Standard Grant,Stefan Robila,8/31/2018,"$2,030,000.00 ",Anna Hasenfratz|James Syvitski|Kenneth Jansen|Peter Ruprecht,thomas.hauser@colorado.edu,"3100 Marine Street, Room 481",Boulder,CO,803031058,3034926221,CSE,1189|7231|8074,1189|7433,"A cluster supercomputer is deployed by the University of Colorado Boulder (CU-Boulder) and Colorado State University (CSU) for the Rocky Mountain Advanced Computing Consortium (RMACC). This high-performance computing (HPC) system supports multiple research groups across the Rocky Mountain region in fields including astrophysics, bioinformatics, chemistry, computational fluid dynamics, earth system science, life science, material science, physics, and social sciences with advanced computing capabilities. It also provides a platform to investigate and address the impact of many-core processors on the applications that support research in these fields.   The system integrates nodes populated with Intel's conventional multicore Xeon processors and Many-Integrated-Core (MIC) 'Knights Landing' Phi processors interconnected by Intel's new Omni-Path networking technology. Users of the new HPC system have access to existing data management services including data storage, data sharing, metadata consulting, and data publishing, leveraging the NSF-funded high-performance networking infrastructure and long term storage system, as well as additional cyberinfrastructure, at CU-Boulder and CSU. The many-core feature of this HPC system enhances graduate and undergraduate students' education and training as they develop, deploy, test, and run optimized applications for next generation many-core architectures. Training for researchers and students is provided through workshops appropriate for introducing diverse audiences to the efficient and effective use of HPC systems, the challenges of vectorization for single core performance, shared memory parallelism, and issues of data management. Additionally, advanced workshops on large-scale distributed computing, high-throughput computing, and data-intensive computing are offered during the year and at the annual RMACC student-centric HPC Symposium. The Symposium brings together hundreds of students, researchers, and professionals from universities, national laboratories and industry to exchange ideas and best practices in all areas of cyberinfrastructure. For-credit HPC classes will be delivered for online participation, educating the next generation of computational scientists in state-of-the-art computational techniques.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1532236,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1532236
1659006,RCN,RCN,RCN: RATES: Building a Spatial and Temporal Framework for Understanding Surface Earth Processes,RCN: RATES: Building a Spatial and Temporal Framework for Understanding Surface Earth Processes,One organization,EAR,SEDIMENTARY GEO & PALEOBIOLOGY|EarthCube,2/15/2017,2/13/2017,Lisa Park Boush,CT,University of Connecticut,41.807741,-72.253981,Standard Grant,Margaret Fraiser,1/31/2020,"$500,000.00 ",,lisa.park_boush@uconn.edu,438 Whitney Road Ext.,Storrs,CT,62691133,8604863622,GEO,7459|8074,7255|7459,"This project will establish a Research Coordination Network (RCN) ""EarthRates: Linking Scales Across the Sedimentary Crust"" that will provide the framework and opportunity to engage communities and forge new collaborations in order to foster transdisciplinary research on Earth's sedimentary crust. This RCN will bring together investigators from NSF-sponsored entities such as the Paleobiology Database, Neotoma, Macrostrat, EarthTime, EarthChem, Earth-Life Transitions, the Continental Scientific Drilling Coordination Office, and Flyover Country to strategize, leverage and build community collaborative efforts to address major grand challenges in Earth system science.  These include: 1) how have the oceans, the Earth's sedimentary crust, carbon sinks and soils, and life itself evolved together, and what does this tell us about the future trajectory of the integrated Earth-life system? and 2) what are the ranges of ecosystem response, modes of vulnerability, and resilience to changes in Earth-system states? By bringing investigators and leaders from these groups together and building stronger partnerships, we will move towards the goal of developing a fully integrated four-dimensional digital Earth to fully understand Earth's dynamic system evolution. EarthRates RCN will build on recent activities of the communities and facilitate efforts to bring these groups together to 1) hold workshops, 2) develop working groups, 3) provide training opportunities to build a future workforce, 4) launch data mobilization campaigns, 5) strengthen community ties, 6) discover new partners and opportunities, 7) promote with social media and strong web presence (such as maintaining the development of a 'Broader Impacts Clearinghouse', extending outreach opportunities with Flyover Country mobile app, and increasing efforts to recruit, retain, and advance members of underrepresented groups), and 8) integrate efforts to build research capacity in the sedimentary crust by exposing and visualizing data from EarthRate's community data repositories. This project will create a stronger scientific infrastructure, leveraging funds already spent by NSF to further build the community that is critical to understanding Earth's past and future states.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1659006,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1659006
1344384,WORKSHOP,WORKSHOP,Collaborative Project:  EarthCube Domain End-User Workshop:  Developing a Community Vision of Cyberinfrastructure Needs for Coral Reef Systems Science,Collaborative Project:  EarthCube Domain End-User Workshop:  Developing a Community Vision of Cyberinfrastructure Needs for Coral Reef Systems Science,Collaborative,OCE,EarthCube,8/1/2013,8/9/2013,Ruth Gates,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Michael Sieracki,7/31/2015,"$34,329.00 ",,rgates@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,GEO,8074,7433,"The Geosciences EarthCube program recognizes the importance of aligning cyber-infrastructure activities with the needs of end user research communities. To that end we propose to convene 50-70 members of the coral reef community in two workshops, one held at the University of Hawaii (HIMB) and the other at the University of California Santa Barbara National Center for Ecological Analysis and Synthesis (NCEAS). The specific objectives of the workshop are to:   1. Define current and future (5-15 years) scientific challenges in the field  2. Summarize data and cyber-infrastructure constraints that prevent these challenges being realized  3. Collate current community data and modeling resources and their locations  4. Identify and recommend data infrastructure that could facilitate rapidly addressing the scientific challenges in the field  The coral reef research community is multidisciplinary and the data on reefs is diverse and complex, crossing biological scales from genes to ecosystems, temporal scales from nanoseconds to millennia, and spatial scales from nanometers to kilometers. The challenge is to integrate across these data sources to identify patterns and relationships that rapidly improve our understanding of coral reefs systems. This effort has been hindered to date by the lack of tools to accomplish this and ineffective means of sharing data or collaborating. This project will support workshops that engage the coral reef community to 1) develop a common vision of the grand science challenges in the field 2) highlight how data cyber-infrastructure needs will integrate the complex datasets and potentially facilitate rapid progress in key areas of coral reefs ecosystem science and 3) emphasize the value of collaboration and data sharing as a first step to changing and improving the way coral reef scientists support each other and advance the field.  As ecosystem engineers, corals provide the nutritional, economic, and structural basis of an ecosystem worth billions of dollars annually. This workshop proposal convenes the coral reef community and will address how cyber-infrastructure can inform coral reef systems science. The latter will ultimately accelerate understanding of reef ecosystems, broaden the scope of the questions that can be asked and build capacity to predict how these societally relevant and fragile ecosystems will face the challenges of climate change and human development. The workshops will also be attended by at least 4 postdocs and represents a significant professional development opportunity for these individuals. Results will be disseminated on the EarthCube website, the NCEAS website, and the HIMB website making them broadly accessible to the science, education and the public. The product from the proposed endeavor will be a report to NSF EarthCube summarizing the discussion for each of these objectives that will serve to define and align the needs across the Geosciences and help prioritize EarthCube activities. There is also an opportunity to use the results to develop a manuscript that articulates how cyber-infrastructure can address the science challenges facing the coral reef community and facilitate a systems level science agenda. Such a product could have high value in both the science funding and policy realm.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1344384,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1344384
1440005,OTHER,OTHER,Collaborative Proposal: ATREX - integrated open source data analysis software for mineral and environmental sciences,Collaborative Proposal: ATREX - integrated open source data analysis software for mineral and environmental sciences,Collaborative,EAR,CI REUSE|EarthCube,9/1/2014,9/3/2014,Przemyslaw Dera,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$468,187.00 ",Bin Chen,pdera@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,GEO,6892|8074,7433|9150,"Synchrotron radiation user facilities are critical resources which enable state-of-the-art research and training in mineralogy, mineral physics and environmental science. Access to these facilities is very competitive and time allocated for experiments is constrained. The most popular and fundamental type of experiment is X-ray diffraction, which produces information on crystal structure, symmetry, chemical bonding, composition and density of minerals and other crystalline solids. Modern synchrotron-based diffraction experiments are typically conducted with the use of area detectors, in which case the data is recorded as digital diffraction images. Technology used in synchrotron experiments evolves rapidly increasing the speed of the data collection and producing massive volumes of experimental data, posing new serious challenges for data analysis. The experiments are often decision-driven, and require at least partial real time data interpretation to guide the experimenter. Software offering such real time analysis capabilities is currently not available. This proposal is a collaborative effort to provide this scientific community with easily accessible tools and training opportunities for using these codes.  This project focuses on a combination of novel tools for diffraction-based synchrotron research in Earth and environmental sciences including: (IM1) New capabilities for structure determination of unknown phases and identification of known phases in natural and synthetic samples; (IM2) Opening new possibilities for real time analysis in studies of solid state dynamic processes; (IM3) Robust Bayesian analysis of outliers, uncertainties and missing data; and (IM4) Creation of new free advanced tools for utilizing the available mineralogical database in synchrotron research. Utilizing a combination of existing, well-tested and widely used software components developed in the Interactive Data Language , Python, the project creates a new integrated multiplatform, open-source Python software package ATREX (Advanced Tools for Research in Extreme Xtallography), with unique capabilities to process diffraction image data from samples in all forms from glasses and melts, bulk powders, though coarse multi grains, to single crystals, which will support new data types produced by novel ultrafast X-ray imaging detectors, offer extensive automated serial processing capabilities for massive data sets and will allow real time data analysis for time-constrained decision-driven synchrotron experiments. ATREX will include database access capabilities utilizing the free American Mineralogist Crystal Structure Database.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440005,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440005
1639614,BB,BB,"Collaborative Proposal: EarthCube Building Blocks: Planet Microbe: Enabling the discovery and integration of oceanographic omics, environmental and physiochemical data layers","Collaborative Proposal: EarthCube Building Blocks: Planet Microbe: Enabling the discovery and integration of oceanographic omics, environmental and physiochemical data layers",Collaborative,OCE,EarthCube,9/1/2017,8/21/2017,Edward DeLong,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Michael Sieracki,8/31/2020,"$126,948.00 ",Elisha Wood-Charlson,edelong@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,GEO,8074,1650|7433|9150,"Oceanographic research expeditions provide a rich source of data comprised of next generation sequencing, microscopy, and physical/chemical environmental data to explore ocean biodiversity. As collection bottles and chemical sensors emerge from the depths of the ocean, research teams work through the night processing their key component of this oceanographic treasure. Despite careful efforts to share data among collaborators, the moment each sample emerges is often the last time these rich data sources are together. In this project the investigators will develop Planet Microbe, a federated resource of database connections to enable data discovery and open data sharing for historical and on-going oceanography and geobiology sequencing efforts.  Planet Microbe will provide the community with a platform that partners -omics data and analyses with any relevant contextual and environmental data available.  To promote the use of Planet Microbe, adoption by the community, and a collaborative research paradigm, the project will leverage and continue development of ECOGEO Research Coordination Network workshop on bioinformatics protocols using open-source web-based Protocols.io software. These protocols will contain multimedia training videos, screenshots, and example datasets in a stepwise format that are cross-linked to specific commands, tools, or outside websites. The investigators will refine and extend these use-cases and protocols in early career workshops. They will adapt the protocols for broader use in high school curriculum in ocean sciences and cyberinfrastructure through an existing collaboration with a technical librarian and science teacher in a high school comprised of 70% minority students. The project will offer undergraduate students research opportunities to design and develop Apps in the existing CyVerse Cyberinfrastructure to address bioinformatic needs from the oceanographic community and participate in protocol development and teaching.    Initially, the project will develop a prototype using data from Hawaii Ocean Time-series (HOT) and Bermuda Atlantic Time Series (BATS), both of which produce extensive ""-omics"" data sets (available via iMicrobe) and oceanographic data (available via the Biological and Chemical Oceanography Data Management Office (BCO-DMO)) and are of great value to the broader science community. Connections between data sets will be derived through automated distance-based algorithms, and refined through collaborative hand-curation. Once the prototype has been validated, additional -omics data sets from two NSF-funded Science and Technology Centers, the Centers for Dark Energy Biosphere Investigations (CDEBI)  and Microbial Oceanography Research and Education (CMORE), will be retrieved from disparate ?omic repositories (e.g., JGI/IMG, MG-RAST, NCBI, EBI) and queryable through a recommendation algorithm fueled and refined by scientific queries from past users. Finally, data in Planet Microbe will leverage existing EarthCube funded projects to expand beyond BCO-DMO such as: GeoLink, which also includes Rolling Deck to Repository (R2R) and International Ocean Discovery Program (IODP), SeaView to share collected resources and create a ""microbe"" user scenario, and GeoDeepDive to discover dark data in historical publications. Through this concerted effort, Planet Microbe will become the go-to site for oceanographic data discovery and integration.By reconnecting -omics data with environmental data from oceanographic cruises, Planet Microbe will enable biological inquiry into environmental changes that affect the distribution and abundance of microbes in the sea. Further, algorithms for connecting disparate data types and a robust search interface developed by Planet Microbe will enable the creation of virtual datasets through user-defined oceanographic measurements, features, and thresholds that can be used to synthesize and analyze global datasets in novel ways by the community. In particular, virtual datasets can be used broadly by the geosciences community to refine global ecological models, to inform citizen science efforts, and derive critical information on temporal and spatial data associated with ocean microbes that re important in disaster analysis. Taken together, Planet Microbe will provide a much needed resource for the geosciences community to unite -omics and environmental data toward unforeseen discovery in the Earth system.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639614,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639614
1440066,RCN,RCN,EarthCube RCN:   An EarthCube Oceanography and Geobiology Environmental Omics Research Coordination Network (ECOGEO RCN),EarthCube RCN:   An EarthCube Oceanography and Geobiology Environmental Omics Research Coordination Network (ECOGEO RCN),One organization,ICER,EarthCube,9/1/2014,8/17/2015,Edward DeLong,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Eva E. Zanzerkia,2/28/2017,"$359,995.00 ",,edelong@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,GEO,8074,0000|7433|9150|OTHR,"The network elements of the ECOGEO RCN reach across diverse communities of ocean scientists, geoscientists, computer scientists and bioinformaticians, and will forge new cross-disciplinary connections. Although the scientific goals of the proposed ECOGEO community network are diverse, common challenges and requirements for big data analyses be identified across this broad community. This project will provide new solutions and ideas that reach beyond disciplinary boundaries, since the challenges of rich omic datasets share commonalities across areas as diverse as soil science, oceanography, geobiology and studies of the human microbiome. Best practices and use case scenarios developed in this project will integrate across challenges of diverse science domains, and provide well documented approaches for omic data management and analyses, that will serve as models and test cases for new cyberinfrascructure systems. These efforts will impact not only ocean scientists and geobiologists, but also other allied areas that use the same approaches, that range from environmental assessment to human health.   Inexpensive sequencing has facilitated the generation of billions of environmental DNA sequences, and allied techniques to survey gene expression (metatranscriptomics) and protein expression (metaproteomics) are advancing as well. The large and complex environmental omic datasets now present major challenges to the ocean and geoscience communities. These omic datasets are diverse, complex, and exponentially expanding, and require the construction, curation, and query of diverse federated databases, as well as development of shared interoperable, big-data capable analytical tools. To help address these current big data challenges, this project establishes a virtual network called EarthCube Oceanography and Geobiology Environmental Omics Research Coordination Network (ECOGEO RCN), that will foster collaborations, communication, innovation, and education in omic data management and analyses in the oceanography and geobiology communities. The effort will identify and communicate needed data standards, sharing and access mechanisms and analytical strategies across the broader community of ocean and geosciences. Major outcomes of ECOGEO RCN will be: 1)Establishment of a virtual network that coordinates collaboration and communication in omics, data sharing and analyses; 2)Training of a cyber-savvy generation of ocean and geo science graduate students, postdocs and young professionals in the rapidly evolving environmental omics and bioinformatics field. 3)Identification and elaboration of environmental omic data standards, ontologies, sharing mechanisms, and analytical strategies; 4)Development of use case scenarios that will inspire creation of a new palette of user friendly inter-operative community data management, analytical and visualization tools for oceanography and geobiology omic science and beyond.  The establishment of the ECOGEO RCN will provide a collection of online resources to enable the access, management and discovery of oceanographic and geobiology omic data, metadata, analysis tools, methodologies, and other user-driven needs. An EarthCube hosted ECOGEO-Wiki will serve as open forum for network participants to share content and link to data repositories, models, and tools. The ECOGEO centralized network and web-based portal will promote better communication within and between ECOGEO microbial oceanography and geobiology scientists and the broader scientific community. This will enable greater access and organization of large and heterogeneous datasets, greater efficiencies in scientific discovery, and broader collaborations based on both survey and experimental data. The overall result will be to facilitate access and use of existing and rapidly accumulating new omic datasets for a wide range of ocean science and geoscience users, to observe measure and model community composition, biological and biogeochemical activities and ecosystem structure and function from ocean surface waters to the deep subsurface. ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440066,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440066
1440342,RCN,RCN,Earthcube RCN:  Coral REef Science & CYberinfrastructure NeTwork (CReSCyNT),Earthcube RCN:  Coral REef Science & CYberinfrastructure NeTwork (CReSCyNT),One organization,ICER,EarthCube,9/1/2014,8/21/2014,Ruth Gates,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Eva Zanzerkia,8/31/2018,"$299,845.00 ",Gwen Jacobs|Judith Lemus|Erik Franklin|Megan Donahue,rgates@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,GEO,8074,7433|9150,"This project develops the the Coral Reef Science & Cyberinfrastructure Network (CReSCyNT). As ecosystem engineers, corals provide the nutritional, economic, and structural basis of ecosystems worth billions of dollars annually. The broader impacts that CReSCyNT encompasses include: (i) integration and exchange with professional societies, (ii) development of visualization products in collaboration with educators and resource managers, (iii) connecting place-based collaborative networks, (iv) building a collaborative community in the coral reef discipline, (v) training of two graduate students, (vi) broad transfer of disciplinary expertise among geoscientists, cybertechnologists, medical scientists and graphic artists (media), (vii) raises visibility and awareness of coral reef data in the geosciences, and (viii) user-friendly web-based visualization tools accessible to the public that serve to showcase the value of coral reef science and the innovative approaches employed by the EarthCube program  The coral reef community has exceptionally diverse data structures and analysis requirements necessary to forward integrative science. It is therefore an exemplar for cyberinfrastructure-enabled advances to other geosciences communities. CReSCyNT will grow a multi-tiered and multidisciplinary network of coral reef researchers, cyberinfrastructure specialists, and computer scientists with the end goal of facilitating integrative and interactive research. This network will match the data sources, data structures, and analysis needs of the coral reef community with the current advances in data management, visualization, and image processing from ocean sciences, biomedical research, and graphic arts to advance coral reef research and meet the increasing challenges of coastal conservation. The network will assemble and communicate to coordinate, plan, and prioritize cyberinfrastructure needs within the coral reef community and with the broader geosciences. Our objectives are to collectively identify needs, best practices, bottlenecks, and avenues or approaches to advance the design and ultimately the development of data management, visualization, and image processing capacity for the coral reef domain that is directly and immediately translatable to the broader geoscience community.The five-member CReSCyNT Facilitating Committee will shepherd the growth of a network around 12 coral reef disciplinary nodes and 5 technology nodes, where each node represents a sub field or discipline of coral reef science (or computer science) that is led by a recognized member of that sub discipline in advocating sharing, transparency, open dialog, creativity, and the integration of data across the geosciences. Facilitated by CReSCyNT meetings, social media, and a presence at professional society conferences, the leader of each node will invite broad participation in CReSCyNT activities from members of their sub discipline. These nodes will be allowed to expand, coalesce, or divide to meet the needs and interests of the subdisciplinary communities, while maintaining a connection to CReSCyNT through the node coordinators and ongoing network activities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440342,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440342
1639775,BB,BB,EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub,EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub,Collaborative,ICER,EarthCube,9/1/2016,2/1/2019,Judith Lemus,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Eva Zanzerkia,8/31/2019,"$63,750.00 ",,jlemus@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,GEO,8074,7433|9150,"Making data discovery more efficient, comprehensive and user-friendly is a critical challenge articulated by geoscientists as well as researchers in other fields. While information discovery portals and search engines have been developed for many data repositories, and systems that simultaneously search multiple resources have been created, cross-disciplinary data discovery remains a serious issue. It becomes especially acute with rapid increases in the volume and diversity of observations, reflecting different components of the Earth System and collected by multiple research groups, government organizations and commercial companies. The main goal of the EarthCube Data Discovery Hub project is to greatly reduce the time and effort necessary to locate and evaluate geoscience information resources across disciplines, and increase the value of investment in data generation by promoting data reuse and reducing duplication of effort. Project outcomes will benefit a wide group of scientists by providing them a user-friendly and powerful gateway to information resources across multiple data facilities and community contributions, and mechanisms for improving the system to answer their research queries in a consistent manner. The project will also benefit geoscience research in several ecosystems that are being used as examples to test the data tools being developed, including rivers, coral reefs and other marine ecosystems, and the critical zone where rock, soil, water, air and living organisms interact. The EarthCube Data Discovery Hub will be developed as a comprehensive data discovery and content enhancement system, which will leverage improved and community-curated metadata descriptions and integrate previously unregistered information sources. The project will further extend, improve and operationalize the inventory catalog developed in an earlier CINERGI (Community Inventory of EarthCube Resources for Geoscience Interoperability) project, which currently includes over 2 million metadata documents from multiple sources. The key technological innovations include: pioneering the development of an automated cross-domain metadata augmentation and curation pipeline enabled by a large integrated geoscience ontology; mechanisms for ?deep registration? of geoscience data from different sources based on a novel data type registry; an online use case management system; and a methodology for processing several types of complex geoscience queries that cannot be answered by existing systems. In addition, the project will support scientific progress in several representative cross-disciplinary research scenarios, using the contexts of river geochemistry, coral reef and other marine ecosystem analysis, and critical zone science. The project will implement innovative community engagement mechanisms, including community annotation of automatically curated metadata, iterative improvement of geoscience ontology based on community feedback, and joint development of cross-disciplinary use cases semantically aligned with data descriptions. ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639775,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639775
1541036,IA,IA,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Collaborative,ICER,EarthCube,9/1/2015,8/19/2015,Przemyslaw Dera,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$34,922.00 ",,pdera@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,GEO,8074,7433|9150,"A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services.   Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541036,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541036
1550597,"SI2, CSSI",SI2,SI2-SSI: Lidar Radar Open Software Environment (LROSE),SI2-SSI: Lidar Radar Open Software Environment (LROSE),One organization,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2016,9/6/2016,Michael Bell,HI,University of Hawaii,21.296939,-157.817112,Standard Grant,Vipin Chaudhary,12/31/2016,"$2,499,996.00 ",Michael Dixon|Wen-Chau Lee|Gary Barnes,mmbell@hawaii.edu,"2440 Campus Road, Box 368",HONOLULU,HI,968222234,8089567800,CSE,1525|8004|8074,4444|7433|8004|8009|9150,"Modern radars and lidars are a diverse class of instruments, capable of detecting molecules, aerosols, birds, bats and insects, winds, moisture, clouds, and precipitation. Scientists and engineers use them to perform research into air quality and pollution, dangerous biological plumes, cloud physics, cloud extent, climate models, numerical weather prediction, road weather, aviation safety, severe convective storms, tornadoes, hurricanes, floods, and movement patterns of birds, bats and insects. Radars and lidars are critical for protecting society from high impact weather and understanding the atmosphere and biosphere, but they are complex instruments that produce copious quantities of data that pose many challenges for researchers, students, and instrument developers. This project will develop a new set of tools called the Lidar Radar Open Software Environment (LROSE) to meet these challenges and help address the 'big data' problem faced by users in the research and education communities. This project will open new avenues of scientific investigation, including data assimilation to improve weather forecasts, and help to maximize returns on NSF investments in weather and climate research by providing better software tools to researchers, students, and educators. Improving the effectiveness of NSF research will provide significant scientific and societal benefits through an improved understanding of many diverse scientific topics that are relevant to public safety, national defense, and the global economy.  The LROSE project will develop a 'Virtual Toolbox' with a set of software tools needed for a diverse set of scientific applications. LROSE will be packaged so that it can be run on a virtual machine (VM), either locally or in the cloud, and stocked with core algorithm modules for those typical processing steps that are well understood and documented in the peer-reviewed literature. LROSE will enable the user community to use the core toolset to develop new research modules that address the specific needs of the latest scientific research. Through the VM Toolbox and a core software framework, other developers of open-source radar software can then provide their own compatible software tools to the set. By combining the open source approach with recent developments in virtual machines and cloud computing, we will develop a system that is both highly capable and easy to run on virtually any hardware, without the complexity of a compilation environment. The LROSE project will build on existing prototypes and available software elements, while facilitating community development of new techniques and algorithms to distribute a suite of documented software modules for performing radar and lidar analysis. These modules will each implement accredited scientific methods referencing published papers. The infrastructure and modules will allow researchers to run standard procedures, thereby improving the efficiency and reproducibility of the analyses, and encourage researchers to jointly develop new scientific approaches for data analysis. The use of collaborative open source methods will lead to a suite of available algorithmic modules that will allow scientists to explore radar and lidar data in new, innovative ways. Researchers will benefit from the improved toolset for advancing understanding of weather and climate, leading to a positive outcome in the advancement of scientific knowledge and societal benefits.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550597,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1550597
1835717,"SI2, CSSI",SI2,Elements: Software: HDR: A knowledge base of deep time to facilitate automated workflows in studying the co-evolution of the geosphere and biosphere,Elements: Software: HDR: A knowledge base of deep time to facilitate automated workflows in studying the co-evolution of the geosphere and biosphere,One organization,OAC,XC-Crosscutting Activities Pro|CESER-Cyberinfrastructure for|EarthCube,12/1/2018,9/6/2018,Xiaogang Ma,ID,University of Idaho,46.7265894,-117.012565,Standard Grant,Stefan Robila,11/30/2021,"$596,975.00 ",,xgmachina@gmail.com,Office of Sponsored Programs,MOSCOW,ID,838443020,2088856651,CSE,7222|7684|8074,026Z|062Z|077Z|7923|8004|9150,"This project will result in the creation of a software that will support research in the Earth's deep time history. The co-evolution of the geosphere and biosphere is one of the fundamental questions for the 21st century Earth science. The multi-disciplinary characteristics of the research questions on co-evolution are reflected in the various subjects of datasets that need to be integrated. In the past decades, many open data facilities have been built through the support from NSF and other sources. However, the shortage of efficient methods for accessing and synthesizing multi-source datasets hamper the data-intensive co-evolution research. Geologic time is an essential topic in the co-evolving geosphere and biosphere, and can be used as a common reference to connect various parameters among the data silos. This project will improve the machine readability and alignment of various global, local and regional geologic time standards and build a knowledge base of deep time and its service on the Web. All the deliverables will be well-documented and offered under open-access to promote a national cyberinfrastructure ecosystem. The planned tasks and activities will leverage the usage of existing data facilities, facilitate executable and reproducible workflows, generate best practices of cross-disciplinary data science, generate state-of-the-art materials to education programs, and engage the participation of female and underrepresented groups. Shared in the national cyberinfrastructure, the knowledge base built in the project will be able to support a broad range of research, education and outreach programs, which will benefit not only science and engineering but also the society at large.  The research question to be addressed is the heterogeneity of geologic time concepts that hamper the data synthesis among multiple data facilities. Accordingly, the objective of this project is to build a knowledge base of deep time to automate geoscience data access and integration in the open data environment, and to support data synthesis in executable workflows for data-intensive scientific discovery. The development approach will include both top-down and bottom-up tracks to leverage previous works on geologic time ontologies and address end user needs through use case analyses. With carefully designed activities and work plan, deliverables from this project will include a machine-readable knowledge base of aligned geologic time standards, services and packages for accessing and querying the knowledge base, and best practices of data synthesis in workflow platforms for studying the co-evolution. The developed knowledge base of deep time will provide powerful support to co-evolution researchers to tackle data heterogeneity issues. Robust services the knowledge base will be built to support automated data synthesis in workflow platforms to advance the co-evolution research. The source code and metadata of the knowledge base will be released on GitHub and registered on community repositories to enable reuse and adaptation.   This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Activities Program of the Division of Earth Sciences within the NSF Directorate for Geosciences, and the OAC Cyberinfrastructure for Emerging Science and Engineering Research (CESER) program.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835717,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835717
1213013,"DIBBS, BIGDATA, III",DIBBS,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments,Collaborative,IIS,INFO INTEGRATION & INFORMATICS|IntgStrat Undst Neurl&Cogn Sys,10/1/2012,8/7/2017,Ouri Wolfson,IL,University of Illinois at Chicago,41.87496,-87.658107,Standard Grant,Maria Zemankova,9/30/2019,"$1,243,009.00 ",Maria Cruz|Bo Xu,wolfson@uic.edu,809 S. Marshfield Avenue,CHICAGO,IL,606124305,3129962862,CSE,7364|8624,7925|8089|8091|8551,"Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.  This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1213013,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1213013
1229928,"EAGER, RAPID, INSPIRE",EAGER,RAPID: Stakeholder Alignment for EarthCube,RAPID: Stakeholder Alignment for EarthCube,One organization,OAC,VIRTUAL ORGANIZATIONS|EarthCube,3/1/2012,2/23/2012,Joel Cutcher-Gershenfeld,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Kevin Crowston,2/28/2014,"$129,030.00 ",Michael Haberman|Joseph Mark Nolan,joelcg@brandeis.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,7642|8074,7433|7642|7914|7969,"Large-scale collaborative science is of increasing importance, but relatively little empirical evidence is available to guide the creation and operation of these multi-stakeholder efforts.  Previous social science research on stakeholder alignment in industrial relations and organizational studies is only now beginning to be applied to scientific consortia.  Early results indicate that social science tools and methods can play a key role in enabling coordinated, cross-organizational alignment. New techniques for identifying stakeholders, assessing interests, and visualizing alignment are beginning to emerge, but require additional refinement. This is a time-bound, demonstration case for applying stakeholder alignment methods initially advanced under the NSF study of 'Stakeholder Alignment in Socio-Technical Systems' (NSF-VOSS 0956472).  This case will demonstrate new ways for stakeholders in complex systems to better visualize and analyze core interests (common and conflicting) in order to more quickly and more comprehensively achieve the alignment needed for understanding and action.  It is anticipated that this application of the methods will highlight needed areas for further instrumentation, validation, and enhancement.  The NSF EarthCube initiative represents a novel approach to rapid development of community-guided cyber infrastructure to integrate data and information for knowledge management across the Geosciences.  Optimizing these activities will require a deep understanding of stakeholder interests, including points of alignment (or misalignment).  This project will identify EarthCube stakeholders and their interests and develop, administer, and analyze the results of an initial stakeholder alignment survey to assess the state of the EarthCube cyber infrastructure, geoscience, and computer science communities prior to the planned June community meeting.  Timely feedback on this survey will be central to the success of the overall EarthCube effort, and enable longitudinal analysis of changes as the EarthCube process moves from separate communities, through the initial organization of emergent interdisciplinary teams and eventual community integration.  Stakeholder alignment is hypothesized to play an important role in community coalescence and team development and to affect the likelihood of successfully defining system requirements and building prototypes.  This project provides an opportunity to test the applicability of innovative stakeholder alignment techniques to emerging geo-sciences, cyber infrastructure and computer science partnerships focused on developing common frameworks for sharing research data.  Improved stakeholder alignment will substantially enhance the success and impact of EarthCube.  The resulting cyber infrastructure will create value and mitigate risk in domains touched by the geosciences.  Further, based on this demonstration case, applications to a wide range of NSF investments may be appropriate.  These tools and methods for stakeholder alignment represent potentially high impact enablers across our societal institutions that are of ever greater importance in an era of accelerating change.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1229928,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1229928
1256163,WORKSHOP,WORKSHOP,Envisioning Success:  A Workshop for Next Generation EarthCube Scholars and Scientists,Envisioning Success:  A Workshop for Next Generation EarthCube Scholars and Scientists,One organization,OAC,EarthCube,10/1/2012,9/12/2012,Joel Cutcher-Gershenfeld,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Amy Walton,9/30/2013,"$99,978.00 ",,joelcg@brandeis.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,8074,7433,"The diversity of data and data types in the geosciences and their dispersal among various academic institutions and federal agencies, all of which have their own data formats and associated search and discovery criteria have prevented maximum effective utilization of this tremendous wealth of information.  To ameliorate this situation, a new NSF initiative, called EarthCube, which is jointly funded by the Directorate of Geosciences and the Office of Cyberinfrastructure, was initiated in 2011 to create an interoperable and integrated data and knowledge management for the geo- and environmental sciences.  An integral part of the process is geoscience and cyberinfrastructure community engagement, at all levels, to ensure that EarthCube's final design and implementation serves all end user needs.  Crucial to the success of EarthCube is its ability to serve the future needs of geoscientists and its ability to scale to new developments in computer science and technology.  To enable input from early career geo-and cyber scientists, a workshop, focused on the expected career trajectory of early career scientists likely to be end users and infrastructure developers, has been funded to examine their needs and to project into the future how these early career professionals envision how EarthCube will impact their science and career trajectories.  The workshop is being held at the Carnegie Institution of Washington.  It is being hosted by a diverse team of convenors and is focused on collecting input from this crucial early career demographic.  The two-day workshop will involve participants from 41 different disciplines within the geo and cyber sciences from around the US.  Broader impacts of the work include providing key stakeholder input into the design of a major NSF activity focused on building infrastructure for science and engaging early career scientists in the process.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1256163,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1256163
1664119,"SI2, CSSI",SI2,"Collaborative Research: SI2-SSI:  Cyberinfrastructure for Advancing Hydrologic Knowledge through Collaborative Integration of Data Science, Modeling and Analysis","Collaborative Research: SI2-SSI:  Cyberinfrastructure for Advancing Hydrologic Knowledge through Collaborative Integration of Data Science, Modeling and Analysis",Collaborative,OAC,SPECIAL INITIATIVES|EAR|XC-Crosscutting Activities Pro|Software Institutes|EarthCube,10/1/2017,9/14/2017,Shaowen Wang,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Stefan Robila,9/30/2021,"$699,999.00 ",,shaowen@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,1642|6898|7222|8004|8074,026Z|7433|8004|8009,"Researchers across the country and around the world expend tremendous resources to gather and analyze vast stores of hydrologic data and populate a myriad of models to better understand hydrologic phenomena and find solutions to vexing water problems. Each of those researchers has limited money, time, computational capacity, data storage, and ability to put that data to productive use. What if they could combine their efforts to make collaboration easier? What if those collected data sets and processed model outputs could be used collaboratively to help advance hydrologic understanding beyond their original purpose? HydroShare is a system to advance hydrologic science by enabling the scientific community to more easily and freely share products resulting from their research, not just the scientific publication summarizing a study, but also the data and models used to create the scientific publication. HydroShare supports the sharing and publication of hydrologic data and models. This capability is necessary for community model development, execution, and evaluation and to improve reproducibility and community trust in scientific findings through transparency. As a platform for collaboration and running models on advanced computational infrastructure, HydroShare enhances the capability for data intensive research in hydrology and other aligned sciences. HydroShare is designed to help researchers easily meet the sharing requirements of data management plans while at the same time providing value added functionality that makes metadata capture more effective and helps researchers improve their work productivity. This project will extend the capabilities of the HydroShare cyberinfrastructure to enhance support for scientific methods, advance the social capabilities of HydroShare to enable improved collaborative research, integrate with 3rd party consumer data storage systems to provide more flexible and sustainable data storage. and establish an application testing environment to empower researchers to develop their own computer programs to act on and work with data in HydroShare. Empowering HydroShare users with the ability to rapidly develop web application programs opens the door to unforeseen, innovative combinations of data and models. WRF-Hydro, the framework for the NOAA National Water Model, will be used as a use case for collaboration on model development. Since WRF-Hydro is used by NOAA as part of the National Water Model (NWM), this collaboration opens possibilities for transfer of research to operations. Collectively, this functionality will provide a computing framework for transforming the practice of broad science communities to leverage advances in data science and computation and accelerate discovery.  HydroShare is a system for sharing hydrologic data and models aimed at giving hydrologists the cyberinfrastructure needed to manage data, innovate and collaborate in research to solve water problems. It addresses the challenges of sharing data and hydrologic models to support collaboration and reproducible hydrologic science through the publication of hydrologic data and models. With HydroShare users can: (1) share data and models with colleagues; (2) manage who has access to shared content; (3) share, access, visualize and manipulate a broad set of hydrologic data types and models; (4) use the web services interface to program automated and client access; (5) publish data and models to meet the requirements of research project data management plans; (6) discover and access data and models published by others; and (7) use web apps to visualize, analyze, and run models on data. This project will extend the capabilities of HydroShare to: (1) enhance support for scientific methods enabling systematic data and model analysis and hypothesis testing; (2) advance the social capabilities of HydroShare to enable improved collaborative research; (3) integrate with 3rd party consumer data storage systems to provide more flexible and sustainable data storage; and (4) establish an application testing environment to empower researchers to develop their own computer programs to act on and work with data in HydroShare. Under development since 2012 and first released in 2014, HydroShare supports the sharing and publication of hydrologic data and models. This capability is necessary for community model development, execution, and evaluation. As a platform for collaboration and cloud based computation on network servers remote from the user, HydroShare enhances the capability for data intensive research in hydrology and other aligned sciences. HydroShare is innovative from a computer science and CI perspective in the way computation and data sharing are framed as a network computing platform that integrates data storage, organization, discovery, and programmable actions through web applications (web apps). Support for these three key elements of computation allows researchers to easily employ services beyond the desktop to make data storage and manipulation more reliable and scalable, while improving ability to collaborate and reproduce results. The generation of new understanding, through integration of information from multiple sources and reuse and collaborative enrichment of research data and models, will be enhanced. Structured and systematic model process intercomparisons and alternative hypothesis testing will be enabled, bringing, through user friendly CI, the latest thinking in advancing hydrologic modeling to a broad community of earth science researchers, thereby transforming research practices and the knowledge generated from this research. Interoperability with consumer cloud storage will greatly ease entry of content into HydroShare and support its sustainability. This meshing of the rigorous metadata model of HydroShare with consumer file sharing will enhance reproducibility as well as provide an innovative mechanism for sharing and collaboration. Empowering HydroShare users with the ability to rapidly develop web apps opens the door to unforeseen, innovative combinations of data and models. WRF- Hydro will be used as a use case for collaboration on model development. WRF-Hydro provides a reach-based high resolution representation of hydrologic processes, and offers the potential to bring together scientists working at scales from research catchments on the order of 1 to 100s of square kilometers as well as those working at regional to continental scales and cut across disciplines from environmental engineering to aquatic ecologists. Since WRF-Hydro is used by NOAA as part of the National Water Model (NWM), this collaboration opens possibilities for transfer of research to operations. This project will adapt current best practices in CI for interoperability and extensibility to serve this multidisciplinary community of scientists. HydroShare has already had a broader impact, with documented rapid growth in use and uptake by other projects including in EarthCube. It will become sustainable community CI through operation as part of the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI) Water Data Center (WDC) facility. The use of WRF- Hydro/NWM, as a driving use case, will advance CI for community based model improvement. Through the Summer Young Innovators Program at the National Water Center (NWC), supported by the National Weather Service (NWS) and operated by CUAHSI, a pathway already exists to translate research findings to the operational needs of federal agencies participating in the NWC. HydroShare already touches a broad and diverse community, with user base including Native American tribes, hydrologic science students, and faculty researchers across the U.S. This proposal builds on the success of HydroShare to extend its capabilities and broaden model hypothesis testing, collaborative data sharing, and open app development across earth science research and education.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664119,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664119
1239603,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,Collaborative,EAR,EarthCube,4/1/2012,8/7/2012,Yong Liu,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Barbara L. Ransom,3/31/2013,"$18,000.00 ",,yongliu@ncsa.illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,GEO,8074,7433|7916,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239603,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239603
1440315,BB,BB,EarthCube Building Blocks: Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models,EarthCube Building Blocks: Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models,Collaborative,ICER,EarthCube,9/1/2014,8/13/2014,Praveen Kumar,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$647,149.00 ",Mostafa Elag|Luigi Marini,kumar1@uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,GEO,8074,7433,"The project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. Many challenges hinder the seamless integration of models with data. These challenges compel scientists to perform the integration process manually. The primary challenges are a consequence of the knowledge latency between model and data resources and others are derived from inadequate adoption and exploitation of information technologies. Knowledge latency challenges increase exponentially when a user aims to integrate long-tail data (data collected by individual researchers or small research groups) and long-tail models (models developed by individuals or small modeling communities).The goal of this research is to develop a framework rooted in semantic techniques and approaches to support ?long-tail? models and data integration. The vision is to develop a decentralized knowledge-based platform that can be easily adopted across geoscience communities comprising of individual and small group researchers.    This project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. The project will develop a knowledge framework to close the loop from models? queries back to data sources by first investigating the required concepts architecture for integrating two leading examples of long-tail resources in geoscience: Community Surface Dynamic Modeling System (CSDMS) and Sustainable Environment Actionable Data (SEAD). The project will also develop a context-based data model that provides an explicit interpretation of a metadata attribute. The researchers will capture the metadata concepts and semantic from various geo-informatics systems and provide tools for ensuring conceptual integration between the resources. Next, the project will develop a knowledge discovery tool that allows automated coupling of a model and data coming from different contributors. Finally, the project will provide a prototype physical implementation of the knowledge framework in CSDMS modeling framework to demonstrate how it can advance the seamless discovery, selection, and integration between models and data, and how to achieve dynamic reusability of resources across multiple Earth Science long-tail resources.  ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440315,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440315
1249607,"EAGER, RAPID, INSPIRE",EAGER,"INSPIRE: ENABLING TRANSFORMATION IN THE SOCIAL SCIENCES, GEOSCIENCES, AND CYBERINFRASTRUCTURE THROUGH STAKEHOLDER ALIGNMENT AND NEW INSTITUTIONAL THEORY, METHODS, AND ANALYTICS","INSPIRE: ENABLING TRANSFORMATION IN THE SOCIAL SCIENCES, GEOSCIENCES, AND CYBERINFRASTRUCTURE THROUGH STAKEHOLDER ALIGNMENT AND NEW INSTITUTIONAL THEORY, METHODS, AND ANALYTICS",One organization,EAR,SCIENCE|TECH & SOCIETY|Science of Organizations|EarthCube|SciSIP Infrastructure|INSPIRE,10/1/2012,9/27/2012,Joel Cutcher-Gershenfeld,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Barbara L. Ransom,9/30/2016,"$800,000.00 ",Michael Haberman|Courtney Flint|Barbara Lawrence|Joseph Mark Nolan,joelcg@brandeis.edu,1901 South First Street,Champaign,IL,618207406,2173332187,GEO,7603|8031|8074|8075|8078,0000|7433|7626|8653|9179|OTHR,"This INSPIRE award is partially funded by the Directorate of Geosciences and Office of Cyberinfrastructure as part of their committment to EarthCube, a major new NSF cyberinfrastructure activity to create a bold, integrated, geoscience data and knowledge management system for the 21st Century, and by three Programs in the Directorate for Social, Behavioral, and Economic Sciences (Science of Science and Innovation Policy; Science, Technology, and Society; and Science of Organizations). This is transformative, interdisciplinary, research that enables more effective design and implementation of community-driven cyberinsrastructure that will create an interoperable system of data systems and data types that serve a broad and disparate community of geoscience users with different backgrounds, needs, and scientific cultures.  The research will also pioneer new social and behavioral science theory, methods, and analytics that address new and emerging ways that stakeholders are aligned around big, complex, infrastructure projects.  The research is transformative in nature because it is a first-of-its kind project in which a major NSF community-driven infrastructure project of this magnitude has incorporated, as an integral part of its project structure, social science and an analysis of the community/stakeholder building process.  It also breaks new ground in the developing of quantitative approaches to measure the evolution of collective community and individual perceptions over time. This type of understanding is critical when building trust and partnerships between science and technology communities that rarely, if ever, interact.  The project involves the intimate interaction of social scientists, geoscientists, and cyberinfrastructure and computer science experts, with the results of the stakeholder studies being used to help improve the cyberinfrastructure design-and-build process, as well as guide the formation of the organizational and governance structures that will be needed to effectively manage community engagement and implementation of the final system. This research employs novel visualization tools and will develop innovative quantitative means for assessing stakeholder agreement and its evolution over time. The analysis of data and results will assist in identifing the most effective targets for infrastructure investment and understanding and improving community engagement in the design process, thus ensuring that whatever is created adequately serves end-user needs. Broader impacts of the work include the training of PhD students, accelerating progress in large NSF-initiated science and technology projects, and generating insights that will inform policy, planning, and resource allocation.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1249607,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1249607
1053575,OTHER,OTHER,XSEDE: eXtreme Science and Engineering Discovery Environment,XSEDE: eXtreme Science and Engineering Discovery Environment,One organization,OAC,FLUID DYNAMICS|INFORMATION TECHNOLOGY RESEARC|COMPUTATIONAL PHYSICS|ETF|EQUIPMENT ACQUISITIONS|PETASCALE - TRACK 1|EarthCube,7/1/2011,6/23/2016,John Towns,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Cooperative Agreement,Rudolf Eigenmann,12/31/2016,"$125,628,751.00 ",Ralph Roskies|Kelly Gaither|John Boisseau|Gregory Peterson|Nancy Wilkins-Diehr|Patricia Kovatch|Philip Andrews,jtowns@ncsa.illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,1443|1640|7244|7476|7619|7781|8074,058E|1640|7433|7476|7556|8084|9263,"The eXtreme Science and Engineering Discovery Environment (XSEDE) partnership will develop an unprecedented, comprehensive advanced digital services cyberinfrastructure (CI) to enable transformative open science and engineering research and innovative training and educational programs. The goal of XSEDE is to offer users tremendous capabilities with maximum productivity, enabling them to advance and share knowledge across domains. The XSEDE architecture, engineering, operations, support, and education activities are co-designed by an unparalleled team to achieve this goal, far surpassing TeraGrid in usability, reliability, capability, performance, and security?and ultimately, in user productivity and science impact. XSEDE will enable scientists, engineers, and educators to exploit powerful digital services and social networking environments to support knowledge exchange and advance understanding across domains. Just a few examples of the advances to science and society include: accurately predicting earthquake damage to urban structures; modeling of protein and nucleic acid folding and structure prediction to understand how drugs interact with target macromolecules to improve health care; developing novel designs for nanoscale microprocessors; advancing scientific understanding of plants to provide a safe and sustainable food supply, as well as benefits in renewable energy; and simulating pandemic spread to create a virtual laboratory where policy decisions such as school closure, vaccine deployment, and quarantine can be explored.  The XSEDE partnership will fulfill this vision by creating the most advanced, capable, and robust advanced digital cyberinfrastructure in the world?and supporting it with the most expert and experienced team of CI professionals. XSEDE will accelerate open scientific discovery and enable researchers, educators, and students across disciplines and across campuses to conduct transformational research efforts and innovative education programs. XSEDE will create strong ties with campus personnel spanning technology, workforce development, and policy issues to enhance CI for research and education. Researchers will use XSEDE directly, from campus and personal systems, from other high-end centers and cyberinfrastructure resources, and via science gateways and discovery environments. XSEDE users will be backed by an integrated national user support program offering an array of services from experts in the application of technology to advance science and engineering, including extensive training and advanced user support and collaboration. XSEDE?s governance model will include participation by these users as stakeholders, while providing centralized management to ensure robustness and to facilitate rapid responses to new issues and opportunities.  XSEDE will carry out a multifaceted Training, Education, and Outreach Services (TEOS) program to raise the competency of the present and future scientific community. XSEDE will work proactively with the nation?s educational institutions to create a significantly larger and more diverse STEM workforce. TEOS will broaden participation by working with under-represented faculty and students to engage larger numbers of under-represented individuals from among minority-serving and EPSCoR institutions, women, and people with disabilities. TEOS will disseminate best practices, lessons learned, and quality materials and will leverage external partnerships to scale-up successful practices. XSEDE will leverage the XD Technology Insertion Service (TIS) activities?already awarded to the XSEDE team?into continuously advancing CI and will work closely with the Technology Audit Service (TAS) team to ensure that XSEDE can be effectively evaluated and improved. These activities will ensure that XSEDE is robust, easy to use, performing as designed, and evolving constantly to meet the growing demands of scientific research and researchers.  Advancing science with the most powerful, diverse, and integrated set of advanced digital services ever?and linking that to other CI projects and to campuses and local research infrastructure?is unprecedented. No engineering and technology plan can anticipate all contingencies and future opportunities. The successful realization of NSF?s vision for XD will require deep expertise and vast experience, as well as focused and passionate effort. The XSEDE team is uniquely experienced and qualified for this incredible opportunity.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1053575,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1053575
1747552,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Building the Community for the Open Storage Network,Collaborative Research: Building the Community for the Open Storage Network,Collaborative,IIS,EarthCube,6/15/2018,9/27/2018,Melissa Cragin,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Alejandro Suarez,5/31/2020,"$434,553.00 ",James Glasgow|Kenton McHenry|Michelle Butler,cragin@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,8074,062Z,"The scientific community is facing a major challenge dealing with the increasing amount of open scientific data emerging from research projects on all scales-- from large facilities to small research labs. Over the last five years the NSF has funded more than 200 high-speed connections to the Internet-2 backbone operating at 10-100Gbps speeds. The goal of this project is to develop a prototype module for a high performance distributed storage system that extends the usability of the existing high-speed interconnects. This project is a pilot for a potential national-scale storage infrastructure for open scientific data, which at full scale could serve hundred sites and many hundreds of Petabytes.  Many of the technologies associated with such a distributed system already exist; the key challenge in this project is social engineering: how can one design a simple enough yet robust storage node that can be easily replicated, is attractive for universities and research projects to adopt, is easy to manage and can support the various patterns for large scale scientific analyses?  Many universities have several of the necessary pieces for Data Intensive Science in place-- reasonably sized computing clusters, a few PB of storage and even a high-speed connection-- yet performing the analyses of data intensive science is very painful and slow. Data is never there when needed, large storage systems often fail despite having massive RAID configurations, and moving data from disk-to-disk at the full network speed still requires complex skills. The project offers a broad community buy-in through the Big Data Hubs, a unique combination of skills, facilities and science challenges to test, evaluate and deploy different hardware and software combinations that can be used in the design of a much larger, national-scale system. The goal is to design and run detailed benchmarks for various test science projects requiring different combinations of data transfer, data processing and massive compute, and use the results to design and build a low-cost, scalable petascale appliance including inexpensive hardware nodes and a simple software stack that can be replicated across many universities, supercomputer centers and large NSF facilities. The proposed system could become an enormous multiplier on the existing NSF investments in high end computing and fast networks. It could also accelerate the pace of standardization of data storage across the nation. The public, open data products, often discussed in the Data Management Plans at the end of NSF proposals could find an easy-to-use home. Various educational projects could simply rely upon a robust storage infrastructure with a simple API, and build a variety of delivery services for the educational community.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747552,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747552
1762039,"DIBBS, BIGDATA, III",DIBBS,Spokes: MEDIUM: MIDWEST: Collaborative: An Integrated Big Data Framework for Water Quality Issues in the Upper Mississippi River Basin,Spokes: MEDIUM: MIDWEST: Collaborative: An Integrated Big Data Framework for Water Quality Issues in the Upper Mississippi River Basin,Collaborative,IIS,BD Spokes -Big Data Regional I|HYDROLOGIC SCIENCES|EarthCube,8/1/2018,7/29/2018,Jong Lee,IL,University of Illinois at Urbana-Champaign,40.101952,-88.227161,Standard Grant,Venkataraman Lakshmi,7/31/2021,"$300,000.00 ",Richard Warner,jonglee1@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,024Y|1579|8074,062Z|1579|8083,"This project will develop a cyberinfrastructure framework to facilitate research on the efficient management of agricultural practices and their impact on water resources in the Upper Mississippi River Basin (UMRB).  Large-scale data acquisition, integration, analysis, and visualization using data-enabled information technologies will accelerate the dissemination of knowledge, experience, and shared resources (e.g., technology, equipment, and people) among communities and partners.  The key element of the project is a new cyber platform, the Upper Mississippi Information System (UMIS), which will provide water quality data within a rich spatio-temporal hydrologic context.  The UMIS directly addresses three of the Grand Challenges for Engineering identified by the National Academy of Engineering: i) provide access to clean drinking water; ii) manage the nitrogen cycle; and iii) engineer the tools of scientific discovery.  The UMIS will immediately begin facilitating data access, integration, and scientific discovery for water quality challenges in the UMRB.   UMIS will offer internet-based open access to water quality information in its meteorological, hydrological, and geographical context, providing almost endless potential benefits for stakeholders.  For example, the experimental design of the UMIS will enable researchers to study spatial scaling, efficiency of various land use and agricultural practices to improve water quality, and the impact of climate change on land management and water quality.  Decision-makers, producers, and extension staff will be able to assess the relative efficacy of local (e.g., best management practices) versus system-level (e.g., state programs) solutions designed to reduce pollution, optimize the use of resources, and evaluate tradeoffs among competing objectives.  For all stakeholders, the UMIS will support partnerships and collaborations, increase dissemination of information about a critical natural resource to empower stakeholders at all levels, and set new standards in the communication of scientific data.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1762039,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1762039
1252279,WORKSHOP,WORKSHOP,EarthCube Domain End-User Workshop for Structural Geology and Tectonics,EarthCube Domain End-User Workshop for Structural Geology and Tectonics,One organization,EAR,EarthCube,9/1/2012,9/19/2012,J. Douglas Walker,KS,University of Kansas Center for Research Inc,38.951591,-95.265608,Standard Grant,Stephen Harlan,8/31/2014,"$50,000.00 ",,jdwalker@ku.edu,2385 IRVING HILL RD,LAWRENCE,KS,660457568,7858643441,GEO,8074,1572|7433|9150,"This project is supporting a two-day workshop that will be held identify the possible interactions between the Structural Geology and Tectonics community (SGTC) with the EarthCube effort. The workshop will assemble a group of about 40 Structural Geology and Tectonics researchers to define better the cyberinfrastructure needs as well as the required interactions within the community as well as with the EarthCube to take the next steps in creating a more integrated digital framework. This effort includes: 1) establishing science drivers and challenges of the SGTC; 2) identifying the impediments to using data and tools both within and external to the SGTC; 3) listing existing and more critically needed data, tools, and visualization to form a cyberinfrastructure for the community; 4) creating several use cases that demonstrate how the cyberinfrastructure will be used to address the science drivers or provide critical connections for teaching and research; and 5) initiating conversation with existing databases on how to interact constructively. A catalyzing issue of the workshop concerns the nature of field data. Structural data is collected on an extremely wide range of spatial (10-8 m to 104 m) and temporal scales, and the collection requires observation, inference, and interpretation at most of these scales. These data are critical to any tectonic modeling and inference. This data at the core of Structural Geology and Tectonics and presents a fundamental challenge to digital representation/integration that can be aided by the interaction with the EarthCube effort.  This project is important for both the scientific and cyberinfrastructure development of the geosciences. Future progress of the geosciences will be based on the integration of rich and diverse datasets. This workshop will identify the needs of one of the most important and data-rich as well as data complex areas in geology. There will be a vast array of intellectually challenging tasks in describing and integrating data across a spectrum of scales as well as granularity.  The construction of a cyberinfrastructure for Structural Geology and Tectonics data will make these data accessible to a much larger group of researchers. This field describes and quantitatively documents the surface geology of the Earth. That itself has impacts into individuals, groups, and organizations that study the earth. In addition, the digital presentation of such data can be used by private and governmental organizations across the local to global spectrum. Lastly, the integration of Structural Geology and Tectonics data and models into the EarthCube effort will be fundamental to the success of EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252279,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252279
1639738,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,Collaborative,ICER,EarthCube,9/1/2017,8/18/2017,J. Douglas Walker,KS,University of Kansas Center for Research Inc,38.951591,-95.265608,Standard Grant,Eva Zanzerkia,8/31/2020,"$285,982.00 ",,jdwalker@ku.edu,2385 IRVING HILL RD,LAWRENCE,KS,660457568,7858643441,GEO,8074,7433|9150,"When viewed at the micro-scale, rocks reveal structures that help to interpret the processes and forces responsible for their formation.  These microstructures help to explain phenomena that occur at the scale of mountains and tectonic plates.  Interpretation of microstructures formed in nature during deformation is aided by comparison with those formed during experiments, under known conditions of pressure, temperature, stress, strain and strain rate, and experimental rock deformation benefits from the ground truth offered through comparison with rocks deformed in nature.  However, the ability to search for relevant naturally or experimentally deformed microstructures is hindered by the lack of any database that contains these data.  The researchers collaborating on this project will develop a single digital data system for rock microstructures to facilitate the critical interaction between and among the communities that study naturally and experimentally deformed rocks.  To aid in the comparison of microstructures formed in nature and experiment, we will link to commonly used analytical tools and develop a pilot project for automatic comparison of microstructures using machine learning.     Rock microstructures relate processes at the microscopic scale to phenomena at the outcrop, orogen, and plate scales and reveal the relationships among stress, strain, and strain rate.  Quantitative rheological information is obtained through linked studies of naturally formed microstructures with those created during rock deformation experiments under known conditions.  The project will develop a single digital data system for both naturally and experimentally deformed rock microstructure data to facilitate comparison of microstructures from different environments.  A linked data system will facilitate interaction between practitioners of experimental deformation, those studying natural deformation and the cyberscience community.  The data system will leverage the StraboSpot data system currently under development in Structural Geology and Tectonics.  To develop this system requires: 1) Modification of the StraboSpot data system to accept microstructural data from both naturally and experimentally deformed rocks; and 2) Linking the microstructural data to its geologic context ? either in nature, or its experimental data/parameters.  The researchers will engage the rock deformation community with the goal of establishing data standards and protocols for data collection, and integrate our work with ongoing efforts to establish protocols and techniques for automated metadata collection and digital data storage.  To analyze the microstructures studied and/or generated by these communities, we will ensure StraboSpot data output is compatible with commonly used microstructural tools.  They will develop a pilot project for comparing and analyzing microstructures from different environments using machine-learning.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639738,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639738
1639734,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,J. Douglas Walker,KS,University of Kansas Center for Research Inc,38.951591,-95.265608,Standard Grant,Eva Zanzerkia,8/31/2019,"$740,338.00 ",Warren Alexander|Diane Kamola,jdwalker@ku.edu,2385 IRVING HILL RD,LAWRENCE,KS,660457568,7858643441,GEO,8074,7433|9150,"Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information.  The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams.  Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field.  The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return.  They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community.  The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks).  By the end of the project,  geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.  The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines.  The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in.  They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows.  The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo.  This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects.  At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists.  The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639734,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639734
1745055,OTHER,OTHER,Collaborative Research: Topographic Controls on Antarctic Ice Sheet Grounding Line Behavior - Integrating Models and Observations,Collaborative Research: Topographic Controls on Antarctic Ice Sheet Grounding Line Behavior - Integrating Models and Observations,Collaborative,OPP,ANTARCTIC EARTH SCIENCES|ANTARCTIC GLACIOLOGY|EarthCube,9/1/2018,8/17/2018,Leigh Stearns,KS,University of Kansas Center for Research Inc,38.951591,-95.265608,Standard Grant,Paul Cutler,8/31/2021,"$239,448.00 ",Cornelis van der Veen,stearns@ku.edu,2385 IRVING HILL RD,LAWRENCE,KS,660457568,7858643441,GEO,5112|5116|8074,062Z|9150,"Current ice mass loss in Antarctica is largely driven by changes at glacier grounding lines, where inland ice transitions from being grounded to floating in the ocean. The rate and pattern of glacier retreat in these circumstances is thought to be controlled by the terrain under the ice. This project incorporates evidence of past ice-retreat events and other field data, such as grounding-line positions and dates, subglacial topography, and meltwater features, into numerical models of ice flow to investigate the influence that grounding-line processes and subglacial topography have on glacier retreat rates over the past 15,000 years.  Recent observations suggest that Antarctic ice mass loss is largely driven by perturbations at or near the grounding line. However, the lack of information on subglacial and grounding-line environments causes large uncertainties in projections of mass loss and sea-level rise. This project will integrate geologic data from the deglaciated continental shelf into numerical models of varying complexity from one to three-dimensions. Rarely do numerical ice-sheet models of Antarctica have multiple constraints on dynamics over the past ~15,000 years (a period that spans the deglaciation of the Antarctic continental shelf since the Last Glacial Maximum).  The geologic constraints include grounding-line positions, deglacial chronologies, and information on grounding line-ice shelf processes.   The models will be used to investigate necessary perturbations and controls that meet the geological constraints. The multidisciplinary approach of merging geologic reconstructions of paleo-ice behavior with numerical models of ice response will allow the research team to test understanding of subglacial controls on grounding-line dynamics and assess the stability of modern grounding lines.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1745055,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1745055
1848747,WORKSHOP,WORKSHOP,"NSF Summer 2019 workshop: Computing Arctic Data: Orono, ME - Spring 2019","NSF Summer 2019 workshop: Computing Arctic Data: Orono, ME - Spring 2019",One organization,OPP,EarthCube,9/1/2018,8/27/2018,Andrei Kurbatov,ME,University of Maine,44.9012197,-68.6688395,Standard Grant,Cynthia Suchman,8/31/2019,"$49,999.00 ",Sean Birkel|Sudarshan Chawathe,akurbatov@maine.edu,5717 Corbett Hall,ORONO,ME,44695717,2075811484,GEO,8074,062Z|1079|9150,"To better understand causes, trends and thresholds of a changing Arctic and to develop robust societal adaptation strategies new research tools are needed. There is a wealth of past climate data sets stored in the NSF-funded Arctic Data Center (ADC) that are unresolved yet have the potential to expand and deepen the current state of understanding about how the Arctic is responding to environmental changes. This award supports an integrative workshop that will bring together a diverse group of early career scientists and experts from the fields of ice core, computer and climate sciences to transform the existing research data computation platform. The goal is to pave the way for the development of a future generation of computer tools necessary to better understand complex interactions of multiple driving forces that are changing Earth's environment. Objectives are to evaluate the latest computational advances, break existing interdisciplinary barriers that limit the use of ice core data sets in climate research, and, by openly sharing results, promote the development of future products that will benefit the Arctic research community and the global population.    Evaluating present and forecasting future trends in the ""New Arctic"" system is closely connected to understanding multidimensional paleoclimate data archives. Using open source tools to ease the reproduction of computational and data-intensive portions of paleoclimate research, transparency in data processing steps will increase. In addition, (1) the range of usability of existing climate and ice core based paleoclimate data archives will be extended; (2) open access data and software libraries, utilizing open source based software tools will be developed; (3) paleoclimate and computer infrastructure specific white papers will be developed that will summarize the state of the problem, map future pathways for systematic improvements, and finally converge this rapidly evolving research domain with a novel computational and easy to use data processing framework.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1848747,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1848747
1354693,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,Collaborative,ICER,EarthCube,9/15/2013,5/12/2014,Thomas Narock,MD,University of Maryland Baltimore County,39.255613,-76.710975,Standard Grant,Barbara L. Ransom,8/31/2015,"$74,984.00 ",Timothy Finin,thomas.w.narock@nasa.gov,1000 Hilltop Circle,Baltimore,MD,212500002,4104553140,GEO,8074,0000|7433|7916|OTHR,"This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures.  It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed.  Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details.  Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354693,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354693
1540542,IA,IA,EarthCube IA: Collaborative Proposal: Optimal Data Layout for Scalable Geophysical Analysis in a Data-intensive Environment,EarthCube IA: Collaborative Proposal: Optimal Data Layout for Scalable Geophysical Analysis in a Data-intensive Environment,Collaborative,ICER,EarthCube,9/1/2015,9/8/2015,Kwo-Sen Kuo,MD,University of Maryland College Park,38.986918,-76.942554,Standard Grant,Eva Zanzerkia,8/31/2018,"$242,906.00 ",,kkuo@umd.edu,3112 LEE BLDG 7809 Regents Drive,COLLEGE PARK,MD,207425141,3014056269,GEO,8074,7433|9150,"Steady advance in remote sensing, satellite imaging, and computing technology has enabled scientists to study geophysical phenomena of unprecedented resolutions and complexity. Earth observation data generated from space-based satellites or ground-based radar and radiometer facilities are typically time-varying, and multivariate, and can take tera- or even peta-bytes of space to preserve and process. The common practice is to choose and transfer subsets of data from multiple data archive servers to local machines and then conduct data analysis tasks. However, this approach becomes increasingly unsustainable with an exponential growth of observation data size. It becomes an increasing severe problem that scientists can gain detailed observation data but lack suitable and scalable analysis capabilities to study the full extent of data. The team will work closely to develop, evaluate,and deploy the computer infrastructure to improve the performance and scalability of geophysical analysis for scientific discovery and education. By making the system available to other researchers, it will facilitate the development of new scalable solutions.Interactive geosciences applications will be used as an effective means to promote students interest in science and engineering studies, and to attract and retain students for geosciences community growth.  This research develops new techniques in support of scalable geophysical analysis in a data-intensive environment. The innovation and the basis of our technique approach are to develop an optimal data layout algorithm for indexing and placing massive heterogeneous observation data across distributed devices of a cluster. The new data layout is tailored to the spatial-temporal characteristics of Earth observation data, and can directly account for advanced compute techniques, including non-volatile storage resources and GPU- and Manycore-based computing nodes, and support high-throughput and high-resolution exploration of large-scale data. The long-term goal is to study theory and technology that enable scalable data management and analysis for the geosciences community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540542,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540542
1639706,BB,BB,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Eunseo Choi,TN,University of Memphis,35.118741,-89.937141,Standard Grant,Eva Zanzerkia,8/31/2018,"$80,000.00 ",,echoi2@memphis.edu,Administration 315,Memphis,TN,381523370,9016783251,GEO,8074,7433|9150,"Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility.   GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639706,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639706
1639722,BB,BB,EarthCube Building Blocks: Collaborative Proposal: That dot is a world! Drilling down from a statistics scatterplot to pre-populated case Notebooks.,EarthCube Building Blocks: Collaborative Proposal: That dot is a world! Drilling down from a statistics scatterplot to pre-populated case Notebooks.,Collaborative,ICER,EarthCube,9/1/2016,9/13/2016,Brian Mapes,FL,University of Miami Rosenstiel School of Marine&Atmospheric Sci,25.732401,-80.162762,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$808,231.00 ",Mohamed Iskandarani,bmapes@rsmas.miami.edu,4600 RICKENBACKER CSWY,KEY BISCAYNE,FL,331491031,3054214089,GEO,8074,7433,"This project will develop and utilize capabilities for its scientists to ""drill down"" into abstract statistics about the flows of the atmosphere and ocean, to build a library of Notebooks with clear views of the actual weather systems (in the atmospheric part of the work) or Gulf of Mexico ocean eddies (in the ocean part of the work). The researchers will build this software, DRILSDOWN, using popular and powerful open-source software components that already exist, so it should be very generally applicable and have a long future. The power at the heart of the DRILSDOWN software will be the Integrated Data Viewer. The front end will consist of Jupyter Notebooks, a very popular new approach for literate computing and reproducibility of science. Literate computing allows a human-readable, meaningful, openly published document to have embedded computer-executable codes that can be repeated by anyone to replicate the results. The code can be adjusted if a user wants to see how analysis choices translate into outcomes. The involvement of scientists and a postdoc and and students will ensure the product development is useful to real research activities, while the collaboration with professional software developers (and the use of popular existing components) will ensure that it is robust and flexible enough to serve other use cases, including researchers in other areas of geoscience.  The project will develop and utilize new software called DRILSDOWN to facilitate the linking of statistics to instances, a key step in the science of complex systems. In order to guide and stress test the software development, the team will perform novel atmospheric and oceanic science newly enabled by DRILSDOWN. In the atmosphere, they will study some distinct but related published measures of high-impact flow events variously classified as Rossby wave breaking (or potential vorticity filamentation) in the upper troposphere, or as poleward water vapor transports in the lower troposphere. Three-dimensional case studies will show the relationship between these low- and high-altitude descriptions, based on statistics of each measure which will allow us to select cases with high-low, low-high, and high-high measures. How do these different measures perform at characterizing these high impact events, and how might they be reconciled and perhaps optimized? In the ocean, similar activity will be to examine statistical characterizations of eddy shedding from the Loop Current in the Gulf of Mexico, an important current system for oil spills, hurricanes, fisheries, and other hazards and interests. Full-detail case studies of marginal cases (shedding/ non-shedding) will inform fundamental science understanding of the shedding process, as well as helping to improve the algorithms for objectively measuring it, so that large ensembles of possible ocean flow scenarios can be more effectively and rapidly screened, with realistic uncertainty quantification, for instance in the event of an incident requiring ocean forecasts.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639722,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639722
1442095,OTHER,OTHER,DYNAmics of the Madden-Julian Oscillation (DYNAMO) Legacy Data Products,DYNAmics of the Madden-Julian Oscillation (DYNAMO) Legacy Data Products,One organization,AGS,PHYSICAL & DYNAMIC METEOROLOGY|CLIMATE & LARGE-SCALE DYNAMICS|EarthCube,4/15/2015,11/28/2016,Shuyi Chen,FL,University of Miami Rosenstiel School of Marine&Atmospheric Sci,25.732401,-80.162762,Standard Grant,Eric T. DeWeaver,11/30/2017,"$788,836.00 ",Steven Rutledge|James Moum|Courtney Schumacher|Robert Houze,shuyic@uw.edu,4600 RICKENBACKER CSWY,KEY BISCAYNE,FL,331491031,3054214089,GEO,1525|5740|8074,4444|7433|OTHR,"This award supports the creation of a legacy dataset for data collected during the DYNAmics of the Madden-julian Oscillation (DYNAMO) field campaign. The goal of DYNAMO was to observe the initiation of the Madden-Julian Oscillation (MJO).  The MJO is a large-scale pattern of precipitation and atmospheric circulation that forms in the Indian Ocean and propagates slowly eastward affecting weather and climate across a large portion of the globe.   The campaign took place in the Indian Ocean from 1 October 2011 until 9 February 2012 and was a massive undertaking involving ships, aircraft, sounding systems, and an island-based radar ""supersite"".  Several US agencies and international partners were involved, as documented in the abstract for NSF award AGS-1022899.  The campaign was a success in that three MJO events occurred during the deployment, of which the first occurred during the Special Observing Period when all the field assets were deployed together. Overall about 10 terabytes of data were collected.  Given the success of the campaign and the large investments made in it, a further investment is warranted to enhance the accessibility of the campaign data and facilitate its used by the research community.  Three categories of data products will be developed on this award, characterized by the type of instrumentation used to collect the observations: radar-based, aircraft-based, and sounding-based products.  A fourth category consists of data products processed in ways consistent with specific interests of the research community, for instance sounding data processed into variables like precipitable water, convective available potential energy, convective inhibition, lifting condensation level, and the level of free convection.  The entire collection will be hosted by the Earth Observing Laboratory at the National Center for Atmospheric Research.  This project is somewhat unusual in that the goal is to develop and serve a dataset for the research community, rather than to conducted research to address a scientific hypothesis. Thus all of the effort can be regarded as a broader impact to the research community. It should also be noted that the MJO has a number of societal consequences, as it is a dominant driver of weather in the tropics and also affects on the US.  Among other impacts, the MJO influences the number of hurricanes that form in the Gulf of Mexico. Research leading to better representation of the MJO in weather forecasting models is thus desirable. In addition, the data products will facilitate research on tropical convection in general, which will be of value for developing better models to predict weather and make projections of future climate change.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1442095,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1442095
1639640,BB,BB,EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2016,9/1/2016,Branko Kerkez,MI,University of Michigan Ann Arbor,42.278044,-83.738224,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$227,999.00 ",,bkerkez@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,GEO,8074,7433,"While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.  CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639640,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639640
1440116,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2014,8/6/2014,Branko Kerkez,MI,University of Michigan Ann Arbor,42.278044,-83.738224,Standard Grant,Eva E. Zanzerkia,8/31/2016,"$40,000.00 ",,bkerkez@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,GEO,8074,7433,"The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating  data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)  The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440116,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440116
1740697,IA,IA,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative,ICER,EarthCube,9/1/2017,9/13/2017,Amy Myrbo,MN,University of Minnesota-Twin Cities,44.97399,-93.227729,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$109,143.00 ",Eric Grimm|Anders Noren,amyrbo@umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,GEO,8074,7433,"Data heterogeneity and accessibility are major barriers to scientific progress. Many community curated data repositories (CCDRs) have emerged in the paleogeosciences in response to the needs of their scientific communities, but these CCDRs are not well integrated. This project seeks to transform geoscientific research by breaking down the barriers among the CCDRs that serve geoscientists. All participating resources are closely engaged with their respective disciplinary communities and each is mobilizing data from its communities; the key need is to facilitate data interchange among CCDRs. The work will align several major CCDRs using a system that develops new shared services that rely on common standards, and demonstrates the kinds of new scientific insights that become possible with an integrated geoscientific infrastructure.  This collaborative project will accomplish the following: 1) A survey of existing data structures and standards, their suitability for paleogeoscience CCDRs and alignment with requirements identified by the paleogeosciences research coordination network, and their degree of adoption. This will lead to recommendations for adoption by participating resources (EarthChem, Flyover Country, IODP, LacCore/CSDCO, LinkedEarth, Neotoma) and documentation written for geoscientific audiences. 2) Alignment of participating CCDRs to recommended standards and development of a common API that will allow data exchange among CCDRs and to third-party users. 3) Development of an Annotation Engine, which will provide a credentialed, crowd-sourced system for scientists to flag changes to datasets, to connect datasets post hoc, to add context to legacy data, and to provide link-back notification among CCDRs when linked dataset attributes change. Annotation Engine will be embedded into existing scientific CCDR-based workflows, minimizing disruption to users. 4) Development of GeoNoteBase to enable scientists to generate citeable, reproducible workflows that draw information from across data resources, with workflows made available through keyword searches, with full attribution. This is a pilot effort to begin some of the work Through two pilot scientific projects, THROUGHPUT will test and evaluate these new capabilities and demonstrate kinds of new scientific insights that can be gained through integration.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740697,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740697
1254928,WORKSHOP,WORKSHOP,EarthCube GEO Domain Workshop: Cyberinfrastructure for Paleogeoscience,EarthCube GEO Domain Workshop: Cyberinfrastructure for Paleogeoscience,One organization,EAR,EarthCube,9/15/2012,11/19/2015,Anders Noren,MN,University of Minnesota-Twin Cities,44.97399,-93.227729,Standard Grant,Judith Ellen Skog,8/31/2016,"$99,994.00 ",,noren021@umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,GEO,8074,7433,"EarthCube is a joint venture between the Directorate of Geosciences and the Office of Cyberinfrastructure at the National Science Foundation. It is a community-driven effort to design and implement an effective data and knowledge management system for the geosciences that will integrates disparate data sets and web services and serves all members of the geoscience community.   This award is for a workshop to be convened in Winter 2013, organized around a scientific domain (theme) called ?Paleogeoscience?. The defining characteristics of this broad domain are 1) its focus on past earth system processes and 2) that all scientific inferences in this domain are ultimately based on the collection of physical samples in the field, from which many kinds of geochemical, geobiological, and geophysical measurements are extracted. This domain includes scientists working on paleorecords from: cores drilled in the seafloor, lakebeds, peatlands, continental crust, glaciers or ice sheets, or trees; rock samples hammered from outcrops; fossil remains retrieved from various depositional environments; speleothems; and corals.  Participants will consist of key individuals already working on EarthCube activities, as well as those from this newly formed special interest group.  Special efforts will be made to reach out to all members of this diverse community in order to gather as much information about user requirements and other aspects of EarthCube relevant to the ?long tail? of data.  Broader impacts involve the potential to change dramatically the way paleogeoscientists interact with data, whether through discovery of existing data, providing context for new data, characterizing and comparing disparate datasets, or archiving data, in ways that will enable new questions to be answered and existing challenges to be addressed. The impact will likely be at least as great, and possibly greater, for students at the graduate, undergraduate, and even secondary levels (and their teachers), as the simplification of data discovery, visualization, and comparison will allow people with less training to interact with paleogeoscience data in a meaningful way. These tools will facilitate the communication of scientific findings even to policymakers and the public at large.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1254928,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1254928
1341831,WORKSHOP,WORKSHOP,Workshop on Cyberinfrastructure for Polar Sciences,Workshop on Cyberinfrastructure for Polar Sciences,One organization,OPP,POLAR CYBERINFRASTRUCTURE|Software Institutes,7/1/2013,7/7/2015,Jonathan Pundsack,MN,University of Minnesota-Twin Cities,44.97399,-93.227729,Standard Grant,Neil R. Swanberg,6/30/2016,"$99,998.00 ",,pundsack@umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,GEO,5407|8004,7433|7556,"The Polar Cyberinfrastructure Program at the National Science Foundation has the potential to transform polar research, by facilitating the transmission and integration of  tools and knowledge across the polar and cyberinfrastructure communities. Community input is essential to the process of realizing these goals, to ensure that the infrastructure investments meet the on-the-ground requirements of scientists working in each domain.  In this regard, the PI proposes to organize a workshop to identify and define priorities for how to further and enable better polar science through cyberinfrastructure.  The workshop will produce a final report to the Polar Cyberinfrastructure Program. The workshop and report will address engagement and building bridges between computer and polar sciences, what can be accomplished in the short-term (1-5 years) and long-term (5-10+ years). Topics that will be discussed include big data and data access, software tools for data and metadata acquisition, workflow support, data analysis, data visualization, and modeling, computing capabilities, interoperability with data from other domains, as well as policies and procedures that address the polar scientists? and engineers? concerns regarding, for example, data sharing, data citation, intellectual property, and career advancement. Participants from the broadest range of science domains will be engaged, including early career scientists.  The format of the workshop will be similar to those organized through the EarthCube program, with presentations and breakout sessions.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1341831,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1341831
1541800,OTHER,OTHER,"Flyover Country, a mobile app for geoscience education","Flyover Country, a mobile app for geoscience education",One organization,EAR,EDUCATION AND HUMAN RESOURCES|INSTRUMENTATION & FACILITIES|EarthCube,5/1/2015,5/26/2015,Amy Myrbo,MN,University of Minnesota-Twin Cities,44.97399,-93.227729,Standard Grant,David Lambert,10/31/2016,"$146,910.00 ",Shane Loeffler,amyrbo@umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,GEO,1575|1580|8074,7433|7916,"This award will develop a mobile app, Flyover Country (FC), that will bring information about relevant points of interest (POI) and map data to the user mid-flight, without the need for in-flight Wi-Fi, by downloading a strip of data based on the flightpath before the user boards the plane.  GPS (Global Positioning System), which functions in airplane mode, allows precise flight tracking, making prompts for POI viewing timely and relevant.  With around 4.5 million people flying every day, the potential audience for FC is huge, as is its potential for geoscience outreach. The app will directly feed high-quality geoscience information to the user at the very point when curiosity is stimulated, and could thus improve public science literacy as well as inspiring and supporting the development of a generation of geoscientists. FC could also readily be adapted for use in STEM education, and will be structured so as to provide a platform for the exposure of all types of geospatial geoscience data, forming new infrastructure for education and research.   Visualization of geoscience through combining map views, articles, audio, visual aids, and the bird's eye view from a plane window will allow for new questions, ideas, relationships, and inspiration to be cultivated by scientists and the public alike. In addition, FC may improve the current state of data accessibility and the potential for dataset integration while simultaneously increasing the incentives for improving data discovery in the geosciences and beyond.  Development of the app will be split into two main tasks: (1) the geospatial acquisition of maps and POI, which may be accomplished off the device (server-side), and (2) an on-device user interface that requests, downloads, and displays the gathered data. FC will be available for both iOS and Android devices.  In addition to supporting informal learning from the airplane window, this system has great potential to be adapted for ground level use. Similar in content and scope to the popular Roadside Geology book series, a mobile app could present relevant geoscience information on road trips or hikes, and do so even where connectivity is absent.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541800,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541800
1541043,IA,IA,EarthCube IA: Collaborative Proposal: Optimal Data Layout for Scalable Geophysical Analysis in a Data-intensive Environment,EarthCube IA: Collaborative Proposal: Optimal Data Layout for Scalable Geophysical Analysis in a Data-intensive Environment,Collaborative,ICER,EarthCube,9/1/2015,9/8/2015,Hongfeng Yu,NE,University of Nebraska-Lincoln,40.820197,-96.700476,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$332,941.00 ",,yu@cse.unl.edu,151 Prem S. Paul Research Center,Lincoln,NE,685031435,4024723171,GEO,8074,7433|9150,"Steady advance in remote sensing, satellite imaging, and computing technology has enabled scientists to study geophysical phenomena of unprecedented resolutions and complexity. Earth observation data generated from space-based satellites or ground-based radar and radiometer facilities are typically time-varying, and multivariate, and can take tera- or even peta-bytes of space to preserve and process. The common practice is to choose and transfer subsets of data from multiple data archive servers to local machines and then conduct data analysis tasks. However, this approach becomes increasingly unsustainable with an exponential growth of observation data size. It becomes an increasing severe problem that scientists can gain detailed observation data but lack suitable and scalable analysis capabilities to study the full extent of data. The team will work closely to develop, evaluate,and deploy the computer infrastructure to improve the performance and scalability of geophysical analysis for scientific discovery and education. By making the system available to other researchers, it will facilitate the development of new scalable solutions.Interactive geosciences applications will be used as an effective means to promote students interest in science and engineering studies, and to attract and retain students for geosciences community growth.  This research develops new techniques in support of scalable geophysical analysis in a data-intensive environment. The innovation and the basis of our technique approach are to develop an optimal data layout algorithm for indexing and placing massive heterogeneous observation data across distributed devices of a cluster. The new data layout is tailored to the spatial-temporal characteristics of Earth observation data, and can directly account for advanced compute techniques, including non-volatile storage resources and GPU- and Manycore-based computing nodes, and support high-throughput and high-resolution exploration of large-scale data. The long-term goal is to study theory and technology that enable scalable data management and analysis for the geosciences community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541043,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541043
1664018,"SI2, CSSI",SI2,"Collaborative Research: SI2-SSI:  Cyberinfrastructure for Advancing Hydrologic Knowledge through Collaborative Integration of Data Science, Modeling and Analysis","Collaborative Research: SI2-SSI:  Cyberinfrastructure for Advancing Hydrologic Knowledge through Collaborative Integration of Data Science, Modeling and Analysis",Collaborative,OAC,SPECIAL INITIATIVES|EAR|XC-Crosscutting Activities Pro|Software Institutes|EarthCube,10/1/2017,9/14/2017,Ray Idaszak,NC,University of North Carolina at Chapel Hill,35.904912,-79.046913,Standard Grant,Stefan Robila,9/30/2021,"$540,000.00 ",Hong Yi|Michael Stealey,rayi@email.unc.edu,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,CSE,1642|6898|7222|8004|8074,026Z|7433|8004|8009,"Researchers across the country and around the world expend tremendous resources to gather and analyze vast stores of hydrologic data and populate a myriad of models to better understand hydrologic phenomena and find solutions to vexing water problems. Each of those researchers has limited money, time, computational capacity, data storage, and ability to put that data to productive use. What if they could combine their efforts to make collaboration easier? What if those collected data sets and processed model outputs could be used collaboratively to help advance hydrologic understanding beyond their original purpose? HydroShare is a system to advance hydrologic science by enabling the scientific community to more easily and freely share products resulting from their research, not just the scientific publication summarizing a study, but also the data and models used to create the scientific publication. HydroShare supports the sharing and publication of hydrologic data and models. This capability is necessary for community model development, execution, and evaluation and to improve reproducibility and community trust in scientific findings through transparency. As a platform for collaboration and running models on advanced computational infrastructure, HydroShare enhances the capability for data intensive research in hydrology and other aligned sciences. HydroShare is designed to help researchers easily meet the sharing requirements of data management plans while at the same time providing value added functionality that makes metadata capture more effective and helps researchers improve their work productivity. This project will extend the capabilities of the HydroShare cyberinfrastructure to enhance support for scientific methods, advance the social capabilities of HydroShare to enable improved collaborative research, integrate with 3rd party consumer data storage systems to provide more flexible and sustainable data storage. and establish an application testing environment to empower researchers to develop their own computer programs to act on and work with data in HydroShare. Empowering HydroShare users with the ability to rapidly develop web application programs opens the door to unforeseen, innovative combinations of data and models. WRF-Hydro, the framework for the NOAA National Water Model, will be used as a use case for collaboration on model development. Since WRF-Hydro is used by NOAA as part of the National Water Model (NWM), this collaboration opens possibilities for transfer of research to operations. Collectively, this functionality will provide a computing framework for transforming the practice of broad science communities to leverage advances in data science and computation and accelerate discovery.  HydroShare is a system for sharing hydrologic data and models aimed at giving hydrologists the cyberinfrastructure needed to manage data, innovate and collaborate in research to solve water problems. It addresses the challenges of sharing data and hydrologic models to support collaboration and reproducible hydrologic science through the publication of hydrologic data and models. With HydroShare users can: (1) share data and models with colleagues; (2) manage who has access to shared content; (3) share, access, visualize and manipulate a broad set of hydrologic data types and models; (4) use the web services interface to program automated and client access; (5) publish data and models to meet the requirements of research project data management plans; (6) discover and access data and models published by others; and (7) use web apps to visualize, analyze, and run models on data. This project will extend the capabilities of HydroShare to: (1) enhance support for scientific methods enabling systematic data and model analysis and hypothesis testing; (2) advance the social capabilities of HydroShare to enable improved collaborative research; (3) integrate with 3rd party consumer data storage systems to provide more flexible and sustainable data storage; and (4) establish an application testing environment to empower researchers to develop their own computer programs to act on and work with data in HydroShare. Under development since 2012 and first released in 2014, HydroShare supports the sharing and publication of hydrologic data and models. This capability is necessary for community model development, execution, and evaluation. As a platform for collaboration and cloud based computation on network servers remote from the user, HydroShare enhances the capability for data intensive research in hydrology and other aligned sciences. HydroShare is innovative from a computer science and CI perspective in the way computation and data sharing are framed as a network computing platform that integrates data storage, organization, discovery, and programmable actions through web applications (web apps). Support for these three key elements of computation allows researchers to easily employ services beyond the desktop to make data storage and manipulation more reliable and scalable, while improving ability to collaborate and reproduce results. The generation of new understanding, through integration of information from multiple sources and reuse and collaborative enrichment of research data and models, will be enhanced. Structured and systematic model process intercomparisons and alternative hypothesis testing will be enabled, bringing, through user friendly CI, the latest thinking in advancing hydrologic modeling to a broad community of earth science researchers, thereby transforming research practices and the knowledge generated from this research. Interoperability with consumer cloud storage will greatly ease entry of content into HydroShare and support its sustainability. This meshing of the rigorous metadata model of HydroShare with consumer file sharing will enhance reproducibility as well as provide an innovative mechanism for sharing and collaboration. Empowering HydroShare users with the ability to rapidly develop web apps opens the door to unforeseen, innovative combinations of data and models. WRF- Hydro will be used as a use case for collaboration on model development. WRF-Hydro provides a reach-based high resolution representation of hydrologic processes, and offers the potential to bring together scientists working at scales from research catchments on the order of 1 to 100s of square kilometers as well as those working at regional to continental scales and cut across disciplines from environmental engineering to aquatic ecologists. Since WRF-Hydro is used by NOAA as part of the National Water Model (NWM), this collaboration opens possibilities for transfer of research to operations. This project will adapt current best practices in CI for interoperability and extensibility to serve this multidisciplinary community of scientists. HydroShare has already had a broader impact, with documented rapid growth in use and uptake by other projects including in EarthCube. It will become sustainable community CI through operation as part of the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI) Water Data Center (WDC) facility. The use of WRF- Hydro/NWM, as a driving use case, will advance CI for community based model improvement. Through the Summer Young Innovators Program at the National Water Center (NWC), supported by the National Weather Service (NWS) and operated by CUAHSI, a pathway already exists to translate research findings to the operational needs of federal agencies participating in the NWC. HydroShare already touches a broad and diverse community, with user base including Native American tribes, hydrologic science students, and faculty researchers across the U.S. This proposal builds on the success of HydroShare to extend its capabilities and broaden model hypothesis testing, collaborative data sharing, and open app development across earth science research and education.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664018,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664018
1239678,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,Collaborative,EAR,EarthCube,4/1/2012,3/28/2012,Reagan Moore,NC,University of North Carolina at Chapel Hill,35.904912,-79.046913,Standard Grant,Barbara L. Ransom,3/31/2013,"$61,719.00 ",,rwmoore@renci.org,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,GEO,8074,7433|7916,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239678,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239678
1639724,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Allen Glazner,NC,University of North Carolina at Chapel Hill,35.904912,-79.046913,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$151,236.00 ",,afg@unc.edu,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,GEO,8074,7433,"Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information.  The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams.  Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field.  The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return.  They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community.  The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks).  By the end of the project,  geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.  The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines.  The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in.  They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows.  The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo.  This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects.  At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists.  The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639724,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639724
1747483,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Building the Community for the Open Storage Network,Collaborative Research: Building the Community for the Open Storage Network,Collaborative,IIS,BD Spokes -Big Data Regional I|EarthCube,6/15/2018,6/7/2018,Stanley Ahalt,NC,University of North Carolina at Chapel Hill,35.904912,-79.046913,Standard Grant,Alejandro Suarez,5/31/2020,"$431,786.00 ",Lea Shanley,ahalt@renci.org,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,CSE,024Y|8074,062Z,"The scientific community is facing a major challenge dealing with the increasing amount of open scientific data emerging from research projects on all scales-- from large facilities to small research labs. Over the last five years the NSF has funded more than 200 high-speed connections to the Internet-2 backbone operating at 10-100Gbps speeds. The goal of this project is to develop a prototype module for a high performance distributed storage system that extends the usability of the existing high-speed interconnects. This project is a pilot for a potential national-scale storage infrastructure for open scientific data, which at full scale could serve hundred sites and many hundreds of Petabytes.  Many of the technologies associated with such a distributed system already exist; the key challenge in this project is social engineering: how can one design a simple enough yet robust storage node that can be easily replicated, is attractive for universities and research projects to adopt, is easy to manage and can support the various patterns for large scale scientific analyses?  Many universities have several of the necessary pieces for Data Intensive Science in place-- reasonably sized computing clusters, a few PB of storage and even a high-speed connection-- yet performing the analyses of data intensive science is very painful and slow. Data is never there when needed, large storage systems often fail despite having massive RAID configurations, and moving data from disk-to-disk at the full network speed still requires complex skills. The project offers a broad community buy-in through the Big Data Hubs, a unique combination of skills, facilities and science challenges to test, evaluate and deploy different hardware and software combinations that can be used in the design of a much larger, national-scale system. The goal is to design and run detailed benchmarks for various test science projects requiring different combinations of data transfer, data processing and massive compute, and use the results to design and build a low-cost, scalable petascale appliance including inexpensive hardware nodes and a simple software stack that can be replicated across many universities, supercomputer centers and large NSF facilities. The proposed system could become an enormous multiplier on the existing NSF investments in high end computing and fast networks. It could also accelerate the pace of standardization of data storage across the nation. The public, open data products, often discussed in the Data Management Plans at the end of NSF proposals could find an easy-to-use home. Various educational projects could simply rely upon a robust storage infrastructure with a simple API, and build a variety of delivery services for the educational community.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747483,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1747483
1339723,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,Collaborative,OAC,PHYSICAL OCEANOGRAPHY|SPECIAL PROJECTS - CISE|SPECIAL PROJECTS - CCF|Software Institutes|EarthCube,10/1/2014,8/26/2014,Richard Luettich,NC,University of North Carolina at Chapel Hill,35.904912,-79.046913,Standard Grant,Bogdan Mihaila,9/30/2019,"$759,047.00 ",,rick_luettich@unc.edu,104 AIRPORT DR STE 2200,CHAPEL HILL,NC,275991350,9199663411,CSE,1610|1714|2878|8004|8074,7433|8009,"The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography. The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339723,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339723
1450168,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,Gretchen Mullendore,ND,University of North Dakota Main Campus,47.922891,-97.076801,Standard Grant,Alan Sussman,7/31/2018,"$168,182.00 ",,gretchen@atmos.und.edu,264 Centennial Dr Stop 7306,Grand Forks,ND,582027306,7017774151,CSE,1525|8004|8074,4444|7433|8009|9150,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450168,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450168
1542052,RCN,RCN,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences,Collaborative,ICER,EarthCube,9/1/2015,8/4/2015,Jaroslaw Nabrzyski,IN,University of Notre Dame,41.705572,-86.235339,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$27,300.00 ",,naber@nd.edu,940 Grace Hall,NOTRE DAME,IN,465565708,5746317432,GEO,8074,7433,"One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs.  Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.  The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed.  This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training.  The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1542052,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1542052
1339738,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,Collaborative,OAC,PHYSICAL OCEANOGRAPHY|SPECIAL PROJECTS - CISE|SPECIAL PROJECTS - CCF|Software Institutes|EarthCube,10/1/2014,10/20/2014,Joannes Westerink,IN,University of Notre Dame,41.705572,-86.235339,Standard Grant,Bogdan Mihaila,9/30/2018,"$730,000.00 ",Tim Stitt|Damrongsak Wirasaet,jjw@nd.edu,940 Grace Hall,NOTRE DAME,IN,465565708,5746317432,CSE,1610|1714|2878|8004|8074,7433|8009,"The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography. The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339738,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339738
1541015,IA,IA,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Edward Davis,OR,University of Oregon Eugene,44.04483,-123.072606,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$70,088.00 ",,edavis@uoregon.edu,5219 UNIVERSITY OF OREGON,Eugene,OR,974035219,5413465131,GEO,8074,7433,"Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.  The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541015,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541015
1541390,RCN,RCN,EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network,EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network,Collaborative,ICER,EarthCube,8/1/2016,8/4/2016,David Sutherland,OR,University of Oregon Eugene,44.04483,-123.072606,Standard Grant,Eva Zanzerkia,7/31/2018,"$43,424.00 ",Twila Moon,dsuth@uoregon.edu,5219 UNIVERSITY OF OREGON,Eugene,OR,974035219,5413465131,GEO,8074,7433,"Greenland ice loss quadrupled over the last two decades and presently accounts for one quarter of global sea level rise. The ice loss is due to changes in surface mass balance and ice sheet dynamics associated with rising air and ocean temperatures. The associated increasing freshwater discharge is impacting the regional ocean, including its ecosystems, and has the potential to impact the large-scale North Atlantic circulation. Thus, Greenland's changes are having far-reaching consequences for global societies, yet the mechanisms responsible for these changes are not well understood. Dynamic ice loss, in particular, was likely triggered by changes at the margins of marine-terminating glaciers, through ice/ocean/atmosphere processes that are either absent or poorly represented in climate, ice sheet and ocean models. The interaction of the ocean, the glaciers and atmosphere at Greenland?s margins is a new research frontier. The complex processes involved include the coupling of multiple components of the Earth system, the challenges of obtaining and integrating diverse data from this region, and of modeling such a complex system. These challenges make this a problem that can only be addressed by bringing together multiple disciplines, including data management, collaboratively exploring diverse approaches and working across national borders. This project establishes a network to help scientists working in this area to share their data and work collaboratively.  The goal of this project is to substantially enhance multi-disciplinary activities and collaboration through the establishment of the GRISO (Greenland Ice Sheet Ocean) Science Network - an international, multidisciplinary, open network of scientists and cyberinfrastructure experts. Participants have a shared interested in advancing collective understanding of problems related to Greenland Ice Sheet change and its impact on regional and global climate. GRISO RCN activities will bring together scientists focused on all aspects of ice/ocean/atmosphere/climate data in Greenland and provide a framework for productive collaborative interaction. Specific objectives include two workshops, and a series of synthesis efforts. Additionally, a virtual data portal, leveraging existing infrastructure, will make interdisciplinary data submission and data availability easier and promote uniform and appropriate data management practices. The RCN builds on activities initiated by the former GRISO US CLIVAR Working Group and explicitly addresses priorities identified in a report from an international workshop held in 2013.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541390,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541390
1835661,"DIBBS, BIGDATA, III",DIBBS,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research,Collaborative,OAC,XC-Crosscutting Activities Pro|DATANET,1/1/2019,8/27/2018,Diego Melgar,OR,University of Oregon Eugene,44.04483,-123.072606,Standard Grant,Amy Walton,12/31/2022,"$405,494.00 ",,dmelgarm@uoregon.edu,5219 UNIVERSITY OF OREGON,Eugene,OR,974035219,5413465131,CSE,7222|7726,062Z|077Z|7925,"This project develops a real-time processing system capable of handling a large mix of sensor observations. The focus of this system is automation of the detection of natural hazard events using machine learning, as the events are occurring.  A four-organization collaboration (UNAVCO, University of Colorado, University of Oregon, and Rutgers University) develops a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  This work will support rapid analysis and understanding of data associated with hazardous events (earthquakes, volcanic eruptions, tsunamis).    This project uses a collaboration between computer scientists and geoscientists to develop a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  It focuses on the aggregation and integration of a large number of data streams into a coherent system that supports analysis of the data streams in real-time. The framework will offer machine-learning-based tools designed to detect signals of events, such as earthquakes and tsunamis, that might only be detectable when looking at a broad selection of observational inputs.  The architecture sets up a fast data pipeline by combining a group of open source components that make big data applications viable and easier to develop. Data sources for the project draw primarily upon the 1500+ sensors from the EarthScope networks currently managed by UNAVCO and the Incorporated Research Institutions for Seismology (IRIS), as well as the Ocean Observatories Initiative (OOI) cabled array data managed by Rutgers University.  Machine learning (ML) algorithms will be researched and applied to the tsunami and earthquake use cases.  Initially, the project plans to employ an advanced convolutional neural network method in a multi-data environment.  The method has only been applied to seismic waveforms, so the project will explore extending the method to a multi-data environment.  The approach is expected to be extensible beyond detection and characterization of earthquakes to include the onset of other geophysical signals such as slow-slip events or magmatic intrusion, expanding the potential for new scientific discoveries.  The framework is applied to use cases in the Cascadia subduction zone and Yellowstone: these locations combine the expertise of the science team with locations where EarthScope and OOI have the greatest concentration of instruments.  The architecture will be transportable and scalable, running in a Docker environment on laptops, local clusters and the cloud.  Integral to the project will be development, documentation and training using collaborative online resources such as GitLab and Jupyter Notebooks, and utilizing NSF XSEDE resources to make larger datasets and computational resources more widely available.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Program and Division of Earth Sciences within the NSF Directorate for Geosciences, the Big Data Science and Engineering Program within the Directorate for Computer and Information Science and Engineering, and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the Office of Advanced Cyberinfrastructure.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835661,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835661
1245067,OTHER,OTHER,Collaborative Research: From Data to Users: A Prototype Open Modeling Framework,Collaborative Research: From Data to Users: A Prototype Open Modeling Framework,Collaborative,EAR,EarthCube,7/15/2012,7/20/2012,Xu Liang,PA,University of Pittsburgh,40.444353,-79.960835,Standard Grant,Barbara Ransom,6/30/2014,"$97,487.00 ",,xuliang@pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,GEO,8074,0000|7433|7916|OTHR,"Because Earth is a complex coupled interacting system, where no one element is independent of any other, there are both pressing scientific and societal needs to improve our understanding how various physical, biological, and hydrological processes interact in surface Earth systems.  This requires the development of new and increasingly more sophisticated ways of mathematically describing these systems and improvements in software and user interfaces that will dramatically enhance our ability to simulate these systems to improve the accuracy and reliability of model predictions of weather, floods, droughts, and climate variability. Such improved models will allow researchers to make better use of available data across disciplines and improve theory and algorithms that are essential to understanding Earth system behavior. Unfortunately, at present there is significant overhead of time and effort needed for discovering, accessing, understanding, and preparing data required to populate these models, as well as long learning lead times on how to use presently available models, owing to their complexity.  This research overcomes some of these limitations by developing an innovative open modeling framework that can integrate data and models easily and is easy to use so that not only the research community and operational professionals can use it, but also policy makers and other interested parties. This EAGER award allows the construction of a prototype open meta-modeling framework that significantly reduces the time and effort on the part of users in the preparatory work for data and model comparisons, model testing and validations, for making fundamental knowledge discoveries in surface and ground water hydrological systems.  In this framework, components/modules interact via user-configured open interfaces that allow the addition and integration of hydrological models and data sources using a common meta-level architecture and scientific workflows. The proposed prototype is based on a recently completed modeling framework, HS-NWSRFS (Hydro-information System for improving the National Weather Service River Forecast System).  It represents a collaboration between investigators from three institutions, NASA, and NWS Ohio River Forecast Center (OHRFC). The funded effort will significantly expand the present code into an open community framework prototype.  Broader impacts of the work include interagency collaboration, improved hydrological forecasting for rivers, and support of a PI whose gender is under-represented in the sciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1245067,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1245067
1835785,"SI2, CSSI",SI2,Framework: Software: Collaborative Research: CyberWater--An open and sustainable framework for diverse data and model integration with provenance and access to HPC,Framework: Software: Collaborative Research: CyberWater--An open and sustainable framework for diverse data and model integration with provenance and access to HPC,Collaborative,OAC,XC-Crosscutting Activities Pro|DATANET|EarthCube,1/1/2019,9/7/2018,Xu Liang,PA,University of Pittsburgh,40.444353,-79.960835,Standard Grant,Stefan Robila,12/31/2022,"$437,232.00 ",,xuliang@pitt.edu,University Club,Pittsburgh,PA,152132303,4126247400,CSE,7222|7726|8074,062Z|077Z|7925,"This project addresses a high priority need for water research communities: interoperability among a wide variety of data sources and models, and integration of different computational models into water research communities.  The project will develop an open and sustainable software framework enabling integration of hydrologic data and models for interdisciplinary teamwork and discovery.   The models and datasets cover fields such as hydrology, biology, environmental engineering and climate.  The project also addresses one of the key issues for extreme-scale computing:  scalable file systems.  The collaboration draws upon computing, modeling, and hydrology expertise at six institutions: University of Pittsburgh, University of Iowa, Ball State University, North Carolina State University, Indiana University, and the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI).    The project develops CyberWater, a community-driven software framework that integrates a wide range of models and datasets across disparate temporal and spatial scales. The CyberWater framework allows scientists to bypass challenges associated with model and dataset complexity.  The project designs a model agent tool enabling users to generate model agents for common model types without coding, and integrates multiple existing software codes/elements that provide for broad-scale use.  To develop such a diverse modeling framework, the project brings together hydrologists, climate experts, meteorologists, computer scientists and cyberinfrastructure experts.  The project builds upon an existing prototype developed by the lead investigator;  basic elements for the system were developed, consisting of plugged-in models and data sources with corresponding agents and a workflow engine allowing user workflow control.  The prototype was successfully demonstrated for two models, making use of datasets plugged in from NASA, USGS and CUAHSI.  For the current project, new models and datasets are added to the framework; the ability to use high performance computing resources is also incorporated.  The team will use the CUAHSI HydroShare System to distribute CyberWater software and its associate model agents, including instructions on how to establish a local CyberWater environment, models and model agents. The project will enable substantial scientific advances for water related issues, and the solution can be applied to other research disciplines.   This award by the Office of Advanced Cyberinfrastructure is jointly supported by the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835785,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835785
921084,OTHER,OTHER,University-National Oceanographic Laboratory System,University-National Oceanographic Laboratory System,One organization,OCE,"ANTARCTIC INSTRUM & SUPPORT|EDUCATION/HUMAN RESOURCES,OCE|OPERATIONS SUPPORT PROGRAM|ARCTIC RESRCH SUPPRT & LOGISTI|SUBMERSIBLE SUPPORT|OCEANOGRAPHIC TECHNICAL SERVCE|SHIP ACQUISITION AND UPGRADE|OCE SPECIAL PROGRAMS|OCEAN OBSERVATORY SCI & TECH|EarthCube|||||||||||",5/1/2009,9/13/2013,Jonathan Alberts,RI,University of Rhode Island,41.486065,-71.530854,Cooperative Agreement,Bauke H. Houtman,6/30/2015,"$4,165,570.00 ",Annette DeSilva,jalberts@mail.uri.edu,RESEARCH OFFICE,KINGSTON,RI,28811967,4018742635,GEO,1647|1690|5140|5205|5412|5415|5417|5418|7398|8074|I343|I364|J383|J417|K626|KX36|L663|LX34|M539|M631|MX52,0000|1079|7556|OTHR,"The University-National Oceanographic Laboratory System (UNOLS) is a consortium of sixty-one U.S. academic institutions with research and educational programs in the ocean sciences and dedication to the major shared-use facilities that support these programs. These institutions support a broad array of facilities, which include research vessels, submersibles, remotely operated vehicles, autonomous underwater vehicles, aircraft, icebreakers, major instrumentation, and national facilities. The institution or the supporting federal agencies own these shared-use assets and it is through the UNOLS system that the community is able to access them.   The PI's request funding to host the UNOLS Office beginning in May 2009. As one of the founding institutions of UNOLS, GSO has a long tradition and deep experience with this organization and with the federal agencies that fund it. Since its inception in 1971, UNOLS has played an increasingly important role in coordinating and improving the operations of the nation's academic research fleet. Because the organization functions largely through the voluntary efforts of scientists and professionals from across the country, it is essential that the UNOLS Office be staffed by people who thoroughly understand UNOLS and are committed to its success.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=921084,https://www.nsf.gov/awardsearch/showAward?AWD_ID=921084
1339768,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: Building Sustainable Tools and Collaboration for Volcanic and Related Hazards,SI2-SSI: Collaborative Research: Building Sustainable Tools and Collaboration for Volcanic and Related Hazards,Collaborative,OAC,Software Institutes|EarthCube,10/1/2013,9/16/2013,Charles Connor,FL,University of South Florida,28.058703,-82.413854,Standard Grant,Rajiv Ramnath,9/30/2017,"$194,869.00 ",,cbconnor@usf.edu,4019 E. Fowler Avenue,Tampa,FL,336172008,8139742897,CSE,8004|8074,7433|8009,"This project is focused on creating and upgrading software infrastructure for a large community of scientists engaged in volcanology research and associated hazard analysis.  Specifically, the project will reengineer three widely used tools (TITAN2D - block and ash flows, TEPHRA and Puff - ash transport and dispersal) and develop support for workflows that use these tools to analyze risk from volcanic hazards. Reengineering will encompass modularization so researchers may easily experiment with different modeling approaches, incorporation of techniques to make the tools efficient on new computing architectures like GPUs and many-core chips. The workflows are intended to tackle the challenges of managing complex and often large data flows associated with these tools in validation processes and in probabilistic inference based on the outcomes of the modeling. The tools and workflows will be made available using the popular vhub.org platform. This project will help provide a standard well managed hardware/software platform and approaches to standardize the documentation associated with input data, source code, and output data. This will ensure that model calculations are reproducible.  The wider use of these high fidelity tools and their use in mitigating hazards is likely to have a significant effect on hazard analysis and management. The project will also engage in several major workshops and in training activities. Project personnel will also engage in the Earthcube initiative - popularizing computational methodologies, online access and dissemination mechanisms through the VHub platform.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339768,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339768
1740683,IA,IA,Collaborative Proposal: EarthCube Integration: Accelerating Scientific WorkflowS using EarthCube Technologies (ASSET),Collaborative Proposal: EarthCube Integration: Accelerating Scientific WorkflowS using EarthCube Technologies (ASSET),Collaborative,ICER,EarthCube,9/1/2017,8/17/2017,Yolanda Gil,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$110,273.00 ",,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,7433,"A major need in the geosciences is to reduce the amount of time geoscientists spend on ""data wrangling"" tasks (finding, accessing, subsetting, gridding, processing, reformatting, visualizing) so that they can spend more time on complex scientific analysis. This project will develop a means for scientists to document and interact with all of the data management and analysis tools that they need to create a scientific result, and it will add tools to find common patterns in their work to help find tools that could reduce the time needed to produce the result. This work may also help to make moethods and analyses more transparent by providing the means to track the steps in creating a scientific result.  This project builds on relationships among cyberinfrastructure experts and geoscientists examine current scientific workflows and the integration of EarthCube tools.  The work will include a workflow sketching interface to specify the steps, dependencies, current tools, current duration, and other important aspects of a scientist's workflow.  As part of the proposed pilot project, the team will examine two geoscience use cases (hurricane risk and water resources) in detail and assign cyberinfrastructure experts to integrate EarthCube tools into these science workflows, to demonstrate the increases in productivity that are realized.  In addition, the team will conduct a workshop/clinic at a major geoscience conference to collect additional use cases from the community, where geoscientists will describe their workflows and receive personalized advice on the use of EarthCube tools.  If successful, the researchers may expand on this pilot project to conduct many more workshops at other venues and to map many more scientific workflows to corresponding EarthCube technologies.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740683,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740683
1238216,WORKSHOP,WORKSHOP,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences,One organization,EAR,IIS SPECIAL PROJECTS|Software Institutes|EarthCube,4/1/2012,3/27/2012,Yolanda Gil,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Barbara L. Ransom,3/31/2013,"$55,000.00 ",Ewa Deelman,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,7484|8004|8074,7433,"EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences.  They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238216,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238216
1341418,WORKSHOP,WORKSHOP,"EarthCube Domain End-User Workshop: Engaging the Ocean Science -Omics Community to Archive, Access, and Analyze Massively Parallel Environmental Genomic Data","EarthCube Domain End-User Workshop: Engaging the Ocean Science -Omics Community to Archive, Access, and Analyze Massively Parallel Environmental Genomic Data",One organization,OCE,EarthCube,7/15/2013,7/2/2013,Katrina Edwards,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Antonius Post,6/30/2014,"$94,918.00 ",Edward DeLong|E. Virginia Armbrust|John Heidelberg,kje@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,1650|7433|9117,"Genomics, bioinformatics, and allied technologies are having wide-sweeping and dramatic impact on observation and experimentation in ocean science. ""Omics"" technologies and approaches are being rapidly adopted and employed by the ocean science research community. ""Omics"" are being broadly and effectively used in areas that include mapping the distributions of taxa and biogeography, time series analyses and biogeochemistry, regional process studies, assessing environmental change and anthropogenic impacts, and ecosystem modeling. Rapidly evolving technologies combined with exponentially decreasing costs have ""democratized"" DNA sequencing and are enabling the generation of massive ocean ""omic"" datasets by individual researchers, and collaborative efforts by the ocean science community as a whole. These massive ""omic"" datasets and their associated metadata require new cyberinfrastructures (CI) that can coordinate and facilitate data and metadata access, analyses, and modeling. The NSF EarthCube initiative recently solicited proposals for domain workshops ""designed to listen to the needs of the end-user groups that make up the geosciences and to understand better how data-enabled science can help them achieve their scientific goals."" This workshop will bring together ocean scientists and computer scientists to inform and engage them about EarthCube activities with the following objectives: 1. Inform and engage 40-45 ocean scientists with CI experience and/or needs, and explore potential Earth cube opportunities to help solve common CI challenges and needs for ocean ""omic"" data mining and analyses. 2. Inform and engage 10-15 bioinformatic and CI scientists about ocean ""omics"" needs and applications and opportunities in EarthCube activities to help address them. The overall goal of the workshop would be to develop a set of unifying CI requirements of ocean ""omic"" scientists, that could integrate their data and efforts, and connect and engage both domain and cyber scientists to pursue cyber solutions for ocean ""omics"" analyses. Intellectual Merit : The workshop will engage of a broad ""omic"" data user group in the ocean science community that stands to benefit from understanding new cyber-infrastructure possibilities, envisioning present and future solutions to their current needs and engaging in the EarthCube process. The EarthCube cyberscience community will benefit from understanding the challenges and needs of a broad, rapidly evolving, multidisciplinary group of ocean science omic and environmental data users. Broader Impacts : Cyber-infrastructure developed for ocean ""omic"" scientists have potential for broad public impact. Examples include improved infrastructures to develop more accurate climate models that incorporate biological processes, improve our understanding of the effects of environmental change, expand our knowledge of life in extreme habitats, and better assess ecosystem structure, function and dynamics.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1341418,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1341418
1533930,WORKSHOP,WORKSHOP,Workshop on Intelligent Systems Research to Support Geosciences and EarthCube Mission,Workshop on Intelligent Systems Research to Support Geosciences and EarthCube Mission,One organization,IIS,INFO INTEGRATION & INFORMATICS|ROBUST INTELLIGENCE|EarthCube,3/1/2015,3/23/2015,Yolanda Gil,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Hector Munoz-Avila,2/29/2016,"$99,999.00 ",,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7364|7495|8074,7364|7433|7495|7556,"This workshop will serve as a conduit for jump-starting synergistic research advancing our understanding of the Earth system through innovative cyber-infrastructure that pushes the envelope on information systems research. The workshop will help synthesize a vision and needs for intelligent systems research that will provide new capabilities envisioned by EarthCube to advance geosciences. The workshop will catalyze a community and research agenda in the emerging area of Discovery Informatics grounded on geoscience requirements.   Participants will discuss how to tackle problems in heterogeneous data integration and visualization (e.g., hand-made sketches, aerial imagery, field-data repositories, stakeholder interviews), ontological reasoning with scientific metadata and mathematical models (e.g., representing uncertainty, simulation predictions, evolving theories). The salient themes arising from discussions at the workshop will be articulated in detail in a final workshop report, which will be made available for the broad research community.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1533930,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1533930
1256100,OTHER,OTHER,The Role of Software and Software Institutes in Computational Science Over Time,The Role of Software and Software Institutes in Computational Science Over Time,One organization,OAC,CI-TEAM|Software Institutes,10/1/2012,9/4/2012,Ewa Deelman,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Daniel Katz,9/30/2014,"$74,430.00 ",Miron Livny,deelman@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7477|8004,7477|8005|8009,"The workshop will bring together Principle Investigators of the leading software cyberinfrastructure projects and discuss issues relevant to the community as we move into the future.  In 2011 and 2012 the OCI Software Infrastructure for Sustained Innovation (SI2) program funded software efforts in small development efforts that can provide software pieces that can be integrated into the larger cyberinfrastructure, and larger collaborations that were delivering significant community software. In addition, new SI2 awards aimed at conceptualizing large-scale software institutes, aimed at providing a fabric for the software needed by domain scientists to achieve breakthroughs in their intra and inter-disciplinary efforts, will be awarded. New NSF initiatives such as EarthCube are defining roadmaps for cyberinfrastructure development in Earth sciences. This workshop will bring together the Principle Investigators of the recent SI2 awards to discuss potential synergies and collaborations, define challenges ahead, discuss the relationship of the SI2 efforts to the planned Software Institutes, and explore the relationship of the OCI-funded software in the context of the broad NSF initiatives such as EarthCube, DataWay, and other planned community-focused efforts.  To achieve its goals, the workshop will focus on these main themes: (i) Discussing SI2 projects within the context of SI2 Institutes and NSF-wide initiative such as EarthCube, DataWay, and others; (ii) sharing experiences in building quality software and services; (iii) fostering collaboration and providing incentives for collaboration and cyberinfrastructure development as a career; and (iv) sustaining the software capabilities in the long term, defining software value.  The workshop will solicit participation from major science and engineering projects that rely on the national cyberinfrastructure for their computations and data management needs. Their participation will help ensure that the cyberinfrastructure software developed as part of SI2 projects will be relevant and broadly applicable to a number of science and engineering domains. The results of this workshop will then potentially guide cyberinfrastructure development and testing in the future.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1256100,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1256100
1440323,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences,Collaborative,ICER,EarthCube,9/1/2014,8/14/2014,Yolanda Gil,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Eva Zanzerkia,8/31/2018,"$1,048,000.00 ",Chris Mattmann,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,7433,"Geosciences software embodies crucial scientific knowledge, and as such it should be explicitly captured, curated, managed, and disseminated. The goal of this project is to create a system for software stewardship in geosciences that will empower scientists to manage their software as valuable scientific assets. Scientific software stewardship requires a combination of cyberinfrastructure, social infrastructure, and professional development infrastructure. The  framework will result in an open transparent and broader access to scientific software to other scientists, software professionals, students, and decision makers. It will significantly improve the adoption of open data and open software initiatives, improve reproducibility, and advance scientific scholarship.  The proposed research will advance knowledge and understanding of scientific software as a valuable community asset that is worth sharing, curating, cataloging, validating, reusing, and maintaining.  1) Facilitating software publication through TurboSoft, a personal assistant (analogous to TurboTax) that guides a user through best practices. Users will choose the degree of investment they are willing to make in componentizing, describing, licensing, and maintaining their software. The system will encourage open source publication, the formation of communities around the software, and set up mechanisms for software citation and credit.  2) Enabling broad software dissemination through GeoSoft, a ""software commons"" for geosciences that will support software contributions (prepared through TurboSoft or otherwise), software discovery through multi-faceted search, and foster social interactions through dynamic formation of communities of interest. GeoSoft will interoperate with existing software repositories and modeling frameworks in geosciences.  3) Providing just-in-time training materials through GeoCamp, an annotated collection of educational units ranging from basic education to professional training on all aspects of software stewardship. GeoCamp will be seamlessly integrated with TurboSoft and GeoSoft, and present a wide range of options for learning in the context of a user?s context of interaction with the framework or independently.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440323,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440323
1343800,BB,BB,EarthCube Building Blocks: Software Stewardship for the Geosciences,EarthCube Building Blocks: Software Stewardship for the Geosciences,One organization,ICER,EarthCube,9/15/2013,8/26/2015,Yolanda Gil,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Barbara L. Ransom,2/29/2016,"$315,000.00 ",Chris Mattmann|Scott Peckham|Erin Robinson|Christopher Duffy,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,7433|0000|OTHR,"Geoscience and environmental science software is crucial for data analysis and generating new knowledge and understanding about the Earth. Because reproducibility of operations, calculations, and predictions done with this software is important for science, commercial, and regulatory applications, it is important that the software generated by geoscientists and their colleagues be captured, curated, managed, and made available to all interested parties upon request. This project initiates that process by building partnerships between computer scientist, software developers, and scientists across all geoscience domains with the goal or creating a software ecosystem and a culture of software stewardship that will empower geoscientists and others to make their software accessible and manage it as a valuable scientific asset. This work will examine the possibility of creating effective on-line tools that will guide users through best practices in software use and development, including componentizing codes, describing and documenting their codes, licensing their programs, and maintaining reusable code. It will also explore the best and most effective means for training geoscientists and providing appropriate educational/training materials to dramatically improve the ability of geoscientists to more effectively develop and curate software generated by themselves, their students, and others. Broader impacts of the work include building infrastructure for science, engagement of early career professionals in both computer and geoscience, and increasing cyber sophistication of geoscience practitioners. The project supports a core team that is geographically distributed (California, Pennsylvania, and Colorado) and partners with a nation-wide consortium of academic organizations dedicated to advancing geoscience geospatial needs.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343800,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343800
1639753,BB,BB,Earthcube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web,Earthcube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web,Collaborative,ICER,POLAR CYBERINFRASTRUCTURE|EarthCube,9/1/2016,9/16/2016,Chris Mattmann,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Gregory J.  Anderson,8/31/2019,"$514,999.00 ",,mattmann@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,5407|8074,7433|8048,"This project develops an NSF EarthCube Building Block focused on Polar Data Science. The system will build upon work in Information Retrieval and Data Science and upon existing investment from NSF Polar, EarthCube, and from DARPA and NASA in this area. The system will collect, analyze, and make interactive the wealth of textual and scientific Polar data collected to date across the Deep web of scientific information -- scientific journals, multimedia information, scientific data, web pages, etc. The system builds upon fundamental research in text analysis, search, and visualization. Its primary goal is to unlock unstructured scientific data from 90+ data formats and to scale to 10s-100s of millions of records using the NSF XSEDE supercomputing resources. The system will perform information retrieval and machine learning on data crawled from the Polar Deep and Scientific web. Crawling will be informed by science questions crowdsourced through the EarthCube and Polar communities. The project is a collaboration with NSIDC, Ronin Institute, and the broader community including the newly funded Arctic Data Center led by NCEAS, to build our proposed system.  The result of periodic and regular crawling will be a Crawl Data Repository (CDR) of raw textual data e.g., web pages containing richly curated dataset abstract descriptions, news stories tied to datasets, ASCII note files and dataset descriptions, and other textual data available on or pointed to by Polar repositories as well as scientific data (HDF, Grib, NetCDF, Matlab, etc.). The CDR will be made available for historical and future analysis by the broader EarthCube and Polar communities. In addition, an extraction pipeline will generate an Extraction Data Repository (EDR) of machine learning features not previously present (geospatial, temporal, people, places, scientific publications and topics, etc.) that will be the basis of interactive, visual analytics over the Polar data resources. Information collected will assist in answering scientific questions such as these derived from the President?s National Strategy for the Arctic Region. To date, the team has also crowd sourced 30+ questions from the Polar community represented on CRYOLIST https://goo.gl/4dDyIS and will continue to solicit this feedback and use the information collected to aid science as prioritized by the community. They will also engage the community to assist in validating our system. This is not a predictive tool per-se ? though it can help to enable such predictions. Its focus is on building an operational and core capability for textual scientific data analysis, both retrospective, and prospective.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639753,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639753
1639716,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,Collaborative,ICER,EarthCube,9/1/2017,8/18/2017,Yolanda Gil,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Eva E. Zanzerkia,8/31/2020,"$60,500.00 ",,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,7433,"When viewed at the micro-scale, rocks reveal structures that help to interpret the processes and forces responsible for their formation.  These microstructures help to explain phenomena that occur at the scale of mountains and tectonic plates.  Interpretation of microstructures formed in nature during deformation is aided by comparison with those formed during experiments, under known conditions of pressure, temperature, stress, strain and strain rate, and experimental rock deformation benefits from the ground truth offered through comparison with rocks deformed in nature.  However, the ability to search for relevant naturally or experimentally deformed microstructures is hindered by the lack of any database that contains these data.  The researchers collaborating on this project will develop a single digital data system for rock microstructures to facilitate the critical interaction between and among the communities that study naturally and experimentally deformed rocks.  To aid in the comparison of microstructures formed in nature and experiment, we will link to commonly used analytical tools and develop a pilot project for automatic comparison of microstructures using machine learning.     Rock microstructures relate processes at the microscopic scale to phenomena at the outcrop, orogen, and plate scales and reveal the relationships among stress, strain, and strain rate.  Quantitative rheological information is obtained through linked studies of naturally formed microstructures with those created during rock deformation experiments under known conditions.  The project will develop a single digital data system for both naturally and experimentally deformed rock microstructure data to facilitate comparison of microstructures from different environments.  A linked data system will facilitate interaction between practitioners of experimental deformation, those studying natural deformation and the cyberscience community.  The data system will leverage the StraboSpot data system currently under development in Structural Geology and Tectonics.  To develop this system requires: 1) Modification of the StraboSpot data system to accept microstructural data from both naturally and experimentally deformed rocks; and 2) Linking the microstructural data to its geologic context ? either in nature, or its experimental data/parameters.  The researchers will engage the rock deformation community with the goal of establishing data standards and protocols for data collection, and integrate our work with ongoing efforts to establish protocols and techniques for automated metadata collection and digital data storage.  To analyze the microstructures studied and/or generated by these communities, we will ensure StraboSpot data output is compatible with commonly used microstructural tools.  They will develop a pilot project for comparing and analyzing microstructures from different environments using machine-learning.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639716,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639716
1540937,IA,IA,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,Collaborative,ICER,EarthCube,9/1/2015,7/28/2015,Yolanda Gil,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$20,000.00 ",,gil@isi.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,7433,"The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.  EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540937,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540937
1541029,IA,IA,EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology,EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology,Collaborative,ICER,EarthCube,9/1/2015,7/28/2015,Julien Emile-Geay,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$684,779.00 ",Yolanda Gil,julieneg@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,GEO,8074,7433,"Natural climate variability signficantly modulates anthropogenic global warming, and only paleoclimate observations can adequately constrain it. Moreover, such observations are most powerful when many records are brought together to provide a spatial understanding of past variability. However, there is currently no universal way to share paleoclimate data between users or machines, hindering integration and synthesis. Large-scale, international, paleoclimate data syntheses have a long and successful history, but have been needlessly labor-intensive. Recognizing that (1) paleoclimate data curation requires expert knowledge; (2) top-down data management approaches are ineffectual; (3) existing infrastructure does not foster standardization; there emerges a critical need for a flexible platform enabling crowdsourced data curation and standards development.The platform will be combined with editorial and community-driven processes which will result in a system that has the potential to engage a broad user base in geoscientific data curation. The proposed framework will lower barriers to participation in the geosciences, enabling more ""dark data"" to join the public domain using community-sanctioned protocols. The pilot project will facilitate the work of hundreds of paleoclimate scientists, accelerating scientific discovery and the dissemination of its results to society.  Semantic wikis provide a simple, intuitive interface to semantic languages and infrastructure that build on open Web architecture. Like traditional wikis, they enable the collaborative authoring of content. Secure access and time-stamped content also enable the tracking of changes and the accountability of users, as well as moderation capabilities by community members of recognized expertise. In contrast to traditional wikis, semantic wikis allow contributors to assign meaning to their content, specifying relationships between the objects they describe. This enables artificial intelligence reasoners to parse, process and translate these data into more useful forms. The technology is well-proven, scalable, and completely transparent to the user, requiring no computer science knowledge or more sophisticated technology than a web browser. The LinkedEarth Wiki will automatically translate this information into Linked Open Data, a universal format to share data across the Web. To demonstrate this concept?s broad applicability across paleoclimate science, the project?s target community is the PAGES2k consortium, an international collaboration dedicated to the climate of the Common Era. Social technologies will be developed to power collective curation, standards development and quality control by the community itself. The project will demonstrate applicability to other paleogeosciences, serving as a potential template for other geoscientific disciplines.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541029,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541029
1450451,"SI2, CSSI",SI2,SI2-SSI: Community Software for Extreme-Scale Computing in Earthquake System Science,SI2-SSI: Community Software for Extreme-Scale Computing in Earthquake System Science,One organization,OAC,GEOPHYSICS|GEOINFORMATICS|Software Institutes|EarthCube|CDS&E,9/1/2015,12/11/2018,Thomas Jordan,CA,University of Southern California,34.022352,-118.285117,Standard Grant,Micah Beck,8/31/2019,"$2,200,000.00 ",Thomas Jordan|Kim Olsen|Yifeng Cui|Ricardo Taborda|Eric Daub,tjordan@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,1574|7255|8004|8074|8084,7433|8004|8009,"The Software Environment for Integrated Seismic Modeling (SEISM) Project of the Southern California Earthquake Center (SCEC) will develop advanced earthquake simulation software capable of using high-performance computing to produce new information about earthquakes and the hazards they present. SCEC's SEISM project is developing an integrated, sustainable community software framework for earthquake system science to serve diverse communities of earthquake scientists and engineers, computer scientists, and at-risk stakeholders. The SEISM project is a collaboration among several diverse user communities with shared interests in reducing seismic risk and enhancing seismic resilience. SCEC SEISM researchers are addressing scientific problems that limit the accuracy and scale in current numerical representations of earthquake processes. SEISM computational improvements in seismic hazard calculations will benefit earthquake system science worldwide. The SCEC SEISM project will educate a diverse STEM workforce from the undergraduate to early-career level, and it will cross-train scientists and engineers in a challenging high-performance environment. As one application of SEISM, the researchers will develop new simulations for the Great California ShakeOut, which is engaging millions of people in earthquake preparedness exercises.  Earthquake simulations at the spatiotemporal scales required for probabilistic seismic hazard analysis present some of the toughest computational challenges in geoscience, requiring extreme-scale computing. The Southern California Earthquake Center is creating a Software Environment for Integrated Seismic Modeling (SEISM) that will provide the extreme-scale simulation capability needed to transform probabilistic seismic hazard analysis into a physics-based science. This project will advance SEISM through a user-driven research and development agenda that will push validated SEISM capabilities to higher seismic frequencies and towards extreme-scale computing. It will develop an integrated, sustainable community software framework for earthquake system science to serve diverse communities of earthquake scientists and engineers, computer scientists and at-risk stakeholders. A new SEISM-T framework will support both in-situ and post-hoc data processing to make efficient use of available heterogeneous architectures. The main goal of the project is to increase the 4D outer-scale/inner-scale ratio of simulations at constant time-to-solution by two orders of magnitude above current capabilities. The software development plan will use an agile process of test-driven development, continuous software integration, automated acceptance test suites for each application, frequent software releases, and attention to user feedback. The researchers will take advantage of the SCEC Implementation Interface to develop a dialog among user communities regarding the application of SEISM to the reduction of seismic risk and enhancement of seismic resilience. This research will address fundamental scientific problems that limit the accuracy and scale range in current numerical representations of earthquake processes, which will benefit earthquake system science worldwide. This project will educate a diverse STEM workforce from the undergraduate to early-career level, and it will cross-train scientists and engineers in a challenging high-performance environment. As one application of SEISM, the project team will develop new simulations for the Great California ShakeOut, which is engaging millions of people in earthquake preparedness exercises.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450451,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450451
1642611,RCN,RCN,Collaborative Proposal:  EarthCube RCN: Connecting the Earth Science and Cyberinfrastructure communities to advance the analysis of high resolution topography data,Collaborative Proposal:  EarthCube RCN: Connecting the Earth Science and Cyberinfrastructure communities to advance the analysis of high resolution topography data,Collaborative,EAR,EarthCube,8/15/2017,8/10/2017,Paola Passalacqua,TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,Dena Smith,7/31/2019,"$102,000.00 ",,paola@austin.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,GEO,8074,,"This EarthCube Research Coordination Network (RCN) will bring together communities that create and use high resolution map data, including those that conduct research on earth surface processes and those that create the technology to make these types of complex data usable. Members of this network will work to share currently available resources and best practices, and to develop new tools to make data more available to researchers. Training will focus on teaching graduate student and early career researchers to access and use high resolution map data to answer earth science research questions.   Vast quantities of High Resolution Terrain (HRT) data have been collected, with applications ranging from scientific research to commercial sector engineering. Full scientific utilization of these HRT data is still limited due to challenges associated with the storage, manipulation, processing, and analysis of these data. The cyberinfrastructure community, including computer vision, computer science, informatics, and related engineering fields are developing advanced tools for visualizing, cataloging, and classifying imagery data including point clouds. Yet, many of these tools are most applicable to engineered structures and small datasets, and not to heterogeneous landscapes. Together the earth science and cyberinfrastructure communities have the opportunity to test and validate emerging tools in challenging landscapes (e.g., heterogeneous and multiscale landforms, vegetation structures, urban footprints). In particular, this RCN will be focused on four themes: (1) coordination of the analysis of HRT data across the earth surface processes and hydrology communities to identify work-flows and best practices for data analysis; (2) identification of cyberinfrastructure tool development needs as new technologies for HRT data acquisition emerge; (3) use of HRT data for numerical models validation and integration of HRT data information in models; (4) training in HRT best practices, and data processing and analysis work-flows.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1642611,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1642611
1252324,WORKSHOP,WORKSHOP,Calling All Experimentalists: EarthCube domain end-user workshop to address community needs for sharing and managing experimental data and techniques: Year 1 Experimental stratigr,Calling All Experimentalists: EarthCube domain end-user workshop to address community needs for sharing and managing experimental data and techniques: Year 1 Experimental stratigr,One organization,EAR,EarthCube,9/1/2012,9/19/2012,Wonsuck Kim,TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,H. Richard Lane,8/31/2013,"$35,470.00 ",,delta@jsg.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,GEO,8074,7433,"CALLING ALL EXPERIMENTALISTS  A WORKSHOP TO BUILD A COMMUNITY NETWORK FOR SHARING AND MANAGING EXPERIMENTAL  DATA AND TECHNIQUES - YEAR 1: EXPERIMENTAL STRATIGRAPHY   By   Wonsuck Kim, Leslie Hsu, Raleigh Martin, and Brandon McElroy   EAR-1250525, University of Texas, Austin   ABSTRACT  Research in experimental Earth surface processes and subsurface stratal development is in a data-rich era with rapid expansion of high-resolution, digitally based data sets that were not available even a few years ago. Multiple millions of dollars have been invested into recent updates in flume laboratories for the science of surface processes and subsurface architecture. These facilities are evolving along with advanced technology and methodology to allow a greater number of more sophisticated experiments at larger scales and finer resolutions than those that could ever be achieved before. In anticipation of the need for storing vast amounts of raw and analyzed data, a coherent effort is required at the community level. PIs envision guiding development of resources to increase the utility of laboratory data beyond its original study, adding an efficient channel for collecting and sharing experimental data, and fostering greater connectivity between the experimentalist community, computer modelers, and field geologists in the context of experimental data. They intend to provide two-way communication between EarthCube and workshop participants. First, the results of this workshop will feed into the EarthCube effort by providing detailed information from disciplinary scientists. PIs will solicit data and informatics needs from the community and contribute these requirements to the EarthCube effort in the relevant discussions and groups (e.g. Data Discovery, Interop, and Semantics groups) on the EarthCube website. Second, they will serve as spokespersons for the EarthCube effort by informing their community of the current developments and needs that have been learned from attending EarthCube events (Hsu has attended the November charrette and has applied to attend the June charrette).",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252324,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1252324
1541088,IA,IA,"EarthCube IA:  Digital Rocks Portal: a Sustainable Platform for Sharing, Translation, and Analysis of Volumetric Data of Porous Media","EarthCube IA:  Digital Rocks Portal: a Sustainable Platform for Sharing, Translation, and Analysis of Volumetric Data of Porous Media",One organization,ICER,EarthCube,9/1/2015,8/25/2015,Masa Prodanovic,TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,Eva Zanzerkia,8/31/2018,"$629,065.00 ",Richard Ketcham|Maria Esteva,masha@utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,GEO,8074,7433,"Recent advances in high-resolution imaging techniques have provided a wealth of 3D datasets that reveal the microstructure of rocks and soil. It is now possible to conduct numerical experiments and construct detailed models to simulate phenomena such as fluid flow or mechanical deformation in the pore spaces of these materials. Popularly called digital rock physics, this research framework can inform important decisions in environmental, civil and petroleum engineering, as well as address key geological questions. Examples include: containing the spread of toxins or harmful bacteria in watersheds; designing safe dams; improving recovery of hydrocarbons, and understanding the history of rock formation. Researchers, however, have trouble storing and sharing these datasets due to their large sizes and the lack of standards to characterize image types and associated information about them. This impedes scientific cross-validation of the simulation approaches, and limits the development of studies that span length scales from a micrometer (a millionth of a meter, the size of individual pores and grains making up a rock) to a kilometer (the level of a geological basin or aquifer).  Studies spanning length scales are important to characterize rock and flow properties at the kilometer scale that often depend on complex processes on the micrometer scale.  This project will continue the development of a sustainable, open and easy-to-use repository called the Digital Rocks Portal (https://pep.tacc.utexas.edu/). The portal will: a) organize the images and related experimental measurements of diverse porous materials; b) improve access to porous media analysis results for a wider community of geoscience and engineering researchers not necessarily trained in computer science or data analysis; and c) enhance productivity, scientific inquiry, and engineering decisions founded on a data-driven basis. The portal will incorporate software tools and pipelines that make it easier for researchers from EarthCube and beyond to organize, publish and reuse data, and for educators to quickly visualize and illustrate concepts for a wide audience. For data sustainability and continuous access, the portal is implemented within the reliable High Performance Computing Infrastructure deployed and maintained at the Texas Advanced Computing Center (TACC) at The University of Texas at Austin, which is supported by The University of Texas System Research Cyberinfrastructure (UTRC) initiative. We will coordinate development and data integration with the High-Resolution X-ray Computed Tomography Facility at The University of Texas at Austin (UTCT), one of the largest academic imaging facilities in the nation. Finally, an important contribution will be the development of a business model for sustaining long-term preservation of important datasets obtained from research investments.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541088,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541088
1632211,RCN,RCN,EarthCube RCN IS-GEO: Intelligent Systems Research to Support Geosciences,EarthCube RCN IS-GEO: Intelligent Systems Research to Support Geosciences,One organization,ICER,ROBUST INTELLIGENCE|EarthCube,8/15/2016,8/23/2016,Suzanne Pierce,TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,Eva E. Zanzerkia,7/31/2019,"$299,998.00 ",,spierce@tacc.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,GEO,7495|8074,7433,"This project will foster collaborations between computer scientists and geoscientists that will advance research in both areas.  Geoscience problems are complex and often involve data that changes across space and time. Frequently geoscience knowledge and understanding provides valuable information and insight for problems related to energy, water, climate, agriculture, mineral resources, and our understanding of how the Earth evolves through time. Simultaneously, many grand challenges in the geosciences cannot be addressed without the aid of computational support and innovations. Intelligent and Information Systems (IS) research in computer science includes a broad range of topics and computational methods such as knowledge representation, information integration, machine learning, robotics, adaptive sensors, and intelligent interfaces. IS research has an important role to play in accelerating the speed of scientific discovery in geosciences and thus in solving challenges that cannot be addressed by other means. Similarly, many aspects of Geosciences (GEO) research pose novel large-scale problems for IS researchers to improve and validate their methods. Intelligent Systems for Geosciences (IS-GEO) represent an emerging community of interdisciplinary researchers producing fundamental new capabilities for understanding Earth systems and how the application of IS technologies can cultivate key new developments in both fields.  The EarthCube Research Coordination Network for Intelligent Systems for Geosciences (IS-GEO RCN) will catalyze collaborations to enable advances in our understanding of Earth systems through innovative applications of intelligent and information systems to fundamental geosciences problems. The goal of the IS-GEO RCN is to leverage expertise and generate interactions between both the geosciences and computing sciences communities to provide advanced scientific capabilities. To enable the network, the IS-GEO RCN will host meetings and other activities that: (1) foster an active and broad-based community across GEO and IIS areas; (2) identify barriers to research, such as terminology differences among the disciplines involved and highlight knowledge gaps that hinder collaboration across the disciplines; (3) establish and enhance communication channels between GEO and IS researchers; (4) defining grand challenges in geosciences that are well suited to IS techniques; and (5) encourage robust, long-term collaborations.  Furthermore, the educational component aims to identify new approaches to teaching students in this new interdisciplinary area, seeking to raise a new generation of scientists that are better able to apply IS methods and tools to geoscience challenges of the future. By providing avenues for IS and GEO researchers to work together the IS-GEO RCN will serve as both a point of contact, as well as an avenue for educational outreach across the disciplines for the nascent community of research and practice.   The initial efforts are focused on connecting the communities in ways that help researchers understand opportunities and challenges that can benefit from IS-GEO collaborations. The uncertain, heterogeneous and disparate nature of geoscience data paired with recent IS advances and increases in observational data offer unique opportunities for new approaches and discoveries through joint efforts. The IS-GEO RCN will jumpstart interdisciplinary research collaborations in this emerging new area so that progress across both disciplines can be accelerated.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1632211,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1632211
1343785,BB,BB,Title:   EarthCube Building Blocks: Integrating Discrete and Continuous Data,Title:   EarthCube Building Blocks: Integrating Discrete and Continuous Data,One organization,ICER,EarthCube,9/15/2013,9/10/2013,David Maidment,TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,Eva E. Zanzerkia,8/31/2016,"$899,999.00 ",Ethan Davis|Alva Couch|Daniel Ames,maidment@mail.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,GEO,8074,7433,"Geoscience information is defined on both discrete and continuous spatial domains. Discrete spatial domains include point locations of observations at measurement sites and GIS coverages of point, line and area features used for observation and data interpretation. Continuous spatial domains are used in geophysical fluid sciences such as for the atmosphere, oceans, and land subsurface to describe arrays of measured or modeled variables defined on a mesh of uniformly spaced points. Data defined on either discrete or continuous spatial domains may also vary discretely or continuously in time, ranging from one-time samples, to samples at random points of time, to samples at regularly spaced intervals of time. This project builds upon previous work called ""Crossing the Digital Divide"" focused on integrated discovery of common information themes including precipitation in discrete data from the CUAHSI hydrologic information system and continuous data from the Unidata THREDDS data server. This project will advance that work by investigating in the first year creating new technologies for publishing and discovery of information through the Global Earth Observation System of Systems (GEOSS) Common Infrastructure, the definition of a Common Information Model for discrete and continuous data, development of shard software tools for using this Common Information Model, and extension of the concepts to similar information in the Polar, Ocean and Solid Earth Sciences.  This work builds on existing NSF data infrastructures and extends them in a reasonable way between two domains, Hydrology and Atmospheric Sciences, which are closely related intellectually, but have very different data environments. Some further extension into the Polar, Ocean and Solid Earth Sciences is also attainable. The project include the engagement of an international spectrum of collaborators through the Global Earth Observing System of Systems.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343785,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343785
1263984,OTHER,OTHER,Increasing the Access to and the Relevance of Marine Seismic Data,Increasing the Access to and the Relevance of Marine Seismic Data,One organization,OCE,MARINE GEOLOGY AND GEOPHYSICS|SHIP OPERATIONS|OCEANOGRAPHIC TECHNICAL SERVCE|OCEAN DRILLING PROGRAM|EarthCube,3/1/2013,12/21/2016,"James Austin, Jr.",TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,Barbara L. Ransom,6/30/2017,"$99,947.00 ",,jamie@ig.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,GEO,1620|5411|5415|5720|8074,0000|7433|OTHR,"This workshop brings together US and non-US representatives of the marine geology and geophysics community, as well as the offshore hydrocarbon industry to discuss shared data challenges in the marine geophysics area, in particular issues surrounding the collection, processing, and availability of 3D seismic data. Workshop Goals are to review successful examples of academic and industry shared-use activities in marine geophysics and discuss lessons learned, to discuss the possibility of R/V Marcus Langseth (the NSF-owned 3D seismic research vessel) operations that could both benefit the academic and industrial sector, and to discuss a possible joint industry-academic data acquisition and data interpretation scenario. Data discovery and accessibility issues and cyberinfrastructure needs related to EarthCube, the new NSF activity to integrate and improve the computing and data management needs of the NSF Geosciences Directorate, will also be discussed and summarized in documents to be made available to the public. This meeting is designed to address problems that have a significant present and future influence on the marine geophysicsl research and the education of the next generation of marine geophysicists.  It will also explore improved sustainability of the Langseth 3-D seismic platform.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1263984,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1263984
1324760,RCN,RCN,RCN:   Building a Sediment Experimentalist Network (SEN),RCN:   Building a Sediment Experimentalist Network (SEN),One organization,EAR,GEOMORPHOLOGY & LAND USE DYNAM|SEDIMENTARY GEO & PALEOBIOLOGY|EarthCube,8/1/2013,4/13/2016,Wonsuck Kim,TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,Justin Lawrence,7/31/2018,"$440,559.00 ",Leslie Hsu|Brandon McElroy,delta@jsg.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,GEO,7458|7459|8074,,"Our dynamic landscape evolves as sediment travels a path through mountain slopes, rivers, and deltas in events like landslides, floods, and hurricanes. In nature, these processes typically occur over vast length and time scales, making them difficult to study directly.  Laboratory sedimentary experiments enable improved control and observation of these Earth-surface processes. However, such investigations often occur in isolation, and there is little if any coordination for our scientific community. We will form a Sediment Experimentalist Network (SEN) to help integrate the efforts of sediment experimentalists and build a knowledge base for guidance on best practices for data collection and management. We will also facilitate cross-institutional collaborative experiments, and communicate with and educate the research community about data and metadata standards for sediment-based experiments. This effort will improve the efficiency and transparency of sedimentary research for field geologists and modelers as well as experimentalists.  Major outcomes from SEN will be 1) creation of a Knowledge Base (SEN-KB), 2) coordination of Experimental Collaboratories (SEN-EC), and 3) integration of Educational efforts and Data standards development (SEN-ED) with tools for propagating new technology and methods. SEN-KB will be a collection of online resources for management and discovery of experimental data, metadata, analysis tools, methodologies, and other user-driven needs. SEN-EC will pilot infrastructure to foster multi-laboratory collaborations on experiments addressing broad and interdisciplinary grand challenges that are difficult to solve in a single laboratory: 1) extrapolation of experiments to natural systems and theory, 2) comparability of experimental results from disparate facilities, and 3) decoupling of external versus intrinsic processes observed in experiments. SEN-ED will provide training for data management through workshops and outreach for collecting and sharing experimental data. The project will facilitate access and use of new and existing data for a wide range of users in the experimentalist community and beyond toward modelers and field geologists.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1324760,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1324760
1339801,"SI2, CSSI",SI2,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling,Collaborative,OAC,OFFICE OF MULTIDISCIPLINARY AC|PHYSICAL OCEANOGRAPHY|SPECIAL PROJECTS - CISE|SPECIAL PROJECTS - CCF|Software Institutes|CDS&E-MSS|EarthCube,10/1/2014,2/27/2015,Clinton Dawson,TX,University of Texas at Austin,30.284919,-97.734057,Standard Grant,Bogdan Mihaila,9/30/2019,"$540,012.00 ",Craig Michoski,clint@ices.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,1253|1610|1714|2878|8004|8069|8074,7433|8009|8251,"The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography. The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339801,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1339801
1835784,"DIBBS, BIGDATA, III",DIBBS,Elements: Data: HDR: Collaborative Research: Developing an On-Demand Service Module for Mining Geophysical Properties of Sea Ice from High Spatial Resolution Imagery,Elements: Data: HDR: Collaborative Research: Developing an On-Demand Service Module for Mining Geophysical Properties of Sea Ice from High Spatial Resolution Imagery,Collaborative,OAC,POLAR CYBERINFRASTRUCTURE|DATANET,1/1/2019,8/8/2018,Hongjie Xie,TX,University of Texas at San Antonio,29.5829699,-98.6219087,Standard Grant,Amy Walton,12/31/2021,"$219,505.00 ",Alberto Mestas-Nunez,hongjie.xie@utsa.edu,One UTSA Circle,San Antonio,TX,782491644,2104584340,CSE,5407|7726,062Z|077Z|7923,"Sea ice acts as both an indicator and an amplifier of climate change. At present, there are multiple sources of  sea ice observations which are obtained from a variety of networks of sensors (in situ, airborne, and space-borne).  By developing a smart cyberinfrastructure element for the analysis of high spatial resolution (HSR) remote sensing images over sea ice, the science community is better able to extract important geophysical parameters for climate modeling. The project contributes new domain knowledge to the sea ice community.  This is accomplished by integrating HSR images that are spatiotemporally discrete to produce a more rapid and reliable identification of ice types, and by a standardized image processing that allows creating compatible sea ice products.  The cyberinfrastructure module is a value-added on-demand web service that can be naturally integrated with existing infrastructure.  The key objective is to develop a reliable and efficient on-demand Open Geospatial Consortium-compliant web service, which is capable of extracting accurate geographic knowledge of water, submerged ice, bare ice, melt ponds, deformed 'ridging' ice, ridge shadows, and other information from HSR images with limited human intervention. The embedded spatial-temporal analysis framework provides functions to search, explore, visualize, organize, and analyze the discrete HSR images and other related remote sensing data and field data. The project creates a data and knowledge web service for the Arctic sea ice community by integrating computer vision and machine learning algorithms, computing resources, and HSR image data and other useful datasets. The conceptual model improves data flow, so users would query data, download value-added data, and have more consistent results across various sources of information.  This creates new opportunities for scientific analysis that minimizes the investment of time in processing complex and spatiotemporally-discrete HSR imagery. The project includes a strong emphasis on teaching and development of the next-generation workforce through course curricula development, involvement of graduate and undergraduate students in research, and the offering of summer workshops for K-12 teachers (funded by other agencies). The collected images and results of the image analyses will be shared with the public in a timely manner through the NSF Arctic Data Center.  This award by the Office of Advanced Cyberinfrastructure is jointly supported by EarthCube and the Office of the Polar Programs Arctic Natural Sciences Program, within the NSF Directorate for Geosciences.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835784,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835784
1321479,WORKSHOP,WORKSHOP,Engaging the Sedimentary Geology Community in EarthCube (Workshop),Engaging the Sedimentary Geology Community in EarthCube (Workshop),One organization,EAR,EarthCube,2/1/2013,2/11/2013,Marjorie Chan,UT,University of Utah,40.764937,-111.842102,Standard Grant,Judith Ellen Skog,1/31/2016,"$99,947.00 ",David Budd,marjorie.chan@utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,GEO,8074,7433|9150,"A workshop is proposed to identify and articulate the cyberinfrastructure (CI) needs and potential applications in the broad scientific domain encompassing sedimentary geology. The effort is intended to build consensus within the diverse sedimentary geology community (SGC) with respect to the EarthCube effort. The SGC focuses on the processes that form, shape, and affect Earth's sedimentary crust, and distribute key resources such as hydrocarbons, coal, and water. The sedimentary records studied by this community are the archives of Earth's past surface processes, climates, oceans, and biosphere. The SGC collects a great diversity of qualitative and quantitative data that characterizes diverse attributes of sedimentary rocks at spatial scales that span 13-orders of magnitude. Most data is based on physical samples; some is continuous. Derivative products based on the data are published, but the data itself are typically not archived or readily available to other researchers.  The domain workshop will focus on: 1) defining the current nature of SGC data and workflows, including the challenges and impediments to sharing and using that data; 2) establish what types of data, repositories, software, and tools (analytical, modeling, and visualization) would enable community-based, 'big science' collaborations within the SGC; 3) evaluate the potential importance of mining legacy data; 4) identify examples of the kind of scientific challenges the SGC would attack given an ideal CI; and 5) evaluate how EarthCube, if populated with the type of data and tools articulated in the above bullets, would impact the SGC's teaching. The overall product of the workshop will be a report to NSF that defines the issues and challenges that must be met for the integration of the SGC with EarthCube.  Sedimentary rocks are the most abundant rock type on the surface of the Earth and are rich in geologic data and history. The intellectual merit of the proposal is that the summary outcomes will provide SGC guidance on the priorities and use of sedimentary data to the EarthCube framework of Earth systems.  The broader of impacts of the proposed workshop are to integrate SGC with one of the most important cyberinfrastructure initiatives to NSF integrating information and data across the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1321479,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1321479
1639682,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Marjorie Chan,UT,University of Utah,40.764937,-111.842102,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$226,000.00 ",,marjorie.chan@utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,GEO,8074,7433|9150,"Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information.  The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams.  Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field.  The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return.  They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community.  The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks).  By the end of the project,  geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.  The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines.  The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in.  They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows.  The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo.  This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects.  At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists.  The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639682,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639682
1443046,"DIBBS, BIGDATA, III",DIBBS,CIF21 DIBBs: STORM: Spatio-Temporal Online Reasoning and Management of Large Data,CIF21 DIBBs: STORM: Spatio-Temporal Online Reasoning and Management of Large Data,One organization,OAC,PHYSICAL & DYNAMIC METEOROLOGY|DATANET|EarthCube,11/1/2014,8/10/2016,Feifei Li,UT,University of Utah,40.764937,-111.842102,Standard Grant,Amy Walton,10/31/2019,"$1,173,975.00 ",John Horel|Paul Rosen|Jeff Phillips,lifeifei@cs.utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,CSE,1525|7726|8074,4444|7433|8048|9150|9251,"A fundamental challenge for many research projects is the ability to handle large quantities of heterogeneous data. Data collected from different sources and time periods can be inconsistent, or stored in different formats and data management systems. Thus, a critical step in many projects is to develop a customized query and analytical engine to translate inputs.  But for each new dataset, or for each new query type or analytic task for an existing dataset, a new query interface or program must be developed, requiring significant investments of time and effort.  This project will develop an automatic engine for searching large, heterogeneous data collections for weather and meteorology, particularly from instruments in the western US, in a regional network called MesoWest.   This project develops an automatic query and analytical engine for large, heterogeneous spatial and temporal data. This capability allows users to automatically deploy a query and analytical engine instance over their large, heterogeneous data with spatial and temporal dimensions.  The system supports a simple search-box and map-like query interface that allows numerous powerful analytical queries.  Techniques to make these queries robust, relevant, and highly scalable will be developed.  The project also enables users to execute queries over multiple data sources simultaneously and seamlessly. The goal of the work is to dramatically simplify the management and analysis of large spatio-temporal data at different institutions, groups, and corporations.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443046,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1443046
1251019,"DIBBS, BIGDATA, III",DIBBS,BIGDATA: Small: DCM: DA: Building a Mergeable and Interactive Distributed Data Layer for Big Data Summarization Systems,BIGDATA: Small: DCM: DA: Building a Mergeable and Interactive Distributed Data Layer for Big Data Summarization Systems,One organization,IIS,EarthCube|Big Data Science &Engineering,9/15/2013,4/2/2014,Feifei Li,UT,University of Utah,40.764937,-111.842102,Standard Grant,Almadena Y. Chtchelkanova,8/31/2017,"$701,386.00 ",Jeff Phillips,lifeifei@cs.utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,CSE,8074|8083,7433|7923|8083|9150|9251,"Big data today is stored in a distributed fashion across many different machines or data sources. This poses new algorithmic and system challenges to performing efficient analysis on the full data set.  To address these difficulties, the PIs are building the MIDDLE (Mergeable and Interactive Distributed Data LayEr) Summarization System and deploying it on large real-world datasets. The MIDDLE system builds and maintains a special class of summaries that can be efficiently constructed and updated while still allowing fine-grained analysis on the heavy tail. Mergeable summaries can represent any data set with a guaranteed tradeoff between size and accuracy, and any two such summaries can be merged to create a new summary with the same size-accuracy tradeoff.  Interactive summaries can be quickly adapted to a specified query range of data while maintaining the same size-accuracy tradeoffs relative to the data in that range. This allows accurate efficient analysis to zero-in on small subsets of big data. The MIDDLE system enables different big data users to develop a wide spectrum of efficient and scalable data analytic tasks through the use of data summaries. The MIDDLE system is being evaluated and refined with the aid of domain experts. Since the prospect of data-summary-based analytics becoming a part of standard techniques in processing big data is tantalizing, this research generates broader impacts on the nation's government agencies, research institutes, education system, and high-tech industries. Our broad impacts also extend to academia and community outreach, through the design and development big data curriculum and education, and the involvement of general public in understanding and using big data through concise summaries.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1251019,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1251019
1639696,BB,BB,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Jonathan Goodall,VA,University of Virginia Main Campus,38.033553,-78.507977,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$110,000.00 ",,goodall@virginia.edu,P.O.  BOX 400195,CHARLOTTESVILLE,VA,229044195,4349244270,GEO,8074,7433,"Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility.   GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639696,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639696
1745043,OTHER,OTHER,Collaborative Research: Topographic Controls on Antarctic Ice Sheet Grounding Line Behavior - Integrating Models and Observations,Collaborative Research: Topographic Controls on Antarctic Ice Sheet Grounding Line Behavior - Integrating Models and Observations,Collaborative,OPP,ANTARCTIC EARTH SCIENCES|ANTARCTIC GLACIOLOGY|EarthCube,9/1/2018,8/17/2018,Lauren Simkins,VA,University of Virginia Main Campus,38.033553,-78.507977,Standard Grant,Paul Cutler,8/31/2021,"$300,433.00 ",John Anderson,lsimkins@rice.edu,P.O.  BOX 400195,CHARLOTTESVILLE,VA,229044195,4349244270,GEO,5112|5116|8074,062Z|9150,"Current ice mass loss in Antarctica is largely driven by changes at glacier grounding lines, where inland ice transitions from being grounded to floating in the ocean. The rate and pattern of glacier retreat in these circumstances is thought to be controlled by the terrain under the ice. This project incorporates evidence of past ice-retreat events and other field data, such as grounding-line positions and dates, subglacial topography, and meltwater features, into numerical models of ice flow to investigate the influence that grounding-line processes and subglacial topography have on glacier retreat rates over the past 15,000 years.  Recent observations suggest that Antarctic ice mass loss is largely driven by perturbations at or near the grounding line. However, the lack of information on subglacial and grounding-line environments causes large uncertainties in projections of mass loss and sea-level rise. This project will integrate geologic data from the deglaciated continental shelf into numerical models of varying complexity from one to three-dimensions. Rarely do numerical ice-sheet models of Antarctica have multiple constraints on dynamics over the past ~15,000 years (a period that spans the deglaciation of the Antarctic continental shelf since the Last Glacial Maximum).  The geologic constraints include grounding-line positions, deglacial chronologies, and information on grounding line-ice shelf processes.   The models will be used to investigate necessary perturbations and controls that meet the geological constraints. The multidisciplinary approach of merging geologic reconstructions of paleo-ice behavior with numerical models of ice response will allow the research team to test understanding of subglacial controls on grounding-line dynamics and assess the stability of modern grounding lines.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1745043,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1745043
1308994,WORKSHOP,WORKSHOP,"Collaborative Research: An EarthCube Domain Workshop integrating the inland-waters biogeochemistry and fluvial sedimentology communities, April 22-24.","Collaborative Research: An EarthCube Domain Workshop integrating the inland-waters biogeochemistry and fluvial sedimentology communities, April 22-24.",Collaborative,EAR,EarthCube,4/1/2013,3/29/2013,Emilio Mayorga,WA,University of Washington,47.655335,-122.30352,Standard Grant,hailiang dong,3/31/2014,"$10,900.00 ",,mayorga@apl.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,GEO,8074,7433,"Continental surface waters represent distinct environments that are hot spots of biogeochemical storage and transformation, as well as conduits for large-scale material transport to the oceans and atmosphere. These systems are integral components of global geochemical cycles, are intertwined with human health and economic activity, and are highly sensitive to anthropogenic impacts. Without data from a wide variety of disciplines, such as organic and physical chemistry, ecosystem science, sedimentology, landscape evolution, water-rock interaction, and element and material cycles (weathering products, trace elements, carbon burial, nutrient fluxes, mineral particles, etc.), it is not possible to realistically model these important surface water systems and understand the complex interactions between their various physical and biological components. Data necessary to populate such models comes from field-based, experimental, laboratory, and theoretical work, involving short research projects, long-term research observatories, and water quality monitoring systems. The goal of this workshop is to surface requirements in the fields of river and fresh water biogeochemical studies for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~60 geoscientists from across the US who come from relevant disciplines, including cyber/computer science experts, this coallition of parties will have a job to collectively define future science goals in this important arena. It will also be used to identify the most critical, widespread needs shared by those working on surface water and fresh water biogeochemical problems and to guide the development of NSF EarthCube cyberinfrastructure for this community. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers. Discussions will encompass all aspects of experimental, in-situ, geospatial, and modeling data as well as address issues related to quantitative analytical and scaling approaches that enable the integration of observations. Workshop participants will also address topics such as process rates along flow paths ranging from short scales such as sediment-water interfaces, to continental-scale basins. Progress addressing these needs in a coordinated fashion across sub-disciplines has the potential to lead to transformative advancements in this dispersed but critical intersection of research communities. Broader impacts of the work center primarily on building infrastructure for science.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1308994,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1308994
1450412,"SI2, CSSI",SI2,"Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics","Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics",Collaborative,OAC,GEOMORPHOLOGY & LAND USE DYNAM|Software Institutes|EarthCube,8/1/2015,7/14/2015,Erkan Istanbulluoglu,WA,University of Washington,47.655335,-122.30352,Standard Grant,Stefan Robila,7/31/2020,"$676,836.00 ",,erkani@u.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7458|8004|8074,7433|8009,"Earth scientists discover and predict the behavior of the natural world in part through the use of computer models. Models are used to study a wide range of phenomena, such as soil erosion, flooding, plant growth, landslide occurrence, and many other processes. Models can be used to develop scientific understanding by comparing model calculations with the real world. They can also be used to make predictions about how nature will behave under certain conditions. In the areas of geosciences that deal with the earth's surface, one bottleneck in the development and use of models is the effort required to build, test, and debug the necessary software. This project contributes to scientific research and discovery by creating open source software tools that scientists can use to more efficiently create, modify, or combine computer models that represent portions of earth's surface and the processes occurring thereon. The project combines software development with user training and web-based resources, so that the products will be openly accessible, well documented, and widely disseminated within the relevant scientific communities. The project also contributes to K-12, undergraduate, and graduate-level education in computational modeling and earth-surface processes.  This project catalyzes research in earth-surface dynamics by developing a software framework that enables rapid creation, refinement, and reuse of two-dimensional (2D) numerical models. The phrase earth-surface dynamics refers to a remarkably diverse group of science and engineering fields that deal with our planet's surface and near-surface environment: its processes, its management, and its responses to natural and human-made perturbations. Scientists who want to use an earth-surface model often build their own unique model from the ground up, re-coding the basic building blocks of their model rather than taking advantage of codes that have already been written. Whereas the end result may be novel software programs, many person-hours are lost rewriting existing code, and the resulting software is often idiosyncratic, poorly documented, and unable to interact with other software programs in the same scientific community and beyond, leading to lost opportunities for exploring an even wider array of scientific questions than those that can be addressed using a single model. The Landlab model framework seeks to eliminate these redundancies and lost opportunities, and simultaneously lower the bar for entry into numerical modeling, by creating a user- and developer-friendly software library that provides scientists with the fundamental building blocks needed for modeling earth-surface dynamics. The framework takes advantage of the fact that nearly all surface-dynamics models share a set of common software elements, despite the wide range of processes and scales that they encompass. Providing these elements in the context of a popular scientific programming environment, with strong user support and community engagement, contributes to accelerating progress in the diverse sciences of the earth's surface.  The Landlab modeling framework is designed so that grid creation, data storage, and sharing of data among process components is done for the user. The framework is generic enough so that the coupling of two process components, whether they are squarely within a geoscience subdiscipline, or they cross subdisciplines, is the same. This architecture makes it easy to explore a wide range of questions in the geosciences without the need for much coding. Further, the model code is primarily written in Python, a language that is relatively easy for casual programmers to learn. Because of these attributes, the Landlab modeling framework has the potential to add computational modeling to the toolbox of a wide array of geoscientists, and to clear a path for trans-disciplinary earth-surface modeling that explores societally relevant topics, such as land-cover changes in response to climate change, as well as modeling of topics that currently require the coupling of sophisticated but harder-to-use models, such as sediment source-to-sink dynamics. The project will generate several proof-of-concept studies that are interesting in their own right, and demonstrate the capabilities of the modeling framework. Community engagement is fostered by presenting clinics and demonstrations at professional venues aimed at hydrologists, sedimentologists, critical zone scientists, and the broader earth and environmental sciences community. The team also supports visits by individual scientists for on-site training beyond these clinics. Input/output tools allow compatibility with data from relevant NSF-supported research. The project supports four graduate students and three postdoctoral researchers, and also includes modeling workshops for fifth to seventh grade girls in a community that has a greater than 50% minority population.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450412,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450412
1541044,IA,IA,EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science,EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science,Collaborative,ICER,EarthCube,9/1/2015,8/18/2015,Emilio Mayorga,WA,University of Washington,47.655335,-122.30352,Standard Grant,Eva Zanzerkia,8/31/2019,"$65,000.00 ",,mayorga@apl.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,GEO,8074,7433,"The Critical Zone (CZ) is the Earth's permeable near-surface layer from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. There has been a recent movement in the US Critical Zone Observatory (CZO) program to promote cross-CZO collaborations, with a major emphasis on biogeochemistry and related microbial ecology research. The project enable the CZ community to use software via training workshops, and better use CZ biogeochemistry and microbial ecology data. These objectives will be accomplished through a set of virtual and in-person workshops where CZ scientists have the opportunity to learn how to use the new cyberinfrastructure products, and use them to synthesize important biogeosciences and microbial ecology data from across numerous CZ sites. This effort will concurrently support the development of community-led standards for data collection and sharing. Direct involvement of software development teams as IA project personnel and collaborators will facilitate the training of members of the CZ community to use newly developed software. CZ scientists will then use these tools in a set of real-life use cases, in the form of synthesis of existing CZO data and analysis of collaboratively designed cross-CZO biogeochemical and metagenomic sample collection and analysis and ancillary measurements. This effort will not only train CZ scientists to use newly emerging EC CI tools, but also solicit community input on software improvements and identify remaining gaps and needs for further EarthCube CI development.  This project lays the groundwork for the whole-earth analysis and simulation capability envisioned through EarthCube, by bringing critical zone scientists together with hands-on training to test available cyberinfrastructure tools with comprehensive multiparameter datasets spanning a wide range of scales. The project will further improve access to the products of critical zone research by promoting the sharing, standardization, synthesis and analysis of biogeochemical and metagenomic data via EarthCube cyberinfrastructure, enabling a broader array of geosciences communities to shape future EarthCube activities and outcomes. This effort will support synthesis of broad swaths of data currently being collected at critical zone sites in the US and worldwide, as well as identify and fill key data gaps. The project will answer key biogeochemistry and microbial ecology questions, such as 1) measuring and modeling the fate of phosphorus during soil formation, and the relative role of bedrock vs. dust inputs to ecosystem phosphorus across diverse systems, and 2) evaluating nutrient availability and its impacts on microbial communities, growth rates and functions, across diverse systems. This project will also facilitate integrative scientific applications using critical zone data. The project will engender broad scientific dissemination of key EarthCube and Critical Zone Observatory products through targeted scientific outreach activities and engagement of diverse types of scientists, including a unique interaction between the computational science and geoscience communities. Key findings will be communicated through collaborative research and synthesis papers and presentations. This project will contribute extensive capacity-building in early-career researchers through targeted workshop participation. Finally, project findings and products will be used to inform future EarthCube development through the activity of the PIs and collaborators in the EarthCube Science Committee and Technology and Architecture Committee, as well as through the broader engagement of critical zone scientists into earthcube activities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541044,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541044
1762255,OTHER,OTHER,DYNAmics of the Madden-Julian Oscillation (DYNAMO) Legacy Data Products,DYNAmics of the Madden-Julian Oscillation (DYNAMO) Legacy Data Products,One organization,AGS,PHYSICAL & DYNAMIC METEOROLOGY|CLIMATE & LARGE-SCALE DYNAMICS|EarthCube,8/1/2017,10/16/2017,Shuyi Chen,WA,University of Washington,47.655335,-122.30352,Standard Grant,Eric DeWeaver,9/30/2018,"$295,956.00 ",,shuyic@uw.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,GEO,1525|5740|8074,4444|7433|OTHR,"This award supports the creation of a legacy dataset for data collected during the DYNAmics of the Madden-julian Oscillation (DYNAMO) field campaign. The goal of DYNAMO was to observe the initiation of the Madden-Julian Oscillation (MJO).  The MJO is a large-scale pattern of precipitation and atmospheric circulation that forms in the Indian Ocean and propagates slowly eastward affecting weather and climate across a large portion of the globe.   The campaign took place in the Indian Ocean from 1 October 2011 until 9 February 2012 and was a massive undertaking involving ships, aircraft, sounding systems, and an island-based radar ""supersite"".  Several US agencies and international partners were involved, as documented in the abstract for NSF award AGS-1022899.  The campaign was a success in that three MJO events occurred during the deployment, of which the first occurred during the Special Observing Period when all the field assets were deployed together. Overall about 10 terabytes of data were collected.  Given the success of the campaign and the large investments made in it, a further investment is warranted to enhance the accessibility of the campaign data and facilitate its used by the research community.  Three categories of data products will be developed on this award, characterized by the type of instrumentation used to collect the observations: radar-based, aircraft-based, and sounding-based products.  A fourth category consists of data products processed in ways consistent with specific interests of the research community, for instance sounding data processed into variables like precipitable water, convective available potential energy, convective inhibition, lifting condensation level, and the level of free convection.  The entire collection will be hosted by the Earth Observing Laboratory at the National Center for Atmospheric Research.  This project is somewhat unusual in that the goal is to develop and serve a dataset for the research community, rather than to conducted research to address a scientific hypothesis. Thus all of the effort can be regarded as a broader impact to the research community. It should also be noted that the MJO has a number of societal consequences, as it is a dominant driver of weather in the tropics and also affects on the US.  Among other impacts, the MJO influences the number of hurricanes that form in the Gulf of Mexico. Research leading to better representation of the MJO in weather forecasting models is thus desirable. In addition, the data products will facilitate research on tropical convection in general, which will be of value for developing better models to predict weather and make projections of future climate change.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1762255,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1762255
1835321,"SI2, CSSI",SI2,Elements: Software. icepack: an open-source glacier flow modeling library in Python,Elements: Software. icepack: an open-source glacier flow modeling library in Python,One organization,OAC,POLAR CYBERINFRASTRUCTURE|EarthCube,11/1/2018,8/15/2018,Daniel Shapero,WA,University of Washington,47.655335,-122.30352,Standard Grant,Stefan Robila,10/31/2021,"$388,314.00 ",Ian Joughin,shapero@uw.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,5407|8074,026Z|062Z|072Z|077Z|1079|7923|8004,"This project supports the development of a software package named ""icepack"", that will enable simulations of how glaciers, such as those in Greenland, Antarctica, and mountain ranges around the world, will flow in response to the environment around them. Glaciologists use software tools to run simulations so that they can make predictions of how large the Greenland and Antarctic ice sheets will be in the future. With these predictions, scientists can give policy-makers and the public better predictions on the sea level rise in the coming decades. While the ability to run simulations is essential for advancing our understanding of science, doing so requires a significant programming and scientific expertise. The goal of this project is to lower this barrier to entry. Led by an early career scientist, the team, from University of Washington will develop a tool that is easier to use for researchers and students, whether they are experts or novices. The software applications will be freely available and an open source license.  icepack allows for estimating parameters, such as a basal friction or internal rheology, that are not observable via remote sensing. Glaciologists use simulation tools like icepack for (1) exploring aspects of the physics of ice sheets that are not completely understood, (2) drawing inferences from observational data, and (3) making predictions of the future state of the ice sheets in order to estimate future sea-level rise. While modeling is an essential tool for practicing glaciologists, it is still a complex endeavor. In addition to supporting development of more features and improvements to icepack, we will create an extensive set of tutorial materials for a workshop aimed at graduate students and early-career researchers on how to use icepack. Additionally, the investigators will implement novel algorithms for parameter estimation and uncertainty quantification in icepack. These will allow the investigators to leverage the entire time series of observations of the ice sheets, while current algorithms are limited in how much data they can use, and to get a better idea of the statistical spread on estimates of the current and future states of the ice sheets.  This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Program within the NSF Directorate for Geosciences, and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the Office of Advanced Cyberinfrastructure.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835321,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835321
1740694,IA,IA,Collaborative Proposal: EarthCube Integration: Geochronology Frontier at the Laboratory-Cyberinformatics Interface,Collaborative Proposal: EarthCube Integration: Geochronology Frontier at the Laboratory-Cyberinformatics Interface,Collaborative,EAR,EarthCube,9/1/2017,7/26/2017,Bradley Singer,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Dena Smith,8/31/2020,"$1,449,662.00 ",Simon Goring|Shaun Marcott|Shanan Peters|Stephen Meyers,bsinger@geology.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"This grant supports a partnership between geochronologists who have built and run laboratory facilities that are designed to measure the ages of rocks using radioisotopic and astronomical methods, geoscientists who are building synthetic databases that depend critically on accurate and precise ages of rocks in order to test hypotheses in the Earth and life sciences, and computer scientists who are building infrastructure components that are now being used broadly in education and research. The aim is to address a 'grand challenge' in the Earth sciences: to develop a fully integrated four-dimensional digital Earth so that we may fully understand dynamic Earth system evolution through time. To meet this goal the team is developing: (1) a robust cyberinfrastructure to manage and expose data produced by multiple distributed geochronology laboratory facilities around the USA, (2) a digital mechanism to enable scientists of all types to readily discover and use geochronologic data, while at the same time keeping age estimates closely connected to geochronology lab expertise and underlying, laboratory-specific data, (3) protocols and workflows that pass geochronological data and metadata from labs to synthetic geological and paleobiological databases and data repositories, and (4) software that can harness this new geochronological infrastructure and leverage it in order to generate age models for broad swaths of rocks and thereby enable the correlation of Earth system records across a range of nested spatial and temporal scales. Institutions formally collaborating in these efforts include: University of Wisconsin-Madison, University of Arizona, Boise State University, New Mexico Institute of Mining and Technology, and University of Minnesota.  Geochronological data are central to our understanding of Earth's past and future. This collaboration between geo- and computer scientists is: (1) creating cyberinfrastructure that better leverages existing and new laboratory-generated geochronologic data, and (2) integrating this infrastructure with with synthetic databases including: Paleo Biology Data Base (https://paleobiodb.org), Neotoma Data Base (http://www.neotomadb.org), Macrostrat (https://macrostrat.org), as well as the Integrated Earth Data Alliance (IEDA) Geochron (http://www.geochron.org/) data repository using a standard that can be widely applied by others. The team's approach is unique in that it involves the parallel efforts of both the producers and consumers of geochronologic data as well as technical staff who have a working knowledge of geologic and biologic databases. The team is also well positioned to broadly serve geochronology because it engages three different geochemical/radioisotopic systems that address different geological problems and time scales. One of the overarching science goals of EarthCube is to characterize the key processes, interactions and feedbacks operating at and across different temporal and spatial scales and biological, chemical, mechanical, and physical domains. These modest, but concrete, steps allow the development of templates for distributed, laboratory cyberinfrastructure and geochronologically grounded models that can be adapted and used across Earth science communities. The aim is to share best practices and move Earth scientists towards an open, frictionless transfer of data and knowledge. The impacts of this project extend beyond the participating laboratories and collaborations and include: (1) three young geoscientists (1 PhD student and 2 Postdoctoral scholars) are gaining the cyberinformatics experience to become next generation faculty/research leaders, (2) a set of standards for distributed laboratory server operations is being created and implemented, forming the foundation for establishing a global network of lab-derived geochronological data, and (3) the GeochronAPI deployed across this network is providing a mechanism by which to integrate and synthesize geochronological data into independently developed applications, including geodiscovery-oriented Flyover Country (http://fc.umn.edu). Through workshops the team is engaging a wide spectrum of geochronologists to converge on an open standard for the GeochronAPI system, and their work with the synthetic databases highlighted above engages a large community spanning bio- and geoscience. All of the project's software, both lab-centric and external facing, is being made accessible in public GitHub repositories to encourage open, creative development.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740694,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740694
1740699,IA,IA,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative Proposal: EarthCube Integration: THROUGHPUT: Standards and Services for Community Curated Repositories,Collaborative,ICER,EarthCube,9/1/2017,9/13/2017,Simon Goring,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$179,739.00 ",John Williams,goring@wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"Data heterogeneity and accessibility are major barriers to scientific progress. Many community curated data repositories (CCDRs) have emerged in the paleogeosciences in response to the needs of their scientific communities, but these CCDRs are not well integrated. This project seeks to transform geoscientific research by breaking down the barriers among the CCDRs that serve geoscientists. All participating resources are closely engaged with their respective disciplinary communities and each is mobilizing data from its communities; the key need is to facilitate data interchange among CCDRs. The work will align several major CCDRs using a system that develops new shared services that rely on common standards, and demonstrates the kinds of new scientific insights that become possible with an integrated geoscientific infrastructure.  This collaborative project will accomplish the following: 1) A survey of existing data structures and standards, their suitability for paleogeoscience CCDRs and alignment with requirements identified by the paleogeosciences research coordination network, and their degree of adoption. This will lead to recommendations for adoption by participating resources (EarthChem, Flyover Country, IODP, LacCore/CSDCO, LinkedEarth, Neotoma) and documentation written for geoscientific audiences. 2) Alignment of participating CCDRs to recommended standards and development of a common API that will allow data exchange among CCDRs and to third-party users. 3) Development of an Annotation Engine, which will provide a credentialed, crowd-sourced system for scientists to flag changes to datasets, to connect datasets post hoc, to add context to legacy data, and to provide link-back notification among CCDRs when linked dataset attributes change. Annotation Engine will be embedded into existing scientific CCDR-based workflows, minimizing disruption to users. 4) Development of GeoNoteBase to enable scientists to generate citeable, reproducible workflows that draw information from across data resources, with workflows made available through keyword searches, with full attribution. This is a pilot effort to begin some of the work Through two pilot scientific projects, THROUGHPUT will test and evaluate these new capabilities and demonstrate kinds of new scientific insights that can be gained through integration.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740699,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740699
1343130,WORKSHOP,WORKSHOP,EarthCube domain end-user workshop:   Bringing Geochronology into the EarthCube framework,EarthCube domain end-user workshop:   Bringing Geochronology into the EarthCube framework,One organization,EAR,EarthCube,8/1/2013,7/11/2013,Bradley Singer,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Russell C. Kelz,7/31/2014,"$100,000.00 ",Shanan Peters,bsinger@geology.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"This grant supports a GEO EarthCube topical workshop with a focus on cyberinfrastructure issues germane to geological dating techniques and their digital publication.  The workshop seeks to engage approximately 70 geochronologists and geoscientists with the intent to: 1) develop a set of unifying requirements for the organization of geochronology data; and 2) explore methods for developing and sustaining an interactive community of domain and cyber-scientists to pursue next-generation solutions to the identified challenges.  The workshop will include invited talks followed by multiple breakout groups to discuss and produce draft documents focused on: 1) specific scientific challenges and opportunities in Geochronology over the next 5-15 years; 2) identification of the data and cyber-infrastructure obstacles to meeting those challenges; 3) a compilation of known community data and modeling resources; 4) description of data and cyber-capabilities required to meet challenges; and 5) development of ideas for at least two ?proof-of-concept? projects or test cases for scientifically transformative CI activities.  Nothing is more fundamental to understanding Earth history and processes than geochronology and the expense incurred in producing robust and high resolution dates implores NSF to help find a modern digital solution(s) for maintaining the integrity of these data sets and promoting access as broadly as possible in support of the advancement of the geosciences.  This workshop will help to address many of the issues that continue to hamper geochonological data curation, digital publication and community access.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343130,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343130
1343760,BB,BB,EarthCube Building Blocks:  A Cognitive Computer Infrastructure for Geoscience,EarthCube Building Blocks:  A Cognitive Computer Infrastructure for Geoscience,One organization,ICER,EarthCube,9/15/2013,9/18/2017,Christopher Re,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Eva Zanzerkia,8/31/2018,"$1,497,798.00 ",Miron Livny|Shanan Peters|Christopher Re,chrismre@cs.stanford.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"This is an era when access to information and data is often less of a problem than the ability to efficiently process and use it. In some cases, these problems are caused by massive, monolithic datasets that are difficult to store, transfer, and/or analyze. In other cases, the first-order problem is discovering and then aggregating relevant data that are widely disseminated in many different locations and formats, such as in the tables, text, and figures of published papers, government agency reports, spreadsheets, and websites. Geosciences currently lacks a cyberinfrastructure that can efficiently, cheaply, and with high precision and accuracy find, extract, and organize many different types of data that are critical to advancing science and leveraging current and past investments in data acquisition. Instead, there are dozens of isolated, sometimes redundant, geosciences data mining efforts that use humans as the primary mechanism for finding data and then keystroking them into structured databases. This mode of operation is not only costly and slow, but it is also an inefficient use of human resources and scientific expertise. This project develops a geoscience-oriented trained computing system that can serve as a cross-disciplinary tool for rapidly finding, extracting, and organizing geosciences data. Unlike traditional data processing systems, trained systems use statistical, or machine learning, techniques to provide rich answers to complex queries of data that are much less structured.   The longer-term vision is to establish an EarthCube trained computing system that can aid in finding, extracting, and aggregating data, as well as in processing, summarizing, and synthesizing them in a way that helps geoscientists to tackle new problems and better understand and model Earth systems. This project brings together a unique interdisciplinary team that is committed to building, testing, and operating an EarthCube Building Block that will bring the power of trained computing systems technologies to the broader geoscience community. Trained computing systems offer an entirely new breed of tools for data processing.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343760,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1343760
1242902,"EAGER, RAPID, INSPIRE",EAGER,EAGER Collaborative: Bringing Together Computational and Linguistic Methods to Extract 'Dark' Geosciences Data for the EarthCube Framework,EAGER Collaborative: Bringing Together Computational and Linguistic Methods to Extract 'Dark' Geosciences Data for the EarthCube Framework,Collaborative,EAR,EarthCube,7/15/2012,7/3/2012,Christopher Re,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Barbara L. Ransom,6/30/2013,"$129,380.00 ",Shanan Peters|Miron Livny,chrismre@cs.stanford.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433|0000|7916|OTHR,"A large percentage of vaulable geoscience data is based on the analysis of discrete samples and is collected manually (e.g., paleontological collections, structural/tectonic data, petrographic/mineralogic data, economic data, geochemical measurements, rock mechanics, etc.) Often, these data are reported only in tables in the published literature or in .pdf or spreadsheets on individual investigator websites. Commonly these data are not registerd on or entered into standardized, publicly accessible databases. As a result, for this data to be discovered and used/reused, researchers or other interested parties must manually comb through the text, figures, and appendices of journal articles or websites of individual investigators, sometimes having to sift through raw experimental data. This process is extremely time intensive and slows down the time needed to make scientific discoveries or allow verification of research results. As a result the vast amount of surface earth geoscience data is currently inaccessible. This inaccessible data is termed ""Dark Data"". This EAGER combines the expertise of top-notch computer scientists and geoscientists whose goal is to create a search algorithm to bring this dark data to light in a way that will enable the next generation of integrative geoscience research. The approach will involved development of an innovative search engine ""crawler"" that will comb the geoscience literature and bring dark data to light from the text and figures in this corpus. The cyberinfrastructure tool being developed will be able to interpret the semantics of English text and the concepts of geoscience. The tool will be piloted by examining entries on the Macrostrat database, a structured spatial database of lithologic and geochronologic information, and then employing a geoscience ontology by means of the Hazy framework for information extraction. Questions to be addressed will be to find out to what extent dark data is presently accessible and if it can be extracted and placed into an accessible format and repository where it can be discovered by web services or other search engines. Broader impacts of the work include training of graduate students and increasing the infrastructure for science through the development of a new and much needed data search tool.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1242902,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1242902
1440312,BB,BB,EarthCube Building Blocks: Collaborative Proposal: Digital Crust: An Exploratory Environment for Earth Science Research and Learning,EarthCube Building Blocks: Collaborative Proposal: Digital Crust: An Exploratory Environment for Earth Science Research and Learning,Collaborative,ICER,EarthCube,9/1/2014,8/8/2014,Shanan Peters,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$246,997.00 ",,peters@geology.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"This project develops the Digital Crust, an online workspace where the geosciences community can contribute data and knowledge, visualize, explore, synthesize and test multiple hypotheses across space-time and themes, and derive 4D data product from multiple data.The platform can serve as a resource to bring together geoscientists working on separate aspects of the Earth system, by bringing their data/ideas together and by providing an environment to view the Earth from different perspectives. It will also be a ""one-stop shop"" for Earth science educators to expose the growing minds to the multi-faceted nature of Earth science problems and to see data and knowledge gaps which are powerful motivators for the young (not all problems have been solved ? there is a place for me to contribute).   The Digital Crust platform prototype will demonstrate technology that has the potential to transform the way geoscientists  conduct research and learning, by (1) linking existing data repositories on all aspects of the Earth?s crust created by all disciplines of geosciences, communities as well as individuals, (2) creating a multi-context environment (e.g., tectonics, structural geology, stratigraphy, sedimentology, geomorphology, paleontology, archeology, mineralogy, geochemistry, soil science, hydrology, terrestrial ecology) at any given space (xyz) and time (t) for synthesis-type explorations, hypothesis-testing or learning, (3) allowing for multi-scale (e.g., outcrop to continent) data extractions and downloads for all research and learning applications, and (4) exposing data-knowledge gaps to identify the most rewarding future investments. Hosting multiple data types and sometimes conflicting interpretations and hypotheses of Earth processes will promote community discussion and debate on Earth processes that will foster interaction, collaboration, and data/idea sharing among scientists who might otherwise never have met. From the CI perspective, Digital Crust leverages and links with existing Building Blocks, explores the application of ""loose-schema"", noSQL databases to allow the flexibility necessary in a geoscience research database, and utilizes a modular software design to facilitate long-term maintenance and evolution of the platform.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440312,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440312
1639748,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,Collaborative,ICER,EarthCube,9/1/2017,8/18/2017,Basil Tikoff,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Eva E. Zanzerkia,8/31/2020,"$98,465.00 ",,basil@geology.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"When viewed at the micro-scale, rocks reveal structures that help to interpret the processes and forces responsible for their formation.  These microstructures help to explain phenomena that occur at the scale of mountains and tectonic plates.  Interpretation of microstructures formed in nature during deformation is aided by comparison with those formed during experiments, under known conditions of pressure, temperature, stress, strain and strain rate, and experimental rock deformation benefits from the ground truth offered through comparison with rocks deformed in nature.  However, the ability to search for relevant naturally or experimentally deformed microstructures is hindered by the lack of any database that contains these data.  The researchers collaborating on this project will develop a single digital data system for rock microstructures to facilitate the critical interaction between and among the communities that study naturally and experimentally deformed rocks.  To aid in the comparison of microstructures formed in nature and experiment, we will link to commonly used analytical tools and develop a pilot project for automatic comparison of microstructures using machine learning.     Rock microstructures relate processes at the microscopic scale to phenomena at the outcrop, orogen, and plate scales and reveal the relationships among stress, strain, and strain rate.  Quantitative rheological information is obtained through linked studies of naturally formed microstructures with those created during rock deformation experiments under known conditions.  The project will develop a single digital data system for both naturally and experimentally deformed rock microstructure data to facilitate comparison of microstructures from different environments.  A linked data system will facilitate interaction between practitioners of experimental deformation, those studying natural deformation and the cyberscience community.  The data system will leverage the StraboSpot data system currently under development in Structural Geology and Tectonics.  To develop this system requires: 1) Modification of the StraboSpot data system to accept microstructural data from both naturally and experimentally deformed rocks; and 2) Linking the microstructural data to its geologic context ? either in nature, or its experimental data/parameters.  The researchers will engage the rock deformation community with the goal of establishing data standards and protocols for data collection, and integrate our work with ongoing efforts to establish protocols and techniques for automated metadata collection and digital data storage.  To analyze the microstructures studied and/or generated by these communities, we will ensure StraboSpot data output is compatible with commonly used microstructural tools.  They will develop a pilot project for comparing and analyzing microstructures from different environments using machine-learning.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639748,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639748
1639549,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,Basil Tikoff,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$134,249.00 ",,basil@geology.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information.  The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams.  Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field.  The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return.  They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community.  The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks).  By the end of the project,  geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.  The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines.  The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in.  They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows.  The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo.  This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects.  At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists.  The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639549,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639549
1541002,IA,IA,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,John Williams,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Eva Zanzerkia,8/31/2018,"$228,770.00 ",Shanan Peters|Simon Goring,jww@geography.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,8074,7433,"Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.  The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541002,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541002
955816,"DIBBS, BIGDATA, III",DIBBS,"INTEROP--Spatial Ontology Community of Practice: an Interdisciplinary Network to Support Geospatial Data Sharing, Integration, and Interoperability","INTEROP--Spatial Ontology Community of Practice: an Interdisciplinary Network to Support Geospatial Data Sharing, Integration, and Interoperability",One organization,OAC,CYBERINFRASTRUCTURE|DATA INTEROPERABILITY NETWORKS,9/1/2010,4/1/2011,Nancy Wiegand,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Robert Chadduck,8/31/2014,"$733,142.00 ",Mike Dean|Naijun Zhou|Gary Berg-Cross|James Wilson,wiegand@cs.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,CSE,7231|7701,7701|9251,"Geospatial data, which describe location information for geographic features, are pervasive across many disciplines and fundamental for diverse applications, such as economic development, natural resources, environmental protection, and emergency response. But, re-using geospatial data remains difficult because of the heterogeneity. Although progress has been made by initiatives such as the National Spatial Data Infrastructure (NSDI) and Geospatial One-Stop to distribute data, it is now necessary to address issues of standards harmonization and agreement on the meanings of relevant concepts from diverse data sets due to the use of different community views. Semantic interoperability has been recognized as a stumbling block to collaboration needed by research communities. As a solution, well designed, formal ontologies, relying on agreements between communities on unambiguous representation of concepts and relationships for a given problem area, can be used as an analytic tool to bridge community gaps. Unfortunately, many communities lack the expertise to develop, test, and disseminate such ontologies on their own, and, further, common ontologies require agreement across a range of communities. The purpose of this Network is to create such opportunities for the geospatial community and extend the results to related communities. The Network can be considered as an umbrella over other more specific domains linked through the Network. The Network is based on an existing Spatial Ontology Community of Practice (SOCoP) network that already has a core group of active participants from academia, government, and industry.    Mechanisms for the Network include an on-line collaboration environment, a repository for geospatial ontologies with tools; educational and participatory workshops for a broad geospatial community to solicit input on use cases, smaller working group sessions on one or two chosen domains to collaborate on developing ontologies that work across use cases, and interactions with standards groups for formal publishing of ontologies, demonstrations, and research activities. The SOCoP INTEROP network will also provide training and outreach in cross-area standards, data-sharing, and information management in scientific and local communities by demonstrating the power of cooperative modeling of semantics. An educational component on geospatial ontologies will also be developed. The project will contribute to a model to incorporate semantics into the next phase of the National Spatial Data Infrastructure",https://www.nsf.gov/awardsearch/showAward?AWD_ID=955816,https://www.nsf.gov/awardsearch/showAward?AWD_ID=955816
1848899,WORKSHOP,WORKSHOP,Workshop: Developing standards and digital infrastructure for structural geology and experimental deformation,Workshop: Developing standards and digital infrastructure for structural geology and experimental deformation,One organization,ICER,NSF Public Access Initiative|EarthCube,9/1/2018,8/28/2018,Basil Tikoff,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$49,286.00 ",,basil@geology.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,GEO,7414|8074,7556,"This workshop will occur prior to the 2018 AGU Fall meeting, and will engage researchers active in the fields of natural and experimental deformation and microstructural analysis to provide input on developing data policies and data standards to improve the availability and access of research data. Participants will identify gaps in current capabilities for the community to store and discover scientific results, and ensure that standards are aligned across the field and experimental scientific communities. The workshop will bring together a diverse range of scientists from different scientific fields and from under-represented groups in STEM. A postdoctoral fellow will lead the organization of this community meeting.   This workshop is conducted to meet the goals of the EarthCube program. In addition it moves a long-tail scientific community towards Public Access of research outcomes. This work will incorporate an analysis of gaps in infrastructure for integrating microstructural data from two related (but currently largely disparate) communities, those studying naturally deformed rocks and those conducting experiments to produce deformed materials in the lab. This analysis will be focused on understanding what current data resources are currently available within each community, where the fundamental gaps are in terms data availability/discoverability in each community, and how the existing StraboSpot data system might work to provide a unified approach to data storage and discovery that can effectively serve both communities. The workshop adds value to an investment in cyberinfrastructure for a long-tail science community. The workshop will bring together a diverse community to make decisions on standards to directly improve data availability and access. The project coordinates with The European Plate Observatory System.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1848899,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1848899
1839338,"DIBBS, BIGDATA, III",DIBBS,TRIPODS+X:RES: Collaborative Research: Data Science Frontiers in Climate Science,TRIPODS+X:RES: Collaborative Research: Data Science Frontiers in Climate Science,Collaborative,DMS,TRIPODS Transdisciplinary Rese|EarthCube,10/1/2018,9/10/2018,Rebecca Willett,WI,University of Wisconsin-Madison,43.076592,-89.412487,Standard Grant,Nandini Kannan,9/30/2021,"$300,000.00 ",Stephen Wright|Garvesh Raskutti,willett@uchicago.edu,21 North Park Street,MADISON,WI,537151218,6082623822,MPS,041Y|8074,047Z|062Z,"Understanding the factors that determine regional climate variability and change is a challenge with important implications for the economy, security, and environmental sustainability of many regions around the globe. Our understanding and modeling of the large-scale dynamics of the Earth climate system and associated regional-scale climate variability significantly affects our ability to predict and mitigate climatic extremes and hazards. Earth observations and climate model outputs are witnessing an unprecedented increase in data volume, creating new opportunities to advance climate science but also leading to new data science challenges that must be addressed using tools from mathematics, statistics, and computer science. This project focuses on two central challenges at the heart of modern data-enabled climate science: (1) Increasing the predictive capacity of subseasonal forecasts by discovering and quantifying the sources of (un)predictability, including known and emergent climate modes and their interactions and non-stationarities; and (2) Understanding and quantifying the intricate space-time dynamics of the climate system to provide guidance for climate model assessment and regional forecasting.  This project brings together an interdisciplinary team that combines expertise in both hydroclimate science and statistical machine learning to create new platforms for climate diagnostics and prognostics.  The broader impacts of an enhanced knowledge of the climate system and robust and accurate seasonal forecasts have wide-ranging implications for society as a whole. For example, better seasonal forecasts will allow water resource managers to make sustainable decisions for water allocation.  This TRIPODS+CLIMATE project will develop novel machine learning and network estimation methodologies for analyzing the climate system over a range of space and time scales, to understand climate modes of variability and change and to explore their predictive ability for regional hydroclimatology. The two main objectives of this project are the following.  Objective 1: Develop novel classification and regression tools that account for highly-correlated features or covariates, nonlinear interaction terms in high-dimensional settings, and nonstationarity in climate observations. These tools will be used to improve seasonal-to-subseasonal forecasts of regional precipitation using multidimensional climate modes and feature vectors in the presence of evolving dynamics and nonstationarities. Objective 2: Develop network identification methods that leverage recent advances in machine learning and statistics and that can account for the nonstationarity and limited timeframe of climate data. The network representation will be used to analyze the structure and dynamics of the learned dependencies to contextualize and interpret them physically, and to quantify changing patterns in climate modes and their regional predictive capacity.  Emphasis will be placed on the western Pacific dynamics where an interhemispheric bi-directional connection has recently been discovered, promising earlier and more accurate seasonal-to-subseasonal forecasts in the southwestern US and other parts of the world.  This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1839338,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1839338
1450439,"SI2, CSSI",SI2,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities,Collaborative,OAC,PHYSICAL & DYNAMIC METEOROLOGY|Software Institutes|EarthCube,8/1/2015,8/4/2015,Allen Evans,WI,University of Wisconsin-Milwaukee,43.078263,-87.881969,Standard Grant,Bogdan Mihaila,7/31/2019,"$164,381.00 ",,evans36@uwm.edu,P O BOX 340,Milwaukee,WI,532010340,4142294853,CSE,1525|8004|8074,4444|7433|8009,"Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.  The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450439,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1450439
1664061,"SI2, CSSI",SI2,"Collaborative Research: SI2-SSI: Cyberinfrastructure for Advancing Hydrologic Knowledge through Collaborative Integration of Data Science, Modeling and Analysis","Collaborative Research: SI2-SSI: Cyberinfrastructure for Advancing Hydrologic Knowledge through Collaborative Integration of Data Science, Modeling and Analysis",Collaborative,OAC,HYDROLOGIC SCIENCES|SPECIAL INITIATIVES|EAR|Software Institutes|EarthCube,10/1/2017,8/23/2018,David Tarboton,UT,Utah State University,41.745161,-111.809742,Standard Grant,Stefan Robila,9/30/2021,"$2,809,998.00 ",Alva Couch|Daniel Ames|Jeffery Horsburgh|Martyn Clark,dtarb@usu.edu,Sponsored Programs Office,Logan,UT,843221415,4357971226,CSE,1579|1642|6898|8004|8074,026Z|7433|7556|8004|8009,"Researchers across the country and around the world expend tremendous resources to gather and analyze vast stores of hydrologic data and populate a myriad of models to better understand hydrologic phenomena and find solutions to vexing water problems. Each of those researchers has limited money, time, computational capacity, data storage, and ability to put that data to productive use. What if they could combine their efforts to make collaboration easier? What if those collected data sets and processed model outputs could be used collaboratively to help advance hydrologic understanding beyond their original purpose? HydroShare is a system to advance hydrologic science by enabling the scientific community to more easily and freely share products resulting from their research, not just the scientific publication summarizing a study, but also the data and models used to create the scientific publication. HydroShare supports the sharing and publication of hydrologic data and models. This capability is necessary for community model development, execution, and evaluation and to improve reproducibility and community trust in scientific findings through transparency. As a platform for collaboration and running models on advanced computational infrastructure, HydroShare enhances the capability for data intensive research in hydrology and other aligned sciences. HydroShare is designed to help researchers easily meet the sharing requirements of data management plans while at the same time providing value added functionality that makes metadata capture more effective and helps researchers improve their work productivity. This project will extend the capabilities of the HydroShare cyberinfrastructure to enhance support for scientific methods, advance the social capabilities of HydroShare to enable improved collaborative research, integrate with 3rd party consumer data storage systems to provide more flexible and sustainable data storage. and establish an application testing environment to empower researchers to develop their own computer programs to act on and work with data in HydroShare. Empowering HydroShare users with the ability to rapidly develop web application programs opens the door to unforeseen, innovative combinations of data and models. WRF-Hydro, the framework for the NOAA National Water Model, will be used as a use case for collaboration on model development. Since WRF-Hydro is used by NOAA as part of the National Water Model (NWM), this collaboration opens possibilities for transfer of research to operations. Collectively, this functionality will provide a computing framework for transforming the practice of broad science communities to leverage advances in data science and computation and accelerate discovery.  HydroShare is a system for sharing hydrologic data and models aimed at giving hydrologists the cyberinfrastructure needed to manage data, innovate and collaborate in research to solve water problems. It addresses the challenges of sharing data and hydrologic models to support collaboration and reproducible hydrologic science through the publication of hydrologic data and models. With HydroShare users can: (1) share data and models with colleagues; (2) manage who has access to shared content; (3) share, access, visualize and manipulate a broad set of hydrologic data types and models; (4) use the web services interface to program automated and client access; (5) publish data and models to meet the requirements of research project data management plans; (6) discover and access data and models published by others; and (7) use web apps to visualize, analyze, and run models on data. This project will extend the capabilities of HydroShare to: (1) enhance support for scientific methods enabling systematic data and model analysis and hypothesis testing; (2) advance the social capabilities of HydroShare to enable improved collaborative research; (3) integrate with 3rd party consumer data storage systems to provide more flexible and sustainable data storage; and (4) establish an application testing environment to empower researchers to develop their own computer programs to act on and work with data in HydroShare. Under development since 2012 and first released in 2014, HydroShare supports the sharing and publication of hydrologic data and models. This capability is necessary for community model development, execution, and evaluation. As a platform for collaboration and cloud based computation on network servers remote from the user, HydroShare enhances the capability for data intensive research in hydrology and other aligned sciences. HydroShare is innovative from a computer science and CI perspective in the way computation and data sharing are framed as a network computing platform that integrates data storage, organization, discovery, and programmable actions through web applications (web apps). Support for these three key elements of computation allows researchers to easily employ services beyond the desktop to make data storage and manipulation more reliable and scalable, while improving ability to collaborate and reproduce results. The generation of new understanding, through integration of information from multiple sources and reuse and collaborative enrichment of research data and models, will be enhanced. Structured and systematic model process intercomparisons and alternative hypothesis testing will be enabled, bringing, through user friendly CI, the latest thinking in advancing hydrologic modeling to a broad community of earth science researchers, thereby transforming research practices and the knowledge generated from this research. Interoperability with consumer cloud storage will greatly ease entry of content into HydroShare and support its sustainability. This meshing of the rigorous metadata model of HydroShare with consumer file sharing will enhance reproducibility as well as provide an innovative mechanism for sharing and collaboration. Empowering HydroShare users with the ability to rapidly develop web apps opens the door to unforeseen, innovative combinations of data and models. WRF- Hydro will be used as a use case for collaboration on model development. WRF-Hydro provides a reach-based high resolution representation of hydrologic processes, and offers the potential to bring together scientists working at scales from research catchments on the order of 1 to 100s of square kilometers as well as those working at regional to continental scales and cut across disciplines from environmental engineering to aquatic ecologists. Since WRF-Hydro is used by NOAA as part of the National Water Model (NWM), this collaboration opens possibilities for transfer of research to operations. This project will adapt current best practices in CI for interoperability and extensibility to serve this multidisciplinary community of scientists. HydroShare has already had a broader impact, with documented rapid growth in use and uptake by other projects including in EarthCube. It will become sustainable community CI through operation as part of the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI) Water Data Center (WDC) facility. The use of WRF- Hydro/NWM, as a driving use case, will advance CI for community based model improvement. Through the Summer Young Innovators Program at the National Water Center (NWC), supported by the National Weather Service (NWS) and operated by CUAHSI, a pathway already exists to translate research findings to the operational needs of federal agencies participating in the NWC. HydroShare already touches a broad and diverse community, with user base including Native American tribes, hydrologic science students, and faculty researchers across the U.S. This proposal builds on the success of HydroShare to extend its capabilities and broaden model hypothesis testing, collaborative data sharing, and open app development across earth science research and education.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664061,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1664061
1239632,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,Collaborative,EAR,EarthCube,4/1/2012,3/28/2012,Jeffery Horsburgh,UT,Utah State University,41.745161,-111.809742,Standard Grant,Barbara L. Ransom,3/31/2013,"$18,000.00 ",,jeff.horsburgh@usu.edu,Sponsored Programs Office,Logan,UT,843221415,4357971226,GEO,8074,7433|7916|9150,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239632,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239632
1639655,BB,BB,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications,Collaborative,ICER,EarthCube,9/1/2016,9/16/2016,David Tarboton,UT,Utah State University,41.745161,-111.809742,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$140,000.00 ",Anthony Castronova,dtarb@usu.edu,Sponsored Programs Office,Logan,UT,843221415,4357971226,GEO,8074,7433|9150,"Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility.   GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639655,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639655
1224638,OTHER,OTHER,Developing a Community Information Model and Supporting Software to Extend Interoperability of Sensor and Sample Based Earth Observations,Developing a Community Information Model and Supporting Software to Extend Interoperability of Sensor and Sample Based Earth Observations,One organization,EAR,HYDROLOGIC SCIENCES|GEOINFORMATICS|CZO: CRITICAL ZONE OBSER SOLIC,8/1/2012,8/1/2013,Jeffery Horsburgh,UT,Utah State University,41.745161,-111.809742,Continuing grant,Russell C. Kelz,7/31/2015,"$551,176.00 ",Ilya Zaslavsky|Kerstin Lehnert|Anthony Aufdenkampe|Emilio Mayorga,jeff.horsburgh@usu.edu,Sponsored Programs Office,Logan,UT,843221415,4357971226,GEO,1579|7255|7693,9150,"This EAR Geoinformatics Program grant supports a two year project to develop a community information model and related software to enable web based interoperability of earth observations derived from sensors and samples that span now discrete data and informatics initiatives for multiple communities.  The system would target specific existing web service data repositories in order to demonstrate how the information model can support federation of earth observations data across multiple data publication systems.  Specific repositories include the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI) Hydrologic Information System (HIS), EarthChem, the Critical Zone Observatory (CZO) Integrated Data Management System (CZOData), the Integrated Ocean Observing System (IOOS) and the Data Observations Network for Earth (DataONE).  The plan calls for collaboration with the related Pis of these projects (through subward support) to improve capture, sharing, and archival these data and associated metadata by building ontologies for describing, encoding and publishing data in common formats to allow interoperability.   The plan involves community workshops to engage stakeholders and students in the design of the model.  The model would incorporate international standards for data description and publishing utilizing Open Geospataial Consortium standards and domain specific markup languages.  It is hoped that the results will feed directly into the larger EarthCube cyberinfrastructure initiative.      ***",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1224638,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1224638
1740704,IA,IA,Collaborative Research: EarthCube Integration--Brokered Alignment of Long-Tail Observations (BALTO),Collaborative Research: EarthCube Integration--Brokered Alignment of Long-Tail Observations (BALTO),Collaborative,AGS,EarthCube,9/15/2017,9/15/2017,Dorothy Stamps,VA,Virginia Polytechnic Institute and State University,37.228384,-80.423417,Standard Grant,Subhashree Misha,8/31/2020,"$572,342.00 ",Zachary Easton|Daniel Fuka,dstamps@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,GEO,8074,7433,"This project, Brokered Alignment for Long-Tail Observations (BALTO), is supported under the EarthCube program.  The development team seeks to build a tool and infrastructure to allow the community to easily submit long-tail observational data that cannot easily fit into existing data repositories.  A data brokering technique will be developed to accomplish the goals of the study.  Graduate students, including from underrepresented minority groups, will receive training opportunities via this project.   To facilitate access to long-tail observations this work seeks to develop a core capability for the future EarthCube (EC) architecture in the Architecture and Implementation Plan - Brokered Alignment for Long-Tail Observations (BALTO). BALTO entails an open-source interface to discover, access and transform geoscience data sources through a brokering solution implemented by user-developed accessors. BALTO integrates core attributes of successful prior EC Building Blocks, BCube and ODSIP, to create a next generation EC capability. Leveraging its large installed base and its open-source flexibility, BALTO will extend Hyrax OPeNDAP's data server for ODSIP with capabilities for distributed brokering. Results from this project will demonstrate improved access and its impacts on scientific discovery via three NSF funded interdisciplinary use-cases that span geodesy, seismology, hydrology, oceanography, and geodynamics.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740704,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1740704
1238438,WORKSHOP,WORKSHOP,Collaborative workshop proposal: Drawing the roadmap for the semantic/ontology based infrastructure for Geosciences,Collaborative workshop proposal: Drawing the roadmap for the semantic/ontology based infrastructure for Geosciences,Collaborative,EAR,EarthCube,4/1/2012,3/27/2012,Akhaury Sinha,VA,Virginia Polytechnic Institute and State University,37.228384,-80.423417,Standard Grant,Barbara L. Ransom,3/31/2014,"$89,924.00 ",,pitlab@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,GEO,8074,7433,"EarthCube is focused on community-driven development of an integrated, and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This award funds a series of broad community interactions to gather adequate information and requirements to create a roadmap for a critical cyberinfrastructure capability (semantics and ontologies) in the development of EarthCube. In the context of cyberinfrastructure, semantics and ontologies are what allows heterogeneous and distributed data systems to become interoperable. They enable scientists to register, discover, access, and integrate data irrespective of its structural heterogeneity. This work convenes public, online/virtual meetings and seeks broad community input in the development of a process to have the geoscience and cyberinfrastructure communities converge on a way forward in the realm of semantics and ontologies for data, with the end product being a capability implementation roadmap. Also involved in the process is the identification of appropriate community agreed upon use cases. Broader impacts of the work include development of approaches, protocols, and standards that may be applicable across the sciences and the fostering of close interaction between communities that do not commonly interact, to a great extent, with one another moving them toward a common goal of the creation of a new paradigm in data and knowledge management in the geosciences.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238438,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1238438
1639554,BB,BB,EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS),Collaborative,ICER,EarthCube,9/1/2016,9/1/2016,Dorothy Stamps,VA,Virginia Polytechnic Institute and State University,37.228384,-80.423417,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$87,811.00 ",,dstamps@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,GEO,8074,7433,"While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.  CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639554,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639554
1541007,IA,IA,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory,Collaborative,ICER,EarthCube,9/1/2015,7/28/2015,J. Michael Ruohoniemi,VA,Virginia Polytechnic Institute and State University,37.228384,-80.423417,Standard Grant,Eva Zanzerkia,8/31/2018,"$72,116.00 ",,mikeruo@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,GEO,8074,7433,"The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.  EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541007,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541007
1639641,DI,DI,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,EarthCube Data Infrastructure: Collaborative Proposal: A unified experimental-natural digital data system for analysis of rock microstructures,Collaborative,ICER,EarthCube,9/1/2017,8/18/2017,Philip Skemer,MO,Washington University,38.64879,-90.310796,Standard Grant,Eva E. Zanzerkia,8/31/2020,"$126,336.00 ",,pskemer@wustl.edu,CAMPUS BOX 1054,Saint Louis,MO,631304862,3147474134,GEO,8074,7433|9150,"When viewed at the micro-scale, rocks reveal structures that help to interpret the processes and forces responsible for their formation.  These microstructures help to explain phenomena that occur at the scale of mountains and tectonic plates.  Interpretation of microstructures formed in nature during deformation is aided by comparison with those formed during experiments, under known conditions of pressure, temperature, stress, strain and strain rate, and experimental rock deformation benefits from the ground truth offered through comparison with rocks deformed in nature.  However, the ability to search for relevant naturally or experimentally deformed microstructures is hindered by the lack of any database that contains these data.  The researchers collaborating on this project will develop a single digital data system for rock microstructures to facilitate the critical interaction between and among the communities that study naturally and experimentally deformed rocks.  To aid in the comparison of microstructures formed in nature and experiment, we will link to commonly used analytical tools and develop a pilot project for automatic comparison of microstructures using machine learning.     Rock microstructures relate processes at the microscopic scale to phenomena at the outcrop, orogen, and plate scales and reveal the relationships among stress, strain, and strain rate.  Quantitative rheological information is obtained through linked studies of naturally formed microstructures with those created during rock deformation experiments under known conditions.  The project will develop a single digital data system for both naturally and experimentally deformed rock microstructure data to facilitate comparison of microstructures from different environments.  A linked data system will facilitate interaction between practitioners of experimental deformation, those studying natural deformation and the cyberscience community.  The data system will leverage the StraboSpot data system currently under development in Structural Geology and Tectonics.  To develop this system requires: 1) Modification of the StraboSpot data system to accept microstructural data from both naturally and experimentally deformed rocks; and 2) Linking the microstructural data to its geologic context ? either in nature, or its experimental data/parameters.  The researchers will engage the rock deformation community with the goal of establishing data standards and protocols for data collection, and integrate our work with ongoing efforts to establish protocols and techniques for automated metadata collection and digital data storage.  To analyze the microstructures studied and/or generated by these communities, we will ensure StraboSpot data output is compatible with commonly used microstructural tools.  They will develop a pilot project for comparing and analyzing microstructures from different environments using machine-learning.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639641,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639641
1338892,WORKSHOP,WORKSHOP,EarthCube GEO Domain Workshop:   Articulating Cyberinfrastructure Needs of the Ocean Ecosystem Dynamics Community,EarthCube GEO Domain Workshop:   Articulating Cyberinfrastructure Needs of the Ocean Ecosystem Dynamics Community,One organization,OCE,EarthCube,4/15/2013,4/10/2013,Danie Kinkade,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Barbara L. Ransom,3/31/2015,"$97,114.00 ",Peter Wiebe|Robert Groman|David Glover|Cynthia Chandler,dkinkade@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,0000|7433|OTHR,"Ocean ecosystem dynamics encompasses a broad array of disciplines that seek to increase our understanding of the interplay between the physical, biological, and chemical processes in the ocean.  Ocean ecosystem dynamics studies include ocean productivity, population dynamics, biogeography, and biogeochemistry. It is an interdisciplinary science that produces highly diverse data types that pose unique challenges for data management, integration, and analysis. The goal of this workshop is to surface requirements in this important ocean science arena for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~50 ocean water column scientists to identify science drivers in the next 15 years in the ocean ecosystem dynamics field and inform the EarthCube process about the data and cyberinfrastructure needs of the associated scientific community. Issues of different scales in time and space of both data and modeling efforts will be discussed in reference to oceans, coastal waters, and the Great Lakes.  The workshop will also include cyber/computer science experts; and together workshop participants will collectively define future science goals and focus on identifying the most critical, widespread, cyberinfrastructure and data management issues and problems holding back scientific advances in the area of ocean ecosystem dynamics. Workshop participants will also discuss needs in software and visualization that are needed to better understand and model both present and new data.  Broader impacts of the work include building infrastructure for science by identifying needs that will help to shape the final form of EarthCube cyberinfrastructure, support of two PIs whose gender is under-represented in the sciences and engineering, and engagement of early career scientists. A virtual component of the workshop will be held to help broaden participation beyond those present on-site.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338892,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1338892
1354107,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,Collaborative,ICER,EarthCube,9/15/2013,8/12/2013,Cynthia Chandler,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Barbara L. Ransom,8/31/2015,"$74,993.00 ",,cchandler@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7916|0000|OTHR,"This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures. It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed. Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details. Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354107,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354107
1239702,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities,Collaborative,EAR,EarthCube,4/1/2012,3/28/2012,Janet Fredericks,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Barbara L. Ransom,3/31/2013,"$26,895.00 ",,jfredericks@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7433|7916,"This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239702,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1239702
1440114,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,Collaborative,ICER,EarthCube,9/1/2014,5/21/2017,Cynthia Chandler,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$286,780.00 ",,cchandler@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7433,"The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.  A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440114,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440114
1639714,DI,DI,EarthCube Data Infrastructure: Laying the Groundwork for an Ocean Protein Portal,EarthCube Data Infrastructure: Laying the Groundwork for an Ocean Protein Portal,One organization,ICER,EarthCube,9/1/2016,8/31/2016,Mak Saito,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Eva Zanzerkia,8/31/2019,"$499,595.00 ",Danie Kinkade,msaito@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7433,"The measurement of the biological inventory of proteins within an organism, known as proteomics, has emerged as an important new biological methodology within the past decade. When this new technology is applied to environmental communities of microbes, typically called metaproteomics for its inclusion of a biological community, it has shown potential to significantly improve the understanding of ocean ecology and biogeochemistry by allowing a broad diagnosis of ecosystems across space and time. In this manner the measurement of proteins and the enzymes that catalyze throughout the ocean basins has great potential as a tool for ocean scientists interested in the chemistry and biology of the oceans. Yet being a relatively new data type, based in mass spectra rather than DNA sequence, proteomic datasets have their own specific informatics complexities. Currently these datasets are not easily accessed by the broader biological and chemical oceanographic communities. The researchers will develop an Ocean Protein Portal that will enable non-expert users to interrogate these large and complex ocean protein datasets.  The ability to connect protein distributions in the oceans, with their implied chemical functionality, with chemical and biological ocean datasets has the potential to enable a broad array of microbial and biogeochemical discovery.The proposed cyberinfrastructure will benefit the broader biological and chemical oceanographic communities through making microbial protein data widely accessible and enabling connections between biogeochemical data and the enzymes that catalyze their reactions. This foundational infrastructure would be accessible to life scientists from other (non-ocean) domains as well. The portal will also contribute to the interpretation of GEOTRACES trace metal and isotope ocean full depth ocean via the incorporation of future protein datasets and linkages to the chemical datasets in BCO-DMO. This project will provide BCO-DMO with an opportunity to research and employ new techniques for efficient data mining combined with semantic technologies that will enable better data discovery and access for its community. In addition, working closely with the proteomics community will allow BCO-DMO data managers to gain working experience with this emerging data type.Specific goals include: 1) creating text-based and sequence-based search capability of processed protein datasets, 2) creating a geospatial global map visualization as well as table output of the query protein?s occurrence in the oceans, 3) providing an Ocean Data View compatible table export of geospatial and temporal distributions of the queried protein, 4) providing an analytic capability to answer the question the taxonomic origin of the protein components, building on our METATRYP Python software and including a lowest common ancestor analysis for each peptide component of the queried protein sequence, 5) creating linkages between protein datasets and relevant environmental datasets within BCO-DMO, and 6) creating a repository for processed and raw ocean protein data.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639714,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639714
1639557,BB,BB,EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub,EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub,Collaborative,ICER,EarthCube,9/1/2016,9/14/2016,Bernhard Peucker-Ehrenbrink,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Eva E. Zanzerkia,8/31/2019,"$76,502.00 ",,behrenbrink@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7433,"Making data discovery more efficient, comprehensive and user-friendly is a critical challenge articulated by geoscientists as well as researchers in other fields. While information discovery portals and search engines have been developed for many data repositories, and systems that simultaneously search multiple resources have been created, cross-disciplinary data discovery remains a serious issue. It becomes especially acute with rapid increases in the volume and diversity of observations, reflecting different components of the Earth System and collected by multiple research groups, government organizations and commercial companies. The main goal of the EarthCube Data Discovery Hub project is to greatly reduce the time and effort necessary to locate and evaluate geoscience information resources across disciplines, and increase the value of investment in data generation by promoting data reuse and reducing duplication of effort. Project outcomes will benefit a wide group of scientists by providing them a user-friendly and powerful gateway to information resources across multiple data facilities and community contributions, and mechanisms for improving the system to answer their research queries in a consistent manner. The project will also benefit geoscience research in several ecosystems that are being used as examples to test the data tools being developed, including rivers, coral reefs and other marine ecosystems, and the critical zone where rock, soil, water, air and living organisms interact. The EarthCube Data Discovery Hub will be developed as a comprehensive data discovery and content enhancement system, which will leverage improved and community-curated metadata descriptions and integrate previously unregistered information sources. The project will further extend, improve and operationalize the inventory catalog developed in an earlier CINERGI (Community Inventory of EarthCube Resources for Geoscience Interoperability) project, which currently includes over 2 million metadata documents from multiple sources. The key technological innovations include: pioneering the development of an automated cross-domain metadata augmentation and curation pipeline enabled by a large integrated geoscience ontology; mechanisms for ?deep registration? of geoscience data from different sources based on a novel data type registry; an online use case management system; and a methodology for processing several types of complex geoscience queries that cannot be answered by existing systems. In addition, the project will support scientific progress in several representative cross-disciplinary research scenarios, using the contexts of river geochemistry, coral reef and other marine ecosystem analysis, and critical zone science. The project will implement innovative community engagement mechanisms, including community annotation of automatically curated metadata, iterative improvement of geoscience ontology based on community feedback, and joint development of cross-disciplinary use cases semantically aligned with data descriptions. ",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639557,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1639557
1541008,IA,IA,EarthCube IA: Collaborative Proposal: Cross-Domain Observational Metadata Environmental Sensing Network (X-DOMES),EarthCube IA: Collaborative Proposal: Cross-Domain Observational Metadata Environmental Sensing Network (X-DOMES),Collaborative,ICER,EarthCube,9/1/2015,8/18/2015,Janet Fredericks,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Eva E. Zanzerkia,6/30/2019,"$677,919.00 ",Michael Botts|Carlos Rueda|Felimon Gayanilo,jfredericks@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7433,"Across-domains, agencies and political boundaries, our environment is being continuously observed and studied.  The researchers in this project are looking for short-term, near-term and long-term changes while researching new and evolving methods to observe properties and to process the collected observations.  Emerging technologies enable us to provide and discover the data openly and freely.  But, if we do not understand the newly discovered data, with its inherent limitations and biases, it cannot be responsibly utilized for new or collaborative research efforts.  Working with environmental sensor manufacturers and researchers, the X-DOMES project will develop tools and social and technical infrastructure to facilitate the creation of data about data (metadata).   Metadata describes not only who, when and where the observations were made, but also it must document how an observation came to be (provenance).  By taking this knowledge out of manuals and human-readable documents, the X-DOMES model creates metadata that can be treated like data ? discoverable and searchable, making it ready to be incorporated into automated archival and processing for quality assurance and validation methods.   Leveraging existing relationships with large NSF-funded data management programs, EarthCube building blocks and working groups, and environmental sensor manufacturers and consortia, we will establish a community of sensor manufacturers and other stakeholders to provide a unifying approach to describing sensors and observations across geo-science domains.  Built on an existing sensor metadata model that references registered, standards-based vocabularies, the X-DOMES pilot project will provide a suite of tools, built upon community-adopted standards of the Open Geospatial Consortium (OGC) and World Wide Web Consortium (W3C) to demonstrate and facilitate the generation of documents that are discoverable and accessible on-line and/or directly from onboard sensor descriptions.  The project will also demonstrate mechanisms to associate the data with the metadata through standards-based web services.  With vendor-ready tools implemented throughout a broad-based community, the X-DOMES Network will lay the foundation for the development of and adoption of interoperable access to much needed content-rich sensor metadata.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541008,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541008
1736599,OTHER,OTHER,US GEOTRACES PMT: Cobalt Biogeochemical Cycling and Connections to Metalloenzymes in the Pacific Ocean,US GEOTRACES PMT: Cobalt Biogeochemical Cycling and Connections to Metalloenzymes in the Pacific Ocean,One organization,OCE,CHEMICAL OCEANOGRAPHY,11/1/2017,8/30/2017,Mak Saito,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Henrietta Edmonds,10/31/2019,"$347,686.00 ",,msaito@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,1670,9198,"Cobalt is important for many forms of marine life, yet it is one of the scarcest nutrients in the sea. Cobalt's oceanic abundance and distribution, along with other scarce nutrients, can influence the growth of microscopic plants (phytoplankton). This in turn can influence carbon cycles in the ocean and atmosphere. Therefore, knowledge of the controls on cobalt's abundance and chemical forms in seawater is a valuable component of our ability to understand the ocean's influence on global carbon cycling. Within phytoplankton and other marine microbes, metals such as cobalt, iron, nickel, and copper are used as critical components of enzymes responsible for key cellular reactions. Since these enzymes require metals to work, they are named metalloenzymes. Participating in a Pacific Ocean cruise from Alaska to Tahiti, this project will study the oceanic distributions of dissolved cobalt and the cellular content of a group of metalloenzymes known to influence biogeochemical cycles. The project will provide scientific impact by creating new knowledge about oceanic micronutrients in regions of economic interest with regard to fisheries and deep-sea mining. Measurement of proteins in the North Pacific will provide data of broad biological and chemical interest and will be made available through a new NSF-funded ""EarthCube Ocean Protein Portal"" data base. Educational impact will stem from participation of a graduate student and two young technicians, as well as the PI's development of a high school chemistry curriculum for use in two local high schools, thus allowing teachers to include real oceanic and environmental data at their first introduction to chemistry.  Cobalt has a complex biogeochemical cycle.  Both its inorganic and organic forms are used by biology in the upper ocean and it is removed from solution by being scavenged in the intermediate and deep ocean. This scavenging removal results in cobalt having the smallest oceanic inventory of any biologically utilized element. Recent studies, however, have found that large dissolved cobalt plumes occur in major oxygen minimum zones due to a combination of less scavenging and additions from sedimentary and remineralization fluxes. The GP15 US GEOTRACES Pacific Meridional Transect (PMT) provides an opportunity to examine the influence of oxygen depletion on cobalt chemistry. Moreover, the study of the protein component of microbial communities using new proteomic techniques will provide evidence of how different major microorganisms respond to the chemical environment (e.g. through transporter production for specific nutrients and micronutrients) as well as the biochemical basis for metal requirements related to the use of specific metalloenzymes. Specifically, the PMT provides an opportunity to confirm that the Pacific oxygen minimum zones contain a large amount of cobalt and to test the hypotheses that simultaneous zinc scarcity could induce wide-scale biochemical substitution of cobalt for zinc in the North Pacific Ocean.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1736599,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1736599
1540909,IA,IA,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community,Collaborative,ICER,EarthCube,9/1/2015,8/19/2015,Samuel Soule,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Eva E. Zanzerkia,8/31/2017,"$30,417.00 ",,ssoule@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7433,"A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services.   Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540909,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540909
1541564,RCN,RCN,EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network,EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network,Collaborative,ICER,EarthCube,8/1/2016,8/4/2016,Fiammetta Straneo,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Standard Grant,Eva E. Zanzerkia,7/31/2017,"$259,385.00 ",,fstraneo@ucsd.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,8074,7433,"Greenland ice loss quadrupled over the last two decades and presently accounts for one quarter of global sea level rise. The ice loss is due to changes in surface mass balance and ice sheet dynamics associated with rising air and ocean temperatures. The associated increasing freshwater discharge is impacting the regional ocean, including its ecosystems, and has the potential to impact the large-scale North Atlantic circulation. Thus, Greenland's changes are having far-reaching consequences for global societies, yet the mechanisms responsible for these changes are not well understood. Dynamic ice loss, in particular, was likely triggered by changes at the margins of marine-terminating glaciers, through ice/ocean/atmosphere processes that are either absent or poorly represented in climate, ice sheet and ocean models. The interaction of the ocean, the glaciers and atmosphere at Greenland?s margins is a new research frontier. The complex processes involved include the coupling of multiple components of the Earth system, the challenges of obtaining and integrating diverse data from this region, and of modeling such a complex system. These challenges make this a problem that can only be addressed by bringing together multiple disciplines, including data management, collaboratively exploring diverse approaches and working across national borders. This project establishes a network to help scientists working in this area to share their data and work collaboratively.  The goal of this project is to substantially enhance multi-disciplinary activities and collaboration through the establishment of the GRISO (Greenland Ice Sheet Ocean) Science Network - an international, multidisciplinary, open network of scientists and cyberinfrastructure experts. Participants have a shared interested in advancing collective understanding of problems related to Greenland Ice Sheet change and its impact on regional and global climate. GRISO RCN activities will bring together scientists focused on all aspects of ice/ocean/atmosphere/climate data in Greenland and provide a framework for productive collaborative interaction. Specific objectives include two workshops, and a series of synthesis efforts. Additionally, a virtual data portal, leveraging existing infrastructure, will make interdisciplinary data submission and data availability easier and promote uniform and appropriate data management practices. The RCN builds on activities initiated by the former GRISO US CLIVAR Working Group and explicitly addresses priorities identified in a report from an international workshop held in 2013.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541564,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1541564
1435578,OTHER,OTHER,Biological and Chemical Oceanography Data Management Office (BCO-DMO):   A System for Access to Ecological and Biogeochemical Ocean Data,Biological and Chemical Oceanography Data Management Office (BCO-DMO):   A System for Access to Ecological and Biogeochemical Ocean Data,One organization,OCE,LONG TERM ECOLOGICAL RESEARCH|BIOLOGICAL OCEANOGRAPHY|CHEMICAL OCEANOGRAPHY|ANTARCTIC ORGANISMS & ECOSYST|POLAR CYBERINFRASTRUCTURE|OCE SPECIAL PROGRAMS|EarthCube|SEES Ship Operations,9/1/2014,10/10/2018,Peter Wiebe,MA,Woods Hole Oceanographic Institution,41.524235,-70.671161,Continuing grant,David L. Garrison,8/31/2019,"$9,600,001.00 ",David Glover|Robert Groman|Mak Saito|Cynthia Chandler|Danie Kinkade|Adam Shepherd,pwiebe@whoi.edu,183 OYSTER POND ROAD,WOODS HOLE,MA,25431041,5082893542,GEO,1195|1650|1670|5111|5407|5418|8074|8291,1382|1389|1650|1670|4444|7433,"The Earth System is changing rapidly as a result of growing pressure from human activities that are changing important components of the System. The oceans act as the flywheel of the climate system, playing major roles in the climate, the water cycle, the carbon cycle, global energy budgets, and sea level rise. Study and understanding of this component of the Earth System requires integrated multi-disciplinary investigations with access to oceanographic data of biological, chemical, geological, and physical origin. The Biological and Chemical Oceanography Data Management Office (BCO-DMO) was created to serve PIs funded by the NSF Biological and Chemical Oceanography Sections and the Division of Polar Programs Antarctic Organisms and Ecosystems Program as a facility where marine biogeochemical and ecological data and information developed in the course of scientific research can be managed and made publicly available. BCO-DMO provides integrated chemical, biological and physical data inventories from a number of large and intermediate-sized programs, as well as single investigator projects. BCO-DMO also provides scientific investigators the opportunity to explore complex and multifaceted datasets and supports cross-disciplinary collaboration to address pressing environmental questions, problems, and challenges that are exacerbated with the increasing pace of climate change. The BCO-DMO collection of datasets contributed by researchers funded by NSF and others is a publicly available resource accessible via the BCO-DMO website. BCO-DMO supports synthesis and modeling activities, reuse of oceanographic data for new research endeavors, availability of ""real data"" for classroom use by teachers and students at K-12 and college level, and provides decision-support field data for policy-relevant issues. BCO-DMO outreach activities include participation in community training courses and workshops both national and international, and help to foster long-term collaborative partnerships between data management professionals and research investigators. These outreach activities reduce community barriers by fostering the sharing of ideas among synergistic, but otherwise independent research groups. BCO-DMO actively participates in the exchange of knowledge at oceanographic and informatics meetings, an important mechanism by which standards development and adoption occurs.   The primary goal of the BCO-DMO data management repository is to manage existing and new datasets from NSF funded individual scientific investigators and collaborative groups of investigators, and to make the data available online. The BCO-DMO data management system is composed of a metadata database and the distributed client-server JGOFS/GLOBEC data system, plus text-based and map-based user interfaces and support for machine clients to access the information and data available from the repository. The office works with principal investigators and other data contributors to support all phases of the data lifecycle; maintain an inventory of projects, deployments, and datasets; generate standards-compliant metadata records as required by federal agencies; promote compliance with the NSF Ocean Sciences data policy; ensure submission of data to national data centers for archive; support and encourage data synthesis by providing enhanced data discovery and access systems; facilitate interoperability among distributed data repositories; and facilitate regional, national, and international data and information exchange. The office participates in the development and use of open-source, standards-based technologies that enable interoperable data systems to exchange data and information that will foster next-generation research in all disciplines. As the analysis of ocean processes becomes more and more sophisticated, multidisciplinary data integration will also grow more complex. BCO-DMO fosters information sharing and is committed to being a fundamental component of the ocean science research infrastructure without which the goals of existing and future ocean research programs cannot be met.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1435578,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1435578
1354778,"EAGER, RAPID, INSPIRE",EAGER,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,EAGER: Collaborative Research: EarthCube Building Blocks: Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery,Collaborative,ICER,EarthCube,9/15/2013,8/12/2013,Pascal Hitzler,OH,Wright State University,39.783075,-84.062786,Standard Grant,Barbara Ransom,8/31/2014,"$74,999.00 ",,hitzler@ksu.edu,3640 Colonel Glenn Highway,Dayton,OH,454350001,9377752425,GEO,8074,0000|7433|7916|OTHR,"This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures.  It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed.  Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details.  Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354778,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1354778
1440202,BB,BB,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,EarthCube Building Blocks:  Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences,Collaborative,ICER,EarthCube,9/1/2014,9/22/2015,Pascal Hitzler,OH,Wright State University,39.783075,-84.062786,Standard Grant,Eva Zanzerkia,8/31/2017,"$416,745.00 ",Timothy Finin|Michelle Cheatham,hitzler@ksu.edu,3640 Colonel Glenn Highway,Dayton,OH,454350001,9377752425,GEO,8074,7433|9251,"The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.  A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440202,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1440202
1540984,IA,IA,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API,Collaborative,ICER,EarthCube,9/1/2015,7/30/2015,Christopher Norris,CT,Yale University,41.316324,-72.922343,Standard Grant,Eva Zanzerkia,8/31/2018,"$274,244.00 ",Lawrence Gall|Susan Butts|Talia Karim,christopher.norris@yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,GEO,8074,7433,"Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.  The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist.  The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals.",https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540984,https://www.nsf.gov/awardsearch/showAward?AWD_ID=1540984
